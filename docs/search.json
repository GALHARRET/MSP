[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MSP",
    "section": "",
    "text": "Introduction\nLa Maitrise Statistique des Procédés (MSP) ou Statistical Process Control (SPC) est une branche des statistiques qui s’intéresse au suivi dans le temps d’un processus (par exemple un procédé de fabrication). Historiquement les premières approches de la MSP ont été introduites par W. A. Shewhart dans les années 1920 alors qu’il travaillait dans les laboratoires BELL."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "chapitre1.html",
    "href": "chapitre1.html",
    "title": "1  Estimation des paramètres du procédé",
    "section": "",
    "text": "1.1 Introduction\nLien vers le cours de Patrice Hardouin\nEn pratique, on prélève \\(k\\) échantillons de même effectif \\(n\\).\nExemple : on prélève à intervalles réguliers 25 échantillons de 5 unités de production. Les observations fluctuent autour de \\(y=1\\). Ces fluctuations sont aléatoires et peu importantes (\\(\\pm\\) 5%).\nLes données sont disponibles ici",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Estimation des paramètres du procédé</span>"
    ]
  },
  {
    "objectID": "chapitre1.html#introduction",
    "href": "chapitre1.html#introduction",
    "title": "1  Estimation des paramètres du procédé",
    "section": "1.1 Introduction",
    "text": "1.1 Introduction\n\nUn procédé de fabrication même lorsqu’il est sous contrôle connait des variations aléatoires (peu importantes).\nCes variations sont assignables aux 5M (voir figure). La dispersion globale du procédé de fabrication notée \\(D_G\\) rend compte de ces fluctuations.\n\n Lien vers le cours de Patrice Hardouin\n\nLes variations qui sont imputables aux machines sont particulièrement étudiées. On note \\(D_M\\) la dispersion due aux machines, on parle aussi de dispersion instantanée.\n\nEn pratique, on prélève \\(k\\) échantillons de même effectif \\(n\\).\nExemple : on prélève à intervalles réguliers 25 échantillons de 5 unités de production. Les observations fluctuent autour de \\(y=1\\). Ces fluctuations sont aléatoires et peu importantes (\\(\\pm\\) 5%).\nLes données sont disponibles ici"
  },
  {
    "objectID": "chapitre1.html#estimation-de-la-dispersion-globale",
    "href": "chapitre1.html#estimation-de-la-dispersion-globale",
    "title": "1  Estimation des variations de production",
    "section": "1.2 Estimation de la dispersion globale",
    "text": "1.2 Estimation de la dispersion globale\nOn suppose que les observations suivent une loi normale de moyenne \\(\\mu\\) et d’écart type \\(\\sigma_G\\). Cela permet de dire que la proportion théorique de données dans\n\n\\([\\mu-\\sigma_G,\\mu+\\sigma_G]\\) est de 68.3 %,\n\\([\\mu-2\\sigma_G,\\mu+2\\sigma_G]\\) est de 95.4 %,\n\\([\\mu-3\\sigma_G,\\mu+3\\sigma_G]\\) est de 99.7 %.\n\nAinsi pour la dispersion globale on choisit \\[D_g=6\\sigma_G.\\]\nPour l’estimation de \\(D_M\\) on prélève un échantillon à un instant donné (ainsi les variations sont uniquement dues à la machine) et on suppose là-encore que les valeurs sont distribuées selon une loi normale de moyenne \\(\\mu\\) et d’écart type \\(\\sigma_M.\\) Naturellement, la dispersion instantanée sera définie par \\(D_M=6\\sigma_M.\\)\nLes deux écarts types \\(\\sigma_M,\\sigma_G\\) sont inconnus, en pratique, ils vont être estimés de la façon suivante :\nOn note \\(y_{ij}\\) la valeur \\(i=1,...,n\\) de l’échantillon \\(j=1,...,k.\\)\nExemple : on prélève 25 échantillons de 5 unités de production. Les observations fluctuent autour de \\(y=1\\). Ces fluctuations sont aléatoires et peu importantes (\\(\\pm\\) 5%).\nLes données sont disponibles ici\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEstimation des paramètres de production\n\n\n\nUne estimation de \\(\\mu\\) est \\[\\hat \\mu=\\frac 1{k} \\displaystyle\\sum_{j=1}^k \\bar y_{j},\\] et une estimation de \\(\\sigma_G\\) est \\[\\hat \\sigma_G= \\sqrt{\\frac{\\displaystyle\\sum_{j=1}^k\\sum_{i=1}^n(y_{ij}-\\hat \\mu)^2}{n\\times k-1}}.\\]\n\n\nCalculer dans l’exemple une estimation de la moyenne et de l’écart type global :\n\n\nVoir la correction\nmean(df$obs)\nsd(df$obs)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Estimation des variations de production</span>"
    ]
  },
  {
    "objectID": "chapitre1.html#estimation-de-la-dispersion-instantanée",
    "href": "chapitre1.html#estimation-de-la-dispersion-instantanée",
    "title": "1  Estimation des variations de production",
    "section": "1.3 Estimation de la dispersion instantanée :",
    "text": "1.3 Estimation de la dispersion instantanée :\nIl existe plusieurs estimations possibles de \\(\\sigma_M\\) :\n\nla première est basée sur le calcul des écarts types des \\(k\\) échantillons prélevés.\nla deuxième est basée sur le calcul des étendues des \\(k\\) échantillons prélevés.\n\nPour ces calculs on appliquera des coefficients de correction qui sont donnés en fonction de \\(n\\) dans le tableau suivant. Le coefficient \\(d_2(n)\\) correspond à l’espérance de l’étendue d’une loi normale centrée réduite et \\(c_4(n)\\) à l’espérance de l’écart type d’une loi normale centrée réduite. Ces valeurs peuvent très facilement être obtenues par simulation par exemple pour \\(n=5\\) :\nLes fonctions c4,d2,d3 du package multiSPC permettent d’estimer ces paramètres :\n\nc4(5)\n\n\nOn sait pour chaque échantillon \\(j\\) de \\(n\\) valeurs calculer une estimation de l’écart type \\(\\sigma_j\\) en calculant \\[s_j= \\sqrt{\\frac{\\displaystyle\\sum_{i=1}^n(y_{ij}-\\bar y_j)^2}{n-1}},\\] où \\(\\bar y_j\\) est la moyenne de l’échantillon \\(j.\\)\n\n\n\n\n\n\n\nEstimation à partir des écarts types\n\n\n\nOn considère \\(k\\) prélèvements de taille \\(n\\) dont les écarts types sont \\(s_1,...,s_k,\\) on pose \\(\\bar S =\\frac{\\sum_{j=1}^k s_j}{k}\\). Une estimation de l’écart type instantané \\(\\sigma_M\\) est donné par \\[\n\\hat \\sigma_M=\\dfrac{\\bar S}{c_4(n)}.\n\\]\n\n\n\nPour chaque échantillon \\(j\\) on calcule l’étendue\n\n\\[\nR_j=\\max(y_{ij})-\\min(y_{ij})\n\\]\n\n\n\n\n\n\nEstimation à partir des écarts types\n\n\n\nOn considère \\(k\\) prélèvements de taille \\(n\\) dont les étendues sont \\(R_1,...,R_k,\\) on pose \\(\\bar R =\\frac{\\sum_{j=1}^k R_j}{k}\\). Une estimation de l’écart type instantané \\(\\sigma_M\\) est donné par \\[\n\\hat \\sigma_M=\\dfrac{\\bar R}{d_2(n)}.\n\\]\n\n\nFaire ces deux calculs sur les données de l’exemple précédent.\n\n\nVoir la correction\n# Estimation à partir des écarts types\ntab&lt;-df %&gt;% group_by(sample) %&gt;% summarise(\"s_j\"=round(sd(obs),5)) \nmean(tab$\"s_j\")/c4(5)\n\n# Estimation à partir des étendues\netendue&lt;-function(X){return(max(X)-min(X))}\ntab2&lt;-df %&gt;% group_by(sample)%&gt;% summarise(\"R_j\"=etendue(obs))\nmean(tab2$\"R_j\")/d2(5)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Estimation des variations de production</span>"
    ]
  },
  {
    "objectID": "chapitre3.html",
    "href": "chapitre3.html",
    "title": "2  Cartes de contrôle",
    "section": "",
    "text": "2.1 Historique\nAvantages\nInconvénients",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Cartes de contrôle</span>"
    ]
  },
  {
    "objectID": "chapitre3.html#historique",
    "href": "chapitre3.html#historique",
    "title": "2  Cartes de contrôle",
    "section": "",
    "text": "Inventées par Walter A. Shewhart (années 1920)\nS’utilisent dans de très nombreux secteurs d’activité (industrie, transport, service, …)\nSuivi et/ou amélioration d’un système de production\n\n\n\nTrès faciles à mettre en oeuvre\nTrès faciles à interpréter (graphiques)\n\n\n\nNe tient pas a priori compte des tolérances\nN’est pas toujours efficace (ex : si problème de déviation progressive)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Cartes de contrôle</span>"
    ]
  },
  {
    "objectID": "chapitre3.html#comprendre-les-variations-des-procédés-de-fabrication",
    "href": "chapitre3.html#comprendre-les-variations-des-procédés-de-fabrication",
    "title": "2  Cartes de contrôle",
    "section": "2.2 Comprendre les variations des procédés de fabrication",
    "text": "2.2 Comprendre les variations des procédés de fabrication\nOn distingue plusieurs causes qui peuvent induire des variations dans un système de production :\n\ncauses aléatoires (communes) elles sont en grand nombre avec un effet individuel faible. On peut les modéliser par une variable aléatoire (en général gaussienne). Elles peuvent être corrigées par des actions sur le système global. Exemple : temps de trajet domicile-travail. Si il y a des feux rouges sur le trajet ceux-ci pourront être parfois verts ou rouges, il peut y avoir plus ou moins de circulation… Action globale : changer de route pour ne plus avoir de feux rouges !\ncauses assignables (spéciales) elles sont rares et ne peuvent pas être associées directement au procédé de fabrication (Deming 1986). Elles peuvent être corrigées par des actions locales. Exemple : un accident de la route se produit sur le trajet.\n\nUn processus est dit sous contrôle ou statistiquement stable lorsque les variations sont uniquement dûes à des causes aléatoires.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Cartes de contrôle</span>"
    ]
  },
  {
    "objectID": "chapitre5.html",
    "href": "chapitre5.html",
    "title": "5  Cartes aux limites modifiées",
    "section": "",
    "text": "5.1 Cas n°1 : le procédé de fabrication n’est pas capable\nPour l’instant les cartes qui ont été proposées ne tiennent pas compte des tolérances imposées par le client. Elles reposent uniquement sur la distribution des observations et sur le % de fausses alertes que l’on souhaite observer (0.3% dans les cartes précédentes).\nDans ce cas on \\(Cam&lt;1.33\\), ce qui donne \\(TS-TI&lt;1.33\\times 6\\sigma_I\\simeq 8\\sigma_I\\). On voudrait pouvoir le plus rapidement possible détecter le problème, le seul paramètre sur lequel on peut jouer est la taille \\(n\\) des prélèvements. En prenant\n\\[\nn \\geq \\left( \\frac{8\\sigma_I}{TS-TI} \\right)^2,\n\\]\non pourra détecter plus rapidement le problème de capabilité du procédé de fabrication.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Cartes aux limites modifiées</span>"
    ]
  },
  {
    "objectID": "chapitre5.html#déréglage-de-la-moyenne",
    "href": "chapitre5.html#déréglage-de-la-moyenne",
    "title": "5  Efficacité des cartes de Shewhart",
    "section": "5.2 Déréglage de la moyenne",
    "text": "5.2 Déréglage de la moyenne\n Un décentrage de moyenne est exprimé en nombre d’écart type (unité standardisé) donc si \\(\\mu_1\\) est la moyenne décentrée, on lui associera le décentrage\n\\[\n\\rho=\\frac{|\\mu_1-\\mu|}{\\sigma}\n\\]\nLa probabilité \\(\\beta\\) de ne pas détecter le décentrage est alors\n\\[\n\\beta=\\mathbb P(LIC&lt;\\widetilde X &lt;LSC)\n\\]\noù \\(\\widetilde X \\sim \\mathcal N(\\mu+\\rho\\sigma,\\frac{\\sigma}{\\sqrt{n}}).\\) Un calcul simple permet d’obtenir\n\\[\n\\beta = F(3-\\rho\\sqrt n)-F(-3-\\rho\\sqrt n)\n\\]\noù \\(F(x)=\\mathbb P(X&lt;x)\\) est la fonction de répartition de la loi normale.\nL’efficacité de la carte est mesurée par \\(1-\\beta\\) ( puissance de la carte).\nOn obtient ainsi les courbes d’efficacité de la carte de la moyenne en fonction de la taille \\(n\\) des échantillons prélevés.\n\n\n\n\n\n\n\n\n\n\nOn constate (ce qui est logique) que la probabilité de ne pas détecter un déréglage donné diminue en fonction de la taille de l’échantillon.\nDétecter un déréglage \\(\\rho=0\\) correspond à une fausse alerte qui vaut pour la carte de la moyenne \\(\\alpha=0.3\\%\\).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Cartes aux limites modifiées</span>"
    ]
  },
  {
    "objectID": "chapitre5.html#déréglage-de-lécart-type",
    "href": "chapitre5.html#déréglage-de-lécart-type",
    "title": "5  Efficacité des cartes de Shewhart",
    "section": "5.3 Déréglage de l’écart type",
    "text": "5.3 Déréglage de l’écart type\nIci on considère des décentrages \\(\\rho&gt;1\\) (sinon il s’agit d’une amélioration de la dispersion).\nUn calcul similaire au précédent conduit à \\[\n\\beta=F(\\frac{3}{\\rho})-F(\\frac{-3}{\\rho})\n\\] Ici on constate que l’efficacité de la carte est indépendante de \\(n\\) et qu’elle est très mauvaise. Il faut une très grande valeur de \\(\\rho\\) pour avoir une petite valeur de \\(\\beta\\).\nPar exemple pour \\(\\rho=3\\) on a \\(\\beta=\\) 0.6826895 c’est à dire pour un écart type qui triplerait la probabilité ne peut pas détecter ce dérèglement est de 68.3%.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Cartes aux limites modifiées</span>"
    ]
  },
  {
    "objectID": "chapitre5.html#période-opérationelle-moyenne-average-run-length",
    "href": "chapitre5.html#période-opérationelle-moyenne-average-run-length",
    "title": "5  Efficacité des cartes de Shewhart",
    "section": "5.4 Période opérationelle moyenne (Average Run Length)",
    "text": "5.4 Période opérationelle moyenne (Average Run Length)\nLa Période Opérationnelle Moyenne correspond au nombre de prélèvements qu’il faut effectuer, en moyenne, pour sortir des limites de contrôle lorsque qu’un déréglage \\(\\rho\\) s’est produit.\nLe cas \\(\\rho=0\\) pour une carte de Shewhart avec des observations indépendantes correspond à une fausse alerte qui se produit dans \\(\\alpha=0.3\\%\\) et correspond à\n\\[\nARL_0=\\frac{1}{0.003}=333\n\\] donc il faut en moyenne 334 prélèvements avant de détecter une fausse alerte.\n\\(ARL\\) est définie par\n\\[\nARL_\\rho=\\frac 1{1-\\beta}\n\\]\nC’est donc l’inverse de la puissance (efficacité) de la carte, donc plus ce nombre sera petit plus la carte sera efficace.\nSi on reprend les courbes d’efficacité précédente on obtient :",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Cartes aux limites modifiées</span>"
    ]
  },
  {
    "objectID": "chapitre5.html#calibration-des-tailles-de-prélèvement",
    "href": "chapitre5.html#calibration-des-tailles-de-prélèvement",
    "title": "5  Efficacité des cartes de Shewhart",
    "section": "5.5 Calibration des tailles de prélèvement",
    "text": "5.5 Calibration des tailles de prélèvement\nLa production initiale est \\(X\\sim \\mathcal N (\\mu,\\sigma)\\) et la production décentrée vaut \\(\\widetilde X \\sim \\mathcal N (\\mu+\\rho\\sigma,\\sigma)\\). On sait calculer la probabilité \\(1-\\beta\\) de détecter le décentrage en fonction de \\(\\rho\\) et on a donc\n\\[\nARL_\\rho=\\frac 1{1-\\beta}=\\frac 1{1-F(3-\\rho\\sqrt n)+F(-3-\\rho\\sqrt n)}\n\\]\nExemple :\nConsidérons le problème suivant : on a un décentrage de moyenne de 0.5 écart type. On voudrait le détecter en moyenne avant 50 prélèvements. Quelle taille d’échantillon doit-on considérer ?\n\nn&lt;-seq(2,20,by=1)\nrho&lt;-.5\nbeta=pnorm(3-rho*sqrt(n))-pnorm(-3-rho*sqrt(n))\nARL&lt;-1/(1-beta)\nJ&lt;-which.max(ARL&lt;50)\nn[J]\n\n[1] 4",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Cartes aux limites modifiées</span>"
    ]
  },
  {
    "objectID": "chapitre5.html#cas-n1-le-procédé-de-fabrication-nest-pas-capable",
    "href": "chapitre5.html#cas-n1-le-procédé-de-fabrication-nest-pas-capable",
    "title": "5  Cartes aux limites modifiées",
    "section": "",
    "text": "5.1.1 Exemple\nOn suppose que \\(X \\sim \\mathcal N(10,2)\\) on prélève 20 échantillons de taille \\(n=4\\).\nLes données sont disponibles ici\nOn peut construire la carte de la moyenne :\n\n\n\n\n\n\n\n\n\nSupposons que l’intervalle de tolérance soit \\(10 \\pm 3\\). Alors on a\n\\(n \\geq\\) 7.1187849 (on prend \\(n=8\\))\n\nn=8\nLICm=mu-3*sigI/sqrt(n)\nLSCm=mu+3*sigI/sqrt(n)\nplot_chart(M,LIC=LICm,LSC=LSCm,Type = \"carte de la moyenne\")\n\n\n\n\n\n\n\n\nOn constate que dès le 8ième prélèvement on trouve une valeur hors contrôle.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Cartes aux limites modifiées</span>"
    ]
  },
  {
    "objectID": "chapitre5.html#cas-n2-le-procédé-de-fabrication-est-capable",
    "href": "chapitre5.html#cas-n2-le-procédé-de-fabrication-est-capable",
    "title": "5  Cartes aux limites modifiées",
    "section": "5.2 Cas n°2 : le procédé de fabrication est capable",
    "text": "5.2 Cas n°2 : le procédé de fabrication est capable\nPar exemple si on a une prodcution \\(X \\sim \\mathcal N(3,0.5)\\) avec des tolérances \\(TI=1\\) et \\(TS=5\\), on a \\(TS-TI &gt;&gt; 6\\sigma\\) donc on peut faire une carte de la moyenne aux limites modifiées les nouvelles limites \\(LIC^*,LSC^*\\) étant égales à des moyennes modifiées \\(\\mu_I,\\mu_S.\\)\n\nOn définit les moyennes maximales refusables (inférieures et supérieures)\n\\[\n\\begin{cases}\n\\mu_I=TI+3\\sigma \\\\\n\\mu_S=TS-3\\sigma\n\\end{cases}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Cartes aux limites modifiées</span>"
    ]
  },
  {
    "objectID": "chapitre5.html#remarque",
    "href": "chapitre5.html#remarque",
    "title": "5  Cartes aux limites modifiées",
    "section": "5.3 Remarque :",
    "text": "5.3 Remarque :\nCe choix peut être relié au coefficient de performance défini dans le chapitre précédent \\(Cmk=\\frac{\\min\\left(\\mu-TI;TS-\\mu\\right)}{3\\sigma}\\).\nSi on remplace \\(\\mu\\) par \\(\\mu_I\\) on obtient \\(\\frac{\\min\\left(\\mu_I-TI;TS-\\mu_I\\right)}{3\\sigma}=\\min(1;\\frac{TS-TI-3\\sigma}{3\\sigma}).\\)\n\nCe nombre vaut 1 si \\(\\frac{TS-TI-3\\sigma}{3\\sigma}&gt;1\\) ce qui revient à \\(Cap&gt;1.\\) C’est à dire que lorsque le procédé est sous contrôle on va autoriser une déviation de la moyenne.\nCe nombre vaut \\(\\frac{TS-TI-3\\sigma}{3\\sigma}\\) sinon et dans ce cas \\(Cap&lt;1,\\) le procédé ne répond pas aux spécifications imposées par le client. Il faut dans ce cas agir sur le procédé.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Cartes aux limites modifiées</span>"
    ]
  },
  {
    "objectID": "chapitre5.html#calibration-de-la-taille-des-échantillons",
    "href": "chapitre5.html#calibration-de-la-taille-des-échantillons",
    "title": "5  Cartes aux limites modifiées",
    "section": "5.4 Calibration de la taille des échantillons :",
    "text": "5.4 Calibration de la taille des échantillons :\nOn peut également définir le déraglage maximal admissible \\(\\rho_{max}\\) par\n\\[\n\\rho_{max}=\\min\\left( \\frac{\\mu_S-\\mu}{\\sigma},\\frac{\\mu-\\mu_I}{\\sigma}\\right)\n\\]\nOn va alors calibrer la taille \\(n\\) des échantillons à prélever de façon à détecter le déréglage maximal admissible à un risque \\(\\beta\\) fixé de ne pas détecter ce déréglage maximal \\(\\rho_{max}\\). D’après ce qui précède \\(n\\) sera le plus petit entier tel que\n\\[\nn \\geq \\left( \\frac{3+z_{1-\\beta}}{\\rho_{max}} \\right)^2\n\\]\noù \\(z_{1-\\beta}\\) est le quantile d’ordre \\((1-\\beta)\\) de la loi normale.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Cartes aux limites modifiées</span>"
    ]
  },
  {
    "objectID": "chapitre5.html#retour-à-lexemple",
    "href": "chapitre5.html#retour-à-lexemple",
    "title": "5  Cartes aux limites modifiées",
    "section": "5.5 Retour à l’exemple",
    "text": "5.5 Retour à l’exemple\nAvec les valeurs précédentes on a \\(\\rho_{max}=3.\\) Si on veut détecter ce déréglage dans 90% des cas alors on doit avoir \\(n \\geq\\) 2.0368538\nPrélever des échantillons de taille \\(n=3\\) suffit à détecter dans 95% des cas des décentrages d’au moins 3 écarts types.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Cartes aux limites modifiées</span>"
    ]
  },
  {
    "objectID": "chapitre4.html",
    "href": "chapitre4.html",
    "title": "3  Cartes univariées",
    "section": "",
    "text": "3.1 Cartes de Shewart\nOn va construire deux graphiques : une carte dite de position et une carte de dispersion. Ces cartes sont appelées les cartes de Shewart.\nExemple\nSuivi de production journalière de steacks hachés surgelés durant 12h de production. Chaque heure on prélève 5 steaks et on les pèse.\nLes données sont disponibles ici\nX\nweight.1\nweight.2\nweight.3\nweight.4\nweight.5\n\n\n\n\n1\n98.6\n100.3\n100.9\n100.2\n99.6\n\n\n2\n100.3\n99.5\n98.9\n100.2\n100.6\n\n\n3\n99.2\n98.8\n101.5\n100.3\n101.0\n\n\n4\n101.1\n97.8\n98.9\n101.3\n101.7\n\n\n5\n101.0\n99.8\n97.3\n99.4\n100.8\n\n\n6\n101.1\n100.1\n99.0\n100.7\n99.9\nOn va construire les cartes de contrôle données ci-dessous\nPour chaque échantillon de 5 steacks on calcule la moyenne et l’écart type et on les reporte sur les cartes correspondantes.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Cartes univariées</span>"
    ]
  },
  {
    "objectID": "chapitre4.html#distribution-des-paramètres",
    "href": "chapitre4.html#distribution-des-paramètres",
    "title": "3  Cartes de contrôles de Shewhart",
    "section": "3.2 Distribution des paramètres",
    "text": "3.2 Distribution des paramètres\nOn suppose que tous les paramètres suivent une loi normale.\n\nLa moyenne d’un échantillon \\(\\bar Y \\sim \\mathcal N(\\mu,\\frac{\\sigma}{\\sqrt n}).\\)\nL’étendue d’un échantillon \\(R \\sim \\mathcal N(\\mu_R,\\sigma_R).\\)\nL’écart type d’un échantillon \\(S \\sim \\mathcal N(\\mu_S,\\sigma_S).\\)\n\nOn définit alors les limites de surveillance et de contrôle pour chaque carte. Pour la carte de la moyenne :\n On se fixe un risque \\(\\alpha\\) de stoper la production alors que celle-ci est sous contrôle (Fausses alertes). On cherche donc un intervalle de confiance \\(1-\\alpha\\) de \\(\\bar X\\) La distribution des moyennes étant normale on a\n\\[\n\\begin{cases}\nLI=\\mu-z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt n} \\\\\nLS=\\mu+z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt n} \\\\\n\\mathbb P(LI&lt;\\bar X&lt;LS)=1-\\alpha\n\\end{cases}\n\\]\nOn pourra en conclure que la moyenne \\(\\bar X\\) de l’échantillon considéré n’est pas significativement différente de la moyenne \\(\\mu\\) (c’est à dire que le procédé est sous contrôle) si \\(\\bar X \\in [LI,LS].\\)\nLes limites de surveillance sont définies de façon à déterminer, au risque de 4.5%, les moyennes significativement différentes de la moyenne globale :\n\nLimite inférieure de surveillance (LIS): \\(LIS=\\mu-2\\frac{\\sigma}{\\sqrt n}\\)\nLimite supérieure de surveillance (LSS): \\(LSS=\\mu+2\\frac{\\sigma}{\\sqrt n}\\)\n\nLes limites de contrôle sont définies de façon à déterminer, au risque de 0.3% de fausses alertes, les moyennes significativement différentes de la moyenne globale :\n\nLimite inférieure de contrôle (LIC): \\(LIC=\\mu-3\\frac{\\sigma}{\\sqrt n}\\)\nLimite supérieure de contrôle (LSC): \\(LSC=\\mu+3\\frac{\\sigma}{\\sqrt n}\\)\n\n\n\n\n\n\n\nLimites des cartes de contrôle\n\n\n\nOn a prélevé à intervalles réguliers \\(k\\) échantillons de \\(n\\) observations. On a calculé \\(\\bar y_j,R_j\\) la moyenne et l’étendue de chacun des \\(k\\) échantillons.\nPour construire :\n\nLa carte de la moyenne on utilise \\(\\hat \\mu_I=\\frac 1{k} \\displaystyle\\sum_{j=1}^k \\bar y_{j}\\) et \\(\\hat \\sigma_I = \\dfrac{\\bar R}{d_2}\\).\nLa carte de l’étendue on utilise \\(\\hat\\mu_R=\\bar R\\) et \\(\\hat \\sigma_R=\\frac{d_3}{d_2}\\bar R\\).\nLa carte de l’écart type on utilise \\(\\hat\\mu_S=\\bar S\\) et \\(\\hat \\sigma_S=\\frac{\\sqrt{1-c_4^2}}{c_4}\\bar S\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Cartes de contrôles de Shewhart</span>"
    ]
  },
  {
    "objectID": "chapitre4.html#estimation-des-limites-de-contrôle-pour-la-carte-de-la-moyenne.",
    "href": "chapitre4.html#estimation-des-limites-de-contrôle-pour-la-carte-de-la-moyenne.",
    "title": "4  Cartes de contrôles de Shewhart",
    "section": "4.3 Estimation des limites de contrôle pour la carte de la moyenne.",
    "text": "4.3 Estimation des limites de contrôle pour la carte de la moyenne.\nReprenons le cas précédent. Pour chaque échantillon on peut calculer \\(\\bar y_j,R_j\\) la moyenne et l’étendue.\nOn a vu dans le chapitre précédent que \\(\\hat\\mu=\\overline{\\overline{y}}=\\frac 1{k} \\displaystyle\\sum_{j=1}^k \\bar y_{j}\\) et que \\(\\hat \\sigma = \\dfrac{\\bar R}{d_2}\\). Donc on a : \\[\n\\begin{cases}\n\\widehat{LIC}= \\bar{\\bar{y}}-\\frac{3}{\\sqrt n} \\frac{\\overline R}{d_2} \\\\\n\\widehat{LSC}= \\bar{\\bar{y}}+\\frac{3}{\\sqrt n} \\frac{\\overline R}{d_2}\n\\end{cases}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cartes de contrôles de Shewhart</span>"
    ]
  },
  {
    "objectID": "chapitre4.html#estimation-des-limites-de-contrôle-pour-la-carte-des-étendues",
    "href": "chapitre4.html#estimation-des-limites-de-contrôle-pour-la-carte-des-étendues",
    "title": "4  Cartes de contrôles de Shewhart",
    "section": "4.4 Estimation des limites de contrôle pour la carte des étendues",
    "text": "4.4 Estimation des limites de contrôle pour la carte des étendues\nPour l’estimation de \\(\\mu_R\\) on prend \\(\\hat\\mu_R=\\bar R\\), et pour l’estimation de \\(\\sigma_R\\) on prend \\(\\hat \\sigma_R=\\frac{d_3}{d_2}\\bar R\\) où \\(d_3\\) est l’écart type des étendues d’une loi normale centrée réduite. On a : \\[\n\\begin{cases}\n\\widehat{LIC}= \\overline{R}-3\\frac{d_3}{d_2}\\overline R \\\\\n\\widehat{LSC}= \\overline{R}+3\\frac{d_3}{d_2}\\overline R\n\\end{cases}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cartes de contrôles de Shewhart</span>"
    ]
  },
  {
    "objectID": "chapitre6.html",
    "href": "chapitre6.html",
    "title": "4  Carte EWMA",
    "section": "",
    "text": "4.1 Introduction\nLa carte de Shewhart de la moyenne est très simple à mettre en oeuvre et à interpréter. Cependant elle n’a pas une très grande efficacité surtout :\nExemple :\nOn suit une production de caractéristique \\(\\mu=15\\) et \\(\\sigma=0.5\\). Pour ce faire 10 prélèvements de 4 unités de production ont été réalisés. On construit la carte de moyenne de Shewhart. A partir du 7ième prélèvement on constate une déviation de la moyenne et un décentrage supérieur. La carte de Shewhart ne détecte cette déviation que très tardivement (14ième prélèvement).\nUne des solutions est la carte EWMA",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Carte EWMA</span>"
    ]
  },
  {
    "objectID": "chapitre6.html#introduction",
    "href": "chapitre6.html#introduction",
    "title": "4  Carte EWMA",
    "section": "",
    "text": "en cas de faibles et moyennes déviations\nen cas de structure d’autocorrélation, c’est à dire lorsque le passé a une influence, par exemple lorsqu’une tendance croissante apparaît.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Carte EWMA</span>"
    ]
  },
  {
    "objectID": "chapitre6.html#définition-des-cartes-ewma",
    "href": "chapitre6.html#définition-des-cartes-ewma",
    "title": "4  Carte EWMA",
    "section": "4.2 Définition des cartes EWMA",
    "text": "4.2 Définition des cartes EWMA\nEWMA : Exponentially Weighted Moving Average\nOn définit la statistique \\(z_i\\) par une relation de récurrence pour tout \\(i=1,...,k\\)\n\\[\nz_i=\\lambda \\bar x_i +(1-\\lambda)z_{i-1},\n\\]\noù \\(\\bar x_i\\) est la moyenne des unités pour le prélèvement \\(i\\) et \\(0&lt;\\lambda\\leq 1\\) est un réel qui sera choisi en fonction du poids que l’on veut donner aux données précédentes. En effet, en général on choisit \\(z_0=\\mu\\) (moyenne du procédé de fabrication). On a \\[\n\\begin{cases}\nz_1=\\lambda \\bar x_1+(1-\\lambda)\\mu \\\\\nz_2=\\lambda \\bar x_2+(1-\\lambda)z_1= \\lambda \\bar x_2+\\lambda(1-\\lambda)\\bar x_1+(1-\\lambda)^2\\mu \\\\\nz_3=\\lambda \\bar x_3+\\lambda(1-\\lambda)\\bar x_2+\\lambda(1-\\lambda)^2\\bar x_1+\n(1-\\lambda)^3\\mu \\\\\n\\ldots\n\\end{cases}\n\\]\n\n\n\n\n\n\n\n\n\n\nLa cas \\(\\lambda=1\\) correspond à la carte de Shewhart sur la moyenne.\nOn constate que \\(\\bar x_i\\) a une importance d’autant plus importante dans \\(z_i\\) que \\(\\lambda\\) est grand.\nEn général on utilise \\(0.25&lt;\\lambda&lt;0.5\\).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Carte EWMA</span>"
    ]
  },
  {
    "objectID": "chapitre6.html#limites-de-contrôle-des-cartes-ewma",
    "href": "chapitre6.html#limites-de-contrôle-des-cartes-ewma",
    "title": "4  Carte EWMA",
    "section": "4.3 Limites de contrôle des cartes EWMA",
    "text": "4.3 Limites de contrôle des cartes EWMA\nLes limites de ces cartes sont variables (en fonction de \\(i\\)) pour \\(X\\sim \\mathcal N(\\mu,\\sigma)\\) on a :\\[LC = \\mu  \\pm L\\frac{\\sigma}{\\sqrt{n}}\\times \\sqrt {\\frac{\\lambda}{2-\\lambda}[1-(1-\\lambda)^{2i}] }.\\]\n\nLorsque le nombre \\(i\\) de prélèvement est très grand alors \\(LC = \\mu  \\pm L\\frac{\\sigma}{\\sqrt{n}}\\times \\sqrt {\\frac{\\lambda}{2-\\lambda}}\\). Dans ce cas on peut jouer sur ce paramètre \\(L\\) pour améliorer l’efficacité de la carte en fonction de \\(\\lambda\\).\nOn constate que sur les petites déviations de production l’efficacité des cartes EWMA est bien supérieure à celle de la carte de Shewhart.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Carte EWMA</span>"
    ]
  },
  {
    "objectID": "chapitre6.html#retour-à-lexemple",
    "href": "chapitre6.html#retour-à-lexemple",
    "title": "4  Carte EWMA",
    "section": "4.4 Retour à l’exemple :",
    "text": "4.4 Retour à l’exemple :\nOn constate que contrairement à la carte de la moyenne la carte EWMA détecte le décentrage dès le 5ième prélèvement.\n\nlambda=0.25\nZ&lt;-ewma_cart1(data,n,mu=mu,sig=sig,lambda=lambda)\nplot_chart(Z$z,LIC=Z$LIC,LSC=Z$LSC,Type=\"Carte EWMA\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Carte EWMA</span>"
    ]
  },
  {
    "objectID": "index.html#but-vérifier-la-qualité-de-réalisation",
    "href": "index.html#but-vérifier-la-qualité-de-réalisation",
    "title": "MSP",
    "section": "But : vérifier la qualité de réalisation",
    "text": "But : vérifier la qualité de réalisation\nDéfinir des indicateurs permettant de détecter des modifications inhabituelles au niveau :\n\ndu procédé de fabrication,\ndes instruments de mesure,\nde la qualité des matières premières,\nde la qualité des lots de produits finis.\n\nCes vérifications seront réalisées sur la base de prélèvements d’échantillon."
  },
  {
    "objectID": "index.html#fluctuation-déchantillons",
    "href": "index.html#fluctuation-déchantillons",
    "title": "MSP",
    "section": "Fluctuation d’échantillons",
    "text": "Fluctuation d’échantillons\nLorsque l’on prélève des échantillons dans une production même si les conditions opérationnelles sont strictement identiques on n’obtiendra pas les mêmes moyennes ni les mêmes écarts types.\n\n\n\n\n\n\nCôté Math\n\n\n\nSi les observations \\(X_1,...,X_n\\) sont prélevées indépendamment dans une population normale de moyenne \\(\\mu\\) et d’écart type \\(\\sigma\\) alors la moyenne de ces observations \\[\\bar X = \\frac 1{n}\\sum_{i=1}^nX_i \\sim \\mathcal N(\\mu,\\frac{\\sigma}{\\sqrt{n}}).\\]\n\n\nPour illustrer ce résultat : Dans l’exemple suivant on prélève des échantillons de taille \\(n=5\\) dans une production normale dont la caractéristique moyenne est 100 et l’écart type 5."
  },
  {
    "objectID": "index.html#la-msp-dans-lamélioration-continue",
    "href": "index.html#la-msp-dans-lamélioration-continue",
    "title": "MSP",
    "section": "La MSP dans l’amélioration continue",
    "text": "La MSP dans l’amélioration continue\n\nLa qualité du produit n’est pas le simple respect d’une spécification.\nL’objectif est représenté comme un processus de réduction de la dispersion des caractéristiques du produit.\nEviter la production de défectueux, c’est à dire d’avoir des produits qui ne répondent pas à des spécifications."
  },
  {
    "objectID": "index.html#méthode-6sigma",
    "href": "index.html#méthode-6sigma",
    "title": "MSP",
    "section": "Méthode \\(6\\sigma\\) :",
    "text": "Méthode \\(6\\sigma\\) :\nHistoriquement mise en place par Mikel Harry dans les années 80.\n\nune méthode d’amélioration de la qualité qui repose sur la maîtrise statistique des procédés,\nune méthode de management qui repose sur une organisation très encadrée de la conduite de projets.\n\nDans la boîte à outils 6 sigma on a : - de nombreux outils d’analyse du procédé, d’analyse statistique (MSP, plans d’expériences)\n\nun mode d’emploi sur la manière de les combiner\n\n\nDMAIC (Define, Measure, Analyse, Improve, Control)\n\n\n\nLes \\(6\\sigma\\) résumés\n\n\n\n\nLes \\(6\\sigma\\) en MSP\nToute production a une variabilité naturelle (mesurée par \\(\\sigma\\) pour une loi normale).\n\\(\\leadsto\\) Il faut que cette variabilité naturelle reste dans des limites de variations admissibles autour d’une valeur cible.\n\\(\\leadsto\\) La moyenne de la production doit être proche de la valeur cible.\nOn revient à une production distribuée selon \\(\\mathcal N(100,5)\\) alors \\(6\\sigma=30\\) donc si on a une cible de 100 et des limites de spécifications de 65 et 135 alors le procédé de fabrication est sous-contrôle :\n\n\n\n\n\n\n\n\n\n\n\n% de Faux positifs avec la règle des \\(6\\sigma\\)\n\n\n\nSi on considère que l’échantillon est conforme lorsque sa moyenne appartient à l’intervalle \\([\\mu-3\\frac{\\sigma}{\\sqrt{n}},\\mu+3\\frac{\\sigma}{\\sqrt{n}}]\\) alors on aura 0.3 % d’échantillons déclarés à tord non conformes (faux positifs)."
  },
  {
    "objectID": "index.html#proportions-de-non-conformes",
    "href": "index.html#proportions-de-non-conformes",
    "title": "MSP",
    "section": "Proportions de non-conformes",
    "text": "Proportions de non-conformes\nCompte tenu de la fluctuation d’échantillonage, on est obligé de se fixer un risque de détecter des faux positifs c’est à dire de rejeter des échantillons alors qu’ils sont conformes aux spcifications ou aux exigences du client.\nDans l’exemple précédent on voit que l’on rejetterai à tord un des échantillons !"
  },
  {
    "objectID": "chapitre2.html",
    "href": "chapitre2.html",
    "title": "5  Capabilité, Répétabilité, Reproductivité",
    "section": "",
    "text": "5.1 Capabilité d’un procédé de fabrication :\nDans la suite \\(TS,TI\\) désigneront la tolérance supérieure et inférieure du procédé de fabrication.\nComme précédemment on distingue la variabilité globale du procédé et celle uniquement attribuable à la machine.\nOn définit deux types d’indices de capabilité :\nIl est clair que lorsque \\(Cap&lt;1\\) le procédé n’est pas capable, il faut le revoir afin d’obtenir une production conforme aux tolérances. Par contre si \\(Cap&gt;2\\) on va considérer que le procédé est capable dans la mesure où la dispersion naturelle des observation est 2 fois moins importante que l’intervalle de tolérance.\nLes deux indicateurs précédents ont un gros inconvénient dans la mesure où ils ne permettent pas de juger du décentrage éventuel du procédé. Par exemple, dans le cas d’une loi normale, on peut avoir une situation comme celle ci-dessous :\nOn voit que le procédé est bien dans l’intervalle de tolérance avec une valeur \\(Cap&gt;2\\) mais qu’il est clairement décentré. Donc il faut définir de nouveaux indices de capabilité qui vont permettre de juger de la justesse du procédé !\nIl est clair que l’on a :\nOn utilisera la norme suivante :\nUn procédé (respectivement une machine) est capable si \\(Cpk&gt;1.33\\) (respectivement \\(Cmk&gt;1.33\\))",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Capabilité, Répétabilité, Reproductivité</span>"
    ]
  },
  {
    "objectID": "chapitre2.html#indices-de-capabilité-globale",
    "href": "chapitre2.html#indices-de-capabilité-globale",
    "title": "2  Capabilité",
    "section": "",
    "text": "2.1.1 Définition\nDans la suite \\(TS,TI\\) désigneront la tolérance supérieure et inférieure du procédé de fabrication.\nComme précédemment on distingue la variabilité globale du procédé et celle uniquement attribuable à la machine.\nOn définit deux types d’indices de capabilité :\n\nLa capabilité globale du procédé de fabrication (appelée aussi coefficient d’aptitude du procédé) \\[\nCap=\\frac{TS-TI}{D_G}\n\\]\nLa capabilité machine (appelée aussi coefficient d’aptitude du moyen)\n\n\\[\nCam=\\frac{TS-TI}{D_I}\n\\]\n\n\n2.1.2 Interprétation/ Inconvénient :\nIl est clair que lorsque \\(Cap&lt;1\\) le procédé n’est pas capable, il faut le revoir afin d’obtenir une production conforme aux tolérances. Par contre si \\(Cap&gt;2\\) on va considérer que le procédé est capable dans la mesure où la dispersion naturelle des observation est 2 fois moins importante que l’intervalle de tolérance.\nLes deux indicateurs précédents ont un gros inconvénient dans la mesure où ils ne permettent pas de juger du décentrage éventuel du procédé. Par exemple, dans le cas d’une loi normale, on peut avoir une situation comme celle ci-dessous :\n On voit que le procédé est bien dans l’intervalle de tolérance avec une valeur \\(Cap&gt;2\\) mais qu’il est clairement décentré. Donc il faut définir de nouveaux indices de capabilité qui vont permettre de juger de la justesse du procédé !",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Capabilité</span>"
    ]
  },
  {
    "objectID": "chapitre2.html#indices-de-capabilité-de-centrage",
    "href": "chapitre2.html#indices-de-capabilité-de-centrage",
    "title": "2  Capabilité",
    "section": "2.2 Indices de capabilité de centrage",
    "text": "2.2 Indices de capabilité de centrage\nLe coefficient de performance du procédé est\n\\[\nCpk=\\frac{\\min\\left(\\mu-TI;TS-\\mu\\right)}{3\\sigma_{G}},\n\\]\net celui la machine est\n\\[\nCmk=\\frac{\\min\\left(\\mu-TI;TS-\\mu\\right)}{3\\sigma_{I}}.\n\\]\nIl est clair que l’on a :\n\n\\(Cap&gt;Cpk,\\)\n\\(Cam&gt;Cmk.\\)\n\nOn utilisera la norme suivante :\nUn procédé (respectivement une machine) est capable si \\(Cpk&gt;1.33\\) (respectivement \\(Cmk&gt;1.33\\))\n\n2.2.1 Intervalles de confiance\nLes calculs de \\(Cap\\) et de \\(Cpk\\) sont basés sur des estimations de l’écart type \\(\\sigma_G\\). Dans le cas d’une loi normale on sait construire un intervalle de confiance de \\(\\sigma_G\\), on en déduit que\n\nL’intervalle \\(\\left[\\widehat C_{ap}\\sqrt{\\dfrac{\\chi^2_{n-1}(\\alpha/2)}{n-1}};\\widehat C_{ap}\\sqrt{\\dfrac{\\chi^2_{n-1}(1-\\alpha/2)}{n-1}}\\right]\\) est un intervalle de confiance de \\(Cap\\) au niveau de confiance \\(100(1-\\alpha)\\) %.\nL’intervalle \\(\\left[\\widehat C_{pk}\\left(1-z_{1-\\alpha/2}\\sqrt{\\dfrac{1}{9n\\widehat C_{pk}^2}+\\dfrac{1}{2(n-1)}}\\right);\\widehat C_{pk}\\left( 1+z_{1-\\alpha/2}\\sqrt{\\dfrac{1}{9n\\widehat C_{pk}^2}+\\dfrac{1}{2(n-1)}}\\right)\\right]\\) est un intervalle de confiance de \\(C_{pk}\\) au niveau de confiance \\(100(1-\\alpha)\\) %.\n\nDe même pour \\(C_{am},C_{mk}\\)\n\n\n2.2.2 Fin de l’exemple\nOn suppose que les tolérance sont \\(TI=0.9\\) et \\(TS=1.1\\). En utilisant la fonction capability du package multiSPC calculer les indices de capabilité associés à ce procédé de fabrication.\n\n\nVoir la correction\nlibrary(multiSPC)\ndf&lt;-read.csv(\"cap_data.csv\",sep=\",\")\nmu=mean(df$obs)\nsG=sd(df$obs)\nsI=df|&gt; group_by(sample) |&gt; summarise(S=sd(obs)) |&gt; select(S) |&gt;unlist() |&gt; mean()/c4(5)\ncapability(n=5,mu=mu,sI=sI,sG=sG,TI=0.9,TS=1.1)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Capabilité</span>"
    ]
  },
  {
    "objectID": "chapitre5.html#faux-positifs-et-faux-négatifs",
    "href": "chapitre5.html#faux-positifs-et-faux-négatifs",
    "title": "5  Efficacité des cartes de Shewhart",
    "section": "",
    "text": "Réalité (jamais connue) : dérive (ou non) de la production\nRésultat du contrôle : détection (ou non) d’une dérive de production.\n\n\n\n\n\n\n\n\n\nRéalité\n\n\n\n\n\n\nDéréglage\nNon déréglage\n\n\ncarte de CTRL\nDétection\nVRAI POSITIF\nFAUX POSITIF\n\n\nNon détection\nFAUX NEGATIF\nVRAI NEGATIF\n\n\n\n\n\nLa probabilité d’obtenir un faux positif : 0.3 % (par définition des limites de contrôle)\nLa probabilité d’obtenir un vrai négatif : 99.7% (toujours par construction).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Cartes aux limites modifiées</span>"
    ]
  },
  {
    "objectID": "chapitre4.html#retour-sur-lexemple",
    "href": "chapitre4.html#retour-sur-lexemple",
    "title": "3  Cartes de contrôles de Shewhart",
    "section": "3.3 Retour sur l’exemple :",
    "text": "3.3 Retour sur l’exemple :\n\nCalculer les limites de contrôles des cartes de la moyenne et de l’écart type.\nConstruire les cartes s’obtiennent en utilisant la fonction plot_chart() du package multiSPC.\n\n\n\nVoir la correction\ndf&lt;-data[,-1]\nn=ncol(df)\nM=apply(df,1,mean)\nS=apply(df,1,sd)\nmu=mean(M)\nsigI=mean(S)/c4(n)\nLICm=mu-3*sigI/sqrt(n)\nLSCm=mu+3*sigI/sqrt(n)\nLICs=mean(S)-3*mean(S)*sqrt(1-c4(n)^2)/c4(n)\nLSCs=mean(S)+3*mean(S)*sqrt(1-c4(n)^2)/c4(n)\nplot_chart(M,LIC=LICm,LSC=LSCm,Type = \"carte de la moyenne\")\nplot_chart(S,LIC=LICs,LSC=LSCs,Type = \"carte de l'écart type\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Cartes de contrôles de Shewhart</span>"
    ]
  },
  {
    "objectID": "chapitre1.html#estimation-des-paramètres-globaux-mu_gsigma_g",
    "href": "chapitre1.html#estimation-des-paramètres-globaux-mu_gsigma_g",
    "title": "1  Estimation des paramètres du procédé",
    "section": "1.2 Estimation des paramètres globaux (\\(\\mu_G,\\sigma_G\\))",
    "text": "1.2 Estimation des paramètres globaux (\\(\\mu_G,\\sigma_G\\))\nDans notre exemple précédent on estime la moyenne et l’écart type du procédé à partir des \\(k\\times n\\) observations :\n\n\n\n\n\nOn suppose que les observations suivent une loi normale de moyenne \\(\\mu_G\\) et d’écart type \\(\\sigma_G\\). Cela permet de dire que la proportion théorique de données dans\n\n\\([\\mu_G-\\sigma_G,\\mu+\\sigma_G]\\) est de 68.3 %,\n\\([\\mu_G-2\\sigma_G,\\mu+2\\sigma_G]\\) est de 95.4 %,\n\\([\\mu_G-3\\sigma_G,\\mu+3\\sigma_G]\\) est de 99.7 %.\n\nPour la dispersion globale on choisit \\[D_g=6\\sigma_G.\\]\n\n\n\n\n\n\nEstimation des paramètres de production\n\n\n\nOn prélève \\(k\\) échantillons de même effectif \\(n\\). On note \\(y_{ij}\\) la valeur \\(i=1,...,n\\) de l’échantillon \\(j=1,...,k.\\) Une estimation de \\(\\mu_G\\) est \\[\\hat \\mu_G=\\frac 1{k} \\displaystyle\\sum_{j=1}^k \\bar y_{j},\\] et une estimation de \\(\\sigma_G\\) est \\[\\hat \\sigma_G= \\sqrt{\\frac{\\displaystyle\\sum_{j=1}^k\\sum_{i=1}^n(y_{ij}-\\hat \\mu)^2}{n\\times k-1}}.\\]\n\n\nCalculer dans l’exemple une estimation de la moyenne et de l’écart type global :\n\n\nVoir la correction\nmean(df$obs)\nsd(df$obs)"
  },
  {
    "objectID": "chapitre1.html#estimation-des-paramètres-instantanés-mu_isigma_i",
    "href": "chapitre1.html#estimation-des-paramètres-instantanés-mu_isigma_i",
    "title": "1  Estimation des paramètres du procédé",
    "section": "1.3 Estimation des paramètres instantanés (\\(\\mu_I,\\sigma_I\\)):",
    "text": "1.3 Estimation des paramètres instantanés (\\(\\mu_I,\\sigma_I\\)):\nOn prélève un échantillon à un instant donné (ainsi les variations sont uniquement dues à la machine) et on suppose que les valeurs sont distribuées selon une loi normale de moyenne \\(\\mu_I\\) et d’écart type \\(\\sigma_I.\\) Naturellement, la dispersion instantanée sera définie par \\(D_I=6\\sigma_I.\\)\n\n\n\n\n\nOn voit dans cet exemple que les variations instantanées sont assez fluctuantes (c’est logique puisque pour chaque estimation on ne considère que 5 observations…) .\nRaisonnablement on peut estimer que \\(\\mu_I\\simeq \\mu_G\\), par contre il existe plusieurs estimations possibles de \\(\\sigma_I\\) :\n\nla première est basée sur le calcul des écarts types des \\(k\\) échantillons prélevés.\nla deuxième est basée sur le calcul des étendues des \\(k\\) échantillons prélevés.\n\nPour ces calculs on appliquera des coefficients de correction :\n\nLe coefficient \\(d_2(n)\\) correspond à l’espérance de l’étendue d’une loi normale centrée réduite et\nLe coefficient \\(c_4(n)\\) à l’espérance de l’écart type d’une loi normale centrée réduite.\n\nLes fonctions c4,d2,d3 du package multiSPC permettent d’estimer ces paramètres :\n\nc4(5)\n\n\nOn sait pour chaque échantillon \\(j\\) de \\(n\\) valeurs calculer une estimation de l’écart type \\(\\sigma_j\\) en calculant \\[s_j= \\sqrt{\\frac{\\displaystyle\\sum_{i=1}^n(y_{ij}-\\bar y_j)^2}{n-1}},\\] où \\(\\bar y_j\\) est la moyenne de l’échantillon \\(j.\\)\n\n\n\n\n\n\n\nEstimation à partir des écarts types\n\n\n\nOn considère \\(k\\) prélèvements de taille \\(n\\) dont les écarts types sont \\(s_1,...,s_k,\\) on pose \\(\\bar S =\\frac{\\sum_{j=1}^k s_j}{k}\\). Une estimation de l’écart type instantané \\(\\sigma_M\\) est donné par \\[\n\\hat \\sigma_M=\\dfrac{\\bar S}{c_4(n)}.\n\\]\n\n\n\nPour chaque échantillon \\(j\\) on calcule l’étendue\n\n\\[\nR_j=\\max(y_{ij})-\\min(y_{ij})\n\\]\n\n\n\n\n\n\nEstimation à partir des écarts types\n\n\n\nOn considère \\(k\\) prélèvements de taille \\(n\\) dont les étendues sont \\(R_1,...,R_k,\\) on pose \\(\\bar R =\\frac{\\sum_{j=1}^k R_j}{k}\\). Une estimation de l’écart type instantané \\(\\sigma_M\\) est donné par \\[\n\\hat \\sigma_M=\\dfrac{\\bar R}{d_2(n)}.\n\\]\n\n\nFaire ces deux calculs sur les données de l’exemple précédent.\n\n\nVoir la correction\n# Estimation à partir des écarts types\ntab&lt;-df %&gt;% group_by(sample) %&gt;% summarise(\"s_j\"=round(sd(obs),5)) \nmean(tab$\"s_j\")/c4(5)\n\n# Estimation à partir des étendues\netendue&lt;-function(X){return(max(X)-min(X))}\ntab2&lt;-df %&gt;% group_by(sample)%&gt;% summarise(\"R_j\"=etendue(obs))\nmean(tab2$\"R_j\")/d2(5)\n\n\nEt alors on obtient :"
  },
  {
    "objectID": "chapitre4.html#estimation-des-limites-de-contrôle-pour-la-carte-des-écarts-types",
    "href": "chapitre4.html#estimation-des-limites-de-contrôle-pour-la-carte-des-écarts-types",
    "title": "4  Cartes de contrôles de Shewhart",
    "section": "4.5 Estimation des limites de contrôle pour la carte des écarts types",
    "text": "4.5 Estimation des limites de contrôle pour la carte des écarts types\nPour l’estimation de \\(\\mu_S\\) on prend \\(\\hat\\mu_S=\\bar S\\), et pour l’estimation de \\(\\sigma_S\\) on prend \\(\\hat \\sigma_S=\\frac{\\sqrt{1-c_4^2}}{c_4}\\bar S\\). On a alors :\n\\[\n\\begin{cases}\n\\widehat{LIC}= \\overline{S}-3\\frac{\\sqrt{1-c_4^2}}{c_4}\\overline S \\\\\n\\widehat{LSC}= \\overline{S}+3\\frac{\\sqrt{1-c_4^2}}{c_4}\\overline S\n\\end{cases}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cartes de contrôles de Shewhart</span>"
    ]
  },
  {
    "objectID": "chapitre4.html#efficacité-des-cartes-de-shewhart",
    "href": "chapitre4.html#efficacité-des-cartes-de-shewhart",
    "title": "3  Cartes de contrôles de Shewhart",
    "section": "3.4 Efficacité des cartes de Shewhart",
    "text": "3.4 Efficacité des cartes de Shewhart\nLa notion d’efficacité d’une carte de contrôle est sa capacité à détecter un dérèglement alors que la production semble rester sous contrôle.\nLe dérèglement peut concerner un décentrage (dérèglement de la moyenne) ou bien une augmentation de la dispersion.\nLa notion d’efficacité est proche de la notion de puissance pour les tests statistiques.\n\n3.4.1 Faux positifs et Faux négatifs\nOn va traduire dans le contexte de la MSP les notions vues sur les tests.\n\nRéalité (jamais connue) : dérive (ou non) de la production\nRésultat du contrôle : détection (ou non) d’une dérive de production.\n\nCeci conduit à deux types d’erreurs\n\n\n\n\n\n\n\nRéalité\n\n\n\n\n\n\nDéréglage\nNon déréglage\n\n\ncarte de CTRL\nDétection\nVRAI POSITIF\nFAUX POSITIF\n\n\nNon détection\nFAUX NEGATIF\nVRAI NEGATIF\n\n\n\nCe que l’on connait (par construction de la carte de contrôle) :\n\nLa probabilité d’obtenir un faux positif : 0.3 % (par définition des limites de contrôle)\nLa probabilité d’obtenir un vrai négatif : 99.7% (toujours par construction).\n\nCe que l’on cherche :\nLa probabilité \\(\\beta\\) d’obtenir un faux négatif ou de manière équivalente la probabilité \\(1-\\beta\\) d’obtenir un vrai positif (appelée puissance du test).\n\n\n3.4.2 Déréglage de la moyenne\n Un décentrage de moyenne est exprimé en nombre d’écart type (unité standardisé) donc si \\(\\mu_1\\) est la moyenne décentrée, on lui associera le décentrage\n\\[\n\\rho=\\frac{|\\mu_1-\\mu|}{\\sigma}\n\\]\nLa probabilité \\(\\beta\\) de ne pas détecter le décentrage est alors\n\\[\n\\beta=\\mathbb P(LIC&lt;\\widetilde X &lt;LSC)\n\\]\noù \\(\\widetilde X \\sim \\mathcal N(\\mu+\\rho\\sigma,\\frac{\\sigma}{\\sqrt{n}}).\\) Un calcul simple permet d’obtenir\n\\[\n\\beta = F(3-\\rho\\sqrt n)-F(-3-\\rho\\sqrt n)\n\\]\noù \\(F(x)=\\mathbb P(X&lt;x)\\) est la fonction de répartition de la loi normale.\nL’efficacité de la carte est mesurée par \\(1-\\beta\\) ( puissance de la carte).\nOn obtient ainsi les courbes d’efficacité de la carte de la moyenne en fonction de la taille \\(n\\) des échantillons prélevés.\n\n\n\n\n\n\n\n\n\n\nOn constate (ce qui est logique) que la probabilité de ne pas détecter un déréglage donné diminue en fonction de la taille de l’échantillon.\nDétecter un déréglage \\(\\rho=0\\) correspond à une fausse alerte qui vaut pour la carte de la moyenne \\(\\alpha=0.3\\%\\).\n\n\n\n3.4.3 Déréglage de l’écart type\nIci on considère des décentrages \\(\\rho&gt;1\\) (sinon il s’agit d’une amélioration de la dispersion).\nUn calcul similaire au précédent conduit à \\[\n\\beta=F(\\frac{3}{\\rho})-F(\\frac{-3}{\\rho})\n\\] Ici on constate que l’efficacité de la carte est indépendante de \\(n\\) et qu’elle est très mauvaise. Il faut une très grande valeur de \\(\\rho\\) pour avoir une petite valeur de \\(\\beta\\).\nPar exemple pour \\(\\rho=3\\) on a \\(\\beta=\\) 0.6826895 c’est à dire pour un écart type qui triplerait la probabilité ne peut pas détecter ce dérèglement est de 68.3%.\n\n\n3.4.4 Période opérationelle moyenne (Average Run Length)\nLa Période Opérationnelle Moyenne correspond au nombre de prélèvements qu’il faut effectuer, en moyenne, pour sortir des limites de contrôle lorsque qu’un déréglage \\(\\rho\\) s’est produit.\nLe cas \\(\\rho=0\\) pour une carte de Shewhart avec des observations indépendantes correspond à une fausse alerte qui se produit dans \\(\\alpha=0.3\\%\\) et correspond à\n\\[\nARL_0=\\frac{1}{0.003}=333\n\\] donc il faut en moyenne 334 prélèvements avant de détecter une fausse alerte.\n\\(ARL\\) est définie par\n\\[\nARL_\\rho=\\frac 1{1-\\beta}\n\\]\nC’est donc l’inverse de la puissance (efficacité) de la carte, donc plus ce nombre sera petit plus la carte sera efficace.\nSi on reprend les courbes d’efficacité précédente on obtient :\n\n\n\n\n\n\n\n\n\n\n\n3.4.5 Calibration des tailles de prélèvement\nLa production initiale est \\(X\\sim \\mathcal N (\\mu,\\sigma)\\) et la production décentrée vaut \\(\\widetilde X \\sim \\mathcal N (\\mu+\\rho\\sigma,\\sigma)\\). On sait calculer la probabilité \\(1-\\beta\\) de détecter le décentrage en fonction de \\(\\rho\\) et on a donc\n\\[\nARL_\\rho=\\frac 1{1-\\beta}=\\frac 1{1-F(3-\\rho\\sqrt n)+F(-3-\\rho\\sqrt n)}\n\\]\nExemple :\nConsidérons le problème suivant : on a un décentrage de moyenne de 0.5 écart type. On voudrait le détecter en moyenne avant 50 prélèvements. Quelle taille d’échantillon doit-on considérer ?\n\nn&lt;-seq(2,20,by=1)\nrho&lt;-.5\nbeta=pnorm(3-rho*sqrt(n))-pnorm(-3-rho*sqrt(n))\nARL&lt;-1/(1-beta)\nJ&lt;-which.max(ARL&lt;50)\nn[J]\n\n[1] 4",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Cartes de contrôles de Shewhart</span>"
    ]
  },
  {
    "objectID": "exercice.html",
    "href": "exercice.html",
    "title": "6  Exercice",
    "section": "",
    "text": "7 Deuxième travail approche multivariée pour la construction des limites (15 premiers prélèvements)\nOn va construire deux cartes de contrôle multivariée sur les 15 premières observations afin de calculer les limites de contrôle qui seront utilisées pour les prélèvements en routine (25 dans notre cas).\nFonction Moy_X() dans le package multiSPC.\nPour les 25 derniers prélèvements :\nConclure sur l’ensemble des résultats et interpréter les différences de résultats obtenus dans les différentes approches."
  },
  {
    "objectID": "exercice.html#premier-travail-cartes-univariées",
    "href": "exercice.html#premier-travail-cartes-univariées",
    "title": "6  Exercice",
    "section": "6.1 Premier travail : cartes univariées",
    "text": "6.1 Premier travail : cartes univariées\n\nCalculer les limites des cartes sur les 15 premiers points :\n\n\nlibrary(multiSPC)\nload(\"X.rda\")\ndim(X)\n\n[1] 40  5  6\n\nX1=X[1:15,,]\nk1=dim(X1)[1]\np=dim(X1)[2]\nn=dim(X1)[3]\n# Pour sélectionner les 15 prélèvements de 6 observations pour la variable 1  \nX1[,1,]\n\n             obs 1    obs 2    obs 3    obs 4    obs 5    obs 6\nprelev 1  23.76246 23.40527 24.91360 25.41634 23.29637 24.98259\nprelev 2  26.47183 24.34791 26.39461 25.38975 24.20868 26.16872\nprelev 3  26.04362 25.19139 26.07489 25.45882 24.60888 24.62398\nprelev 4  25.10706 25.88083 23.70325 25.34959 23.48259 24.90549\nprelev 5  23.61300 23.54233 23.70711 27.18749 24.50389 25.03395\nprelev 6  24.72257 24.19010 24.89519 23.95908 25.47115 23.40282\nprelev 7  23.28691 24.56824 24.92739 24.70540 26.37064 24.77298\nprelev 8  26.08343 24.47033 24.36704 24.87880 26.08653 25.58326\nprelev 9  26.18530 24.89157 23.66520 25.22682 24.76154 25.53291\nprelev 10 23.52080 23.79163 26.13552 25.10471 24.63480 24.22959\nprelev 11 24.58895 24.62262 25.59954 24.86031 24.57686 25.86795\nprelev 12 25.40909 25.26060 24.08024 25.38977 25.34972 25.00771\nprelev 13 24.43261 24.24110 24.86680 24.02565 24.87711 24.29757\nprelev 14 23.78666 24.80767 25.89863 24.23327 25.45326 24.78892\nprelev 15 24.43656 24.63109 25.67316 24.21859 25.62118 24.29264\n\n\nQue peut-on en déduire ?\n\nAppliquer les limites de contrôles sur les 25 autres prélèvements et interpréter les résultats."
  },
  {
    "objectID": "chapitre7.html",
    "href": "chapitre7.html",
    "title": "4  Cartes multivariées",
    "section": "",
    "text": "4.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cartes multivariées</span>"
    ]
  },
  {
    "objectID": "chapitre7.html#introduction",
    "href": "chapitre7.html#introduction",
    "title": "5  Cartes multivariées",
    "section": "5.1 Introduction",
    "text": "5.1 Introduction\n\nCours précédent : une caractéristique \\(X\\) de la production suivie au cours du temps par carte de la moyenne de Shewhart et carte EWMA\nCe cours : plusieurs variables \\(X_1,...,X_p\\) caractérisant la production. Il existe toujours des liens entre ces variables donc faire des cartes univariées n’est pas optimal."
  },
  {
    "objectID": "chapitre7.html#exemple",
    "href": "chapitre7.html#exemple",
    "title": "5  Cartes multivariées",
    "section": "5.2 Exemple :",
    "text": "5.2 Exemple :\nAu cours du processus de fabrication d’un tube en fibre de carbone spécifique, trois caractéristiques qualitatives corrélées sont mesurées : le diamètre intérieur, l’épaisseur et la longueur du tube. Ici les données sont sous la forme d’une matrice à trois dimensions.\n\n\n\n\n\n\nNotation\n\n\n\nOn note \\[X=[x_{tji}]_{tji}\\] le tableau de données à trois dimensions avec :\n\n\\(t\\) numéro du prélèvement (\\(t=1,...,k\\)),\n\\(j\\) est l’indice de la variable (\\(j=1,...,p\\)) et\n\\(i\\) le numéro de l’observation (\\(i=1,...,n\\)).\n\n\n\nSur les données précédentes :\n\ndata(\"carbon1\")\nclass(carbon1)\n\n[1] \"array\"\n\ndim(carbon1)\n\n[1] 30  3  8\n\n\nIci on a donc 30 prélèvements de 8 unités sur 3 variables. Si on replie la troisème dimension en calculant les moyennes de chaque prélèvement sur chaque caractéristique on obtient donc une matrice \\((k,p)\\) dont les éléments sont les moyennes.\n\nOn peut tracer le graphe de corrélation des 30 moyennes de \\(X=(X_1,X_2,X_3)\\) :\n\nM=Moy_X(carbon1)\nggpairs(M)\n\nWarning in geom_point(): All aesthetics have length 1, but the data has 9 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\nOn en déduit que les corrélations entre les trois caractéristiques sont fortes et significatives."
  },
  {
    "objectID": "chapitre7.html#notations",
    "href": "chapitre7.html#notations",
    "title": "5  Cartes multivariées",
    "section": "5.3 Notations",
    "text": "5.3 Notations\n\nLes données sont dans une matrice à trois dimensions.\nOn replie la troisème dimension en calculant les moyennes de chaque prélèvement sur chaque caractéristique on obtient donc une matrice \\((k,p)\\) dont les éléments sont les moyennes.\n\n\nOn peut tracer le graphe de corrélation des 30 moyennes de \\(X=(X_1,X_2,X_3)\\) :\n\nM=Moy_X(carbon1)\nggpairs(M)\n\nWarning in geom_point(): All aesthetics have length 1, but the data has 9 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\nOn en déduit que les corrélations entre les trois caractéristiques sont fortes et significatives."
  },
  {
    "objectID": "chapitre7.html#matrice-de-covariance",
    "href": "chapitre7.html#matrice-de-covariance",
    "title": "5  Cartes multivariées",
    "section": "5.3 Matrice de covariance",
    "text": "5.3 Matrice de covariance\n\nSoit \\(X,Y\\) deux variables aléatoires réelles, la covariance \\(\\sigma_{X,Y}=\\mathbb E \\left([X-\\mathbb E(X)][Y-\\mathbb E(Y)] \\right)\\). On a \\(\\sigma_{X,X}=\\sigma^2_X\\) (variance de X).\nSi les variables \\(X,Y\\) sont indépendantes alors \\(\\sigma_{X,Y}=0\\). (réciproque fausse)\nSoit \\((X_1,...,X_p)\\) des variables aléatoires réelles. On appelle matrice de covariance la matrice \\[\\Sigma=[\\sigma_{ij}]_{i,j=1,...,p}.\\]\n\nOn peut aussi écrire cette matrice sous forme vectorielle. Soit \\(X=(X_1,...,X_p)\\) la vecteur aléatoire alors \\[\\Sigma=\\mathbb E \\left([X-\\mathbb E(X)].[X-\\mathbb E(X)]^T \\right).\\]\n\n\n\n\n\n\nPropriétés de \\(\\Sigma\\)\n\n\n\n\n\\(\\Sigma\\) est symétrique donc elle est diagonalisable.\n\\(\\Sigma\\) est semi-définie positive, c’est à dire que ses valeurs propres \\(\\lambda_1,...\\lambda_p\\) sont postives ou nulles.\n\\(\\Sigma\\) est définie positive (vp strictement positives) si il n’existe aucune relation affine entre les variables \\((X_1,...,X_p)\\). Dans ce cas \\(\\Sigma\\) est inversible, c’est à dire qu’il existe une matrice notée \\(\\Sigma^{-1}\\) telle que \\[\\Sigma^{-1}.\\Sigma=\\Sigma.\\Sigma^{-1}=I_p\\]\n\n\n\nIl faut estimer cette matrice à partir de la matrice des données \\(x_{tji}\\) : il s’agit de la moyenne des covariances empiriques des \\(k\\) prélèvements.\n\n\n\n\n\n\nEstimation de \\(\\Sigma\\)\n\n\n\nPour \\(t=1,...,k\\) on calcule la covariance \\(S_t\\) de la matrice \\((X_{tji})_{ji}\\) et on choisit \\[\\hat\\Sigma\\simeq\\frac1{k}\\sum_{t=1}^kS_t.\\]\n\n\nLa fonction covariance_X du package multiSPC permet de réaliser ce calcul.\n\ncovariance_X(carbon1)\n\n                inner   thickness      length\ninner     0.002486845 0.003586726 0.006694762\nthickness 0.003586726 0.014491131 0.010203155\nlength    0.006694762 0.010203155 0.059207381\n\n\nRemarque : La corrélation est la covariance des variables standardisées."
  },
  {
    "objectID": "chapitre7.html#la-distribution-normale-multivariée",
    "href": "chapitre7.html#la-distribution-normale-multivariée",
    "title": "5  Cartes multivariées",
    "section": "5.4 La distribution normale multivariée}",
    "text": "5.4 La distribution normale multivariée}\nLa densité de probabilité de \\(X\\sim \\mathcal N(\\mu,\\sigma)\\) est pour \\(x\\in \\mathbb R\\) \\[f(x)=\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac1{2}[\\sigma^{-1}(x-\\mu)]^2}.\\]\nExemple : \\(\\mu=0,\\sigma=1\\), \\(\\varphi(x)=\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac1{2}x^2}.\\)\nOn a \\(\\varphi(0)=\\) 0.4 et \\(\\varphi(2)=\\) 0.1\n\n\n\n\n\nLa densité de probabilité de \\((X_1,...,X_p)\\sim \\mathcal N_p(\\mu,\\Sigma)\\) est pour \\(x=(x_1,...,x_p)\\in \\mathbb R^p\\) \\[f_p(x)=\\frac{1}{|\\Sigma|^{-1/2}\\sqrt{2\\pi}}e^{-\\frac1{2}[(x-\\mu)^T\\Sigma^{-1}(x-\\mu)]}.\\]\n\n\n\nLoi Normale bivariée\n\n\n\nLa loi normale ci-dessus a pour paramètres \\(\\mu=\\begin{pmatrix}0\\\\0 \\end{pmatrix}\\) et \\(\\Sigma=\\begin{pmatrix} 1 & 0.5 \\\\ 0.5 & 1 \\end{pmatrix}\\).\nTout plan vertical passant par \\((0,0)\\) donne une loi normale centrée."
  },
  {
    "objectID": "chapitre7.html#cartes-de-contrôles-t2-hotelling",
    "href": "chapitre7.html#cartes-de-contrôles-t2-hotelling",
    "title": "5  Cartes multivariées",
    "section": "5.5 Cartes de contrôles \\(T^2\\) Hotelling",
    "text": "5.5 Cartes de contrôles \\(T^2\\) Hotelling\n\n5.5.1 Généralités\n\nLe vecteur des caractéristiques \\(X=(X_1,...,X_p)\\sim \\mathcal N_p(\\mu,\\Sigma).\\)\nPour un prélèvement \\(t\\), \\(\\bar X_{t}=(\\bar X_{t1},...,\\bar X_{tp})\\) avec \\(X_{t}=\\) i.i.d. de même loi que \\(X\\).\n\\(T_t^2\\) de Hotelling est défini par \\[T_t^2=(\\bar X_t-\\mu)^T.\\Sigma^{-1}.(\\bar X_t-\\mu).\\]\nEn pratique les paramètres \\(\\mu,\\Sigma\\) inconnus et approximés par \\(\\overline X\\) et \\(\\hat \\Sigma\\) (cf paragraphe précédent).\nApproximation de \\(T_t^2\\) donnée par \\[\n\\hat T_t^2=(\\bar X_t-\\overline{X})^T.\\hat \\Sigma^{-1}.(\\bar X_t-\\overline{X}).\n\\] La statistique \\(\\hat T_t^2\\) suit une loi de Fisher à \\((p,kn-k-p+1)\\) degrés de liberté.\n\n\n\n\n\n\n\nQuelques remarques\n\n\n\n\nLa statistique de Hotelling est une généralisation du \\(t\\) de Student. En effet pour \\(p=1\\) on retrouve la formule \\(T^2=t^2\\).\n\\(T_t^2\\) donne une mesure de l’éloignement de la moyenne d’un prélèvement \\(t\\) par rapport à la moyenne de la production (en multidimensionnel) donc c’est une généralisation de la carte de Shewart de la moyenne.\nComme les cartes de Shewhart elles vont permettre de détecter des grandes déviations de moyenne.\nConstruire une carte basée sur le \\(T^2\\) est alors possible dans la mesure où c’est un indicateur univarié (réel).\n\n\n\nLa moyenne empirique \\(\\overline X\\) est égale à\n\nMoy_T(carbon1)\n\n     inner  thickness     length \n 0.9949583  1.0372083 49.9843333 \n\n\nSur R :\n\nT2=T2_Hotelling_kn(data = carbon1)\nprint(T2)\n\n [1] 4.98848636 4.65756465 3.27858449 1.93129021 5.61700024 4.63924111\n [7] 5.50056763 0.86557296 2.87376790 0.48616297 2.39585925 1.98317510\n[13] 2.36109313 0.96030773 0.35242206 0.22362835 0.05247532 0.86290231\n[19] 3.42953651 1.08381086 0.45175392 2.73538851 9.43218347 2.92725106\n[25] 0.46222199 1.33752988 3.38986615 1.96857745 3.53540827 1.40366439\n\n\n\n\n5.5.2 Construction de la carte :\n\nPour la phase I (construction de la carte de Hotelling) on pose : \\[LSC=\\frac{p(k-1)(n-1)}{kn-k-p+1}F_{(p,kn-k-p+1)}(1-\\alpha).\\]\nPour la phase II (futures observations,[!] \\(k\\) est le nombre de prélèvements de la phase I) on pose : \\[LSC=\\frac{p(k+1)(n-1)}{kn-k-p+1}F_{(p,kn-k-p+1)}(1-\\alpha).\\]\n\n\nk=dim(carbon1)[1]\nLSCT2=LSC_T2_Hotelling_kn(carbon1)\nprint(LSCT2)\n\n  PhaseI  PhaseII \n11.35182 12.13470 \n\n\nCe qui donne la carte suivante (sur les données ayant permis de calculer LSC) :\n\nplot_chart(T2,LSC=LSCT2[\"PhaseI\"],Type=\"Carte du T2\")\n\n\n\n\n\n\n5.5.3 Application des limites de contrôle (Phase II)\n\ndata(\"carbon2\")\nT2=T2_Hotelling_kn(carbon2,\n                      MoyT =Moy_T(carbon1),\n                      S=covariance_X(carbon1))\nplot_chart(T2,LSC=LSCT2[\"PhaseII\"],Type=\"Carte T2 de Hotelling\")\n\n\n\n\nOn a prélevé 25 nouveaux échantillons et on identifie un point hors-contrôle (4ième prélèvement).\n\nPour les caractéristiques univariées, lorsqu’un point est hors des limites de contrôles, il est évident que le procédé a eu une déviation non aléatoire.\nPour les caractéristiques multivariées, il est nécessaire d’identifier laquelle (lesquelles) des caractéristiques a (ont) eu une déviation non aléatoire.\n\n\n\n\n\n\n\nMYT décomposition\n\n\n\nOn considère qu’un prélèvement \\(t\\) est hors-contrôle, on note \\(\\textbf{X}_t=(X_{tji})_{1\\leq j\\leq p;1\\leq i\\leq n}\\) la matrice des caractéristique de ce prélèvement. On note \\(\\bar{\\textbf{X}}_t=(\\bar{X}^{(t)}_{1},...,\\bar{X}^{(t)}_{p})\\) le vecteur des moyennes de ces caractéristiques.\n\nEtape 1 : Contribution individuelle. Calculer \\[t^2_{j}=\\frac{n(\\bar{X}^{(t)}_{j}-\\overline{ X}_j)^2}{s_j^2}\\] pour chaque variable \\(j\\) où \\(s_j^2\\) est la variance de la caractéristique \\(X^{(t)}_j\\). Calculer pour \\(p=1\\), Exclure les variables \\(j\\) qui vérifient \\(t^2_j&gt;LSC,\\) où \\(LSC=\\frac{(k+1)(k-1)}{k(k-1)}F_{(p,k-1)}(1-\\alpha).\\)\n\n\n\nEtape 2 : Contribution bivariée. On retire toutes variables identifiées à l’étape 1. On note \\(J\\) les indices des variables restantes. Pour \\(j,j'\\in J\\), calculer \\(T_{jj'}^2\\) correspondant aux colonnes \\(j,j'\\) de la matrice \\(\\textbf{X}_t\\).\nExclure les variables \\(j,j'\\) qui vérifient \\(T^2_{jj'}&gt;LSC,\\) où \\(LSC=\\frac{p(k+1)(k-1)}{k(k-p)}F_{(p,k-p)}(1-\\alpha),\\) pour \\(p=2.\\)\nOn itère les étapes précédentes jusqu’au modèle qui contient toutes les variables restantes.\n\n\n\nRetour sur l’exemple :\n\np=dim(carbon2)[2]\nk=dim(carbon2)[1]\nT2j=NULL\nfor(j in 1:p) T2j=c(T2j,T2_Hotelling_kn_MYT(k_hc=4,k=k,select=j,data=carbon2,MoyT=Moy_T(carbon1))$T2)\n\n## Valeurs des t2j :\nT2j \n\n    inner thickness    length \n 4.795952 12.259130  3.416894 \n\n## Valeur de la LSC :\nT2_Hotelling_kn_MYT(k_hc=4,k=k,select=1,data=carbon2,MoyT=Moy_T(carbon1))$LSC\n\n[1] 8.135785\n\n\nLa variable tickness est donc exclue car sa valeur de \\(t^2\\) est supérieure à \\(LSC\\).\n\nT2_Hotelling_kn_MYT(k_hc=4,k=k,select=c(1,3),data=carbon2,MoyT=Moy_T(carbon1))\n\n$T2\n         [,1]\n[1,] 6.888749\n\n$LSC\n[1] 12.29269\n\n\nDonc cette valeur n’est pas HC sur les deux autres variables."
  },
  {
    "objectID": "chapitre7.html#phase-ii-points-hors-contrôle",
    "href": "chapitre7.html#phase-ii-points-hors-contrôle",
    "title": "4  Cartes multivariées",
    "section": "5.1 Phase II : points hors contrôle",
    "text": "5.1 Phase II : points hors contrôle\n\nPour les caractéristiques univariées, lorsqu’un point est hors des limites de contrôles, il est évident que le procédé a eu une déviation non aléatoire.\nPour les caractéristiques multivariées, il est nécessaire d’identifier laquelle (lesquelles) a (ont) eu une déviation non aléatoire.\n\n\n\n\n\n\n\nMYT décomposition\n\n\n\nOn considère un prélèvement \\(t\\) Hors Contrôle, on note \\(\\mathcal{X}=(X_{tji})_{ji}\\) la matrice des caractéristique de ce prélèvement. On note \\(\\bar{\\mathcal{X}}=(\\bar{\\mathcal {X}}_1,...,\\bar{\\mathcal{X}}_p)\\) le vecteur des moyennes de ces caractéristiques.\n\nEtape 1 : Contribution individuelle.\n\n\nCalculer \\(T^2_{j}=\\frac{n(\\bar{\\mathcal {X}}_j-\\overline{\\overline X}_j)^2}{s_j^2}\\) pour chaque variable \\(j\\) où \\(s_j^2\\) est la variance de la caractéristique \\(\\bar{\\mathcal {X}}_j\\).\nCalculer pour \\(p=1\\), \\(LSC=\\frac{p(k+1)(k-1)}{k(k-p)}F_{(p,k-p)}(1-\\alpha).\\)\nExclure les variables \\(j\\) qui vérifient \\(T^2_j&gt;LSC.\\)\n\n\nEtape 2 : Contribution bivariée. On retire toutes variables identifiées à l’étape 1. On note \\(J\\) les indices des variables restantes\n\n\nPour \\(j,j'\\in J\\), calculer \\(T_{jj'}^2\\) correspondant aux colonnes \\(j,j'\\) de la matrice \\(\\mathcal{X}\\).\nCalculer pour \\(p=2\\), \\(LSC=\\frac{p(k+1)(k-1)}{k(k-p)}F_{(p,k-p)}(1-\\alpha).\\)\nExclure les variables \\(j,j'\\) qui vérifient \\(T^2_{jj'}&gt;LSC.\\) On itère les étapes précédentes jusqu’au modèle qui contient toutes les variables restantes.\n\n\n\nRetour sur l’exemple :\n\np=dim(carbon2)[2]\nk=dim(carbon2)[1]\nT2j=NULL\nfor(j in 1:p) T2j=c(T2j,T2_Hotelling_kn_MYT(k_hc=4,k=k,select=j,\n                                            data=carbon2,MoyT=Moy_T(carbon1))$T2)\nT2j \n\n    inner thickness    length \n 4.795952 12.259130  3.416894 \n\nT2_Hotelling_kn_MYT(k_hc=4,k=k,select=1,data=carbon2,MoyT=Moy_T(carbon1))$LSC\n\n[1] 8.135785\n\n\nLa variable tickness est donc exclue.\n\nT2_Hotelling_kn_MYT(k_hc=4,k=k,select=c(1,3),data=carbon2,MoyT=Moy_T(carbon1))\n\n$T2\n         [,1]\n[1,] 6.888749\n\n$LSC\n[1] 12.29269\n\n\nDonc cette valeur n’est pas HC sur les deux autres variables.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cartes multivariées</span>"
    ]
  },
  {
    "objectID": "chapitre7.html#etape-2",
    "href": "chapitre7.html#etape-2",
    "title": "4  Cartes multivariées",
    "section": "5.2 Etape 2 :",
    "text": "5.2 Etape 2 :\n\nT2_Hotelling_kn_MYT(k_hc=4,k=k,select=c(1,3),data=carbon2,MoyT=Moy_T(carbon1))\n\n$T2\n         [,1]\n[1,] 6.888749\n\n$LSC\n[1] 12.29269\n\n\nDonc cette valeur n’est pas HC sur les deux autres variables.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cartes multivariées</span>"
    ]
  },
  {
    "objectID": "chapitre7.html#exemple-1",
    "href": "chapitre7.html#exemple-1",
    "title": "4  Cartes multivariées",
    "section": "5.4 Exemple :",
    "text": "5.4 Exemple :\nOn considère des données contenant des mesures de la déviation, de la courbure, de la résistivité et de la dureté dans les côtés à faible et forte dilatation des thermostats bimétalliques en laiton et en acier.\n\ndata(\"bimetal1\")\nhead(bimetal1)\n\n     deflection curvature resistivity Hardness low side Hardness high side\n[1,]      20.84     39.84       14.98             21.88              25.87\n[2,]      20.89     39.94       14.91             22.03              25.97\n[3,]      21.13     40.12       15.58             22.13              26.11\n[4,]      20.42     39.78       14.73             21.46              25.74\n[5,]      21.29     40.31       15.56             22.65              26.22\n[6,]      21.08     39.98       15.19             22.22              25.91\n\n\nOn peut représenter les corrélations des caractéristiques :\n\nggpairs(bimetal1)\n\n\n\n\n\n\n\n\nCi dessous la carte de contrôle dans R pour la phase I :\n\nT2=T2_Hotelling_k1(bimetal1)\nLSCT2=LSC_T2_Hotelling_k1(bimetal1)\nplot_chart(T2,LSC=LSCT2[\"PhaseI\"],Type=\"T2 individuel Phase I\") \n\n\n\n\n\n\n\nT2=T2_Hotelling_k1(bimetal1[-c(16,20),])\nLSCT2=LSC_T2_Hotelling_k1(bimetal1[-c(16,20),])\nplot_chart(T2,LSC=LSCT2[\"PhaseI\"],Type=\"T2 individuel Phase I\") \n\n\n\n\n\n\n\n\nOn utilise les données bimetal2.\n\ndata(\"bimetal2\")\n\nT2=T2_Hotelling_k1(bimetal2,\n                      MoyT = Moy_T(bimetal1),\n                      S=covariance_X(bimetal1))\nplot_chart(T2,LSC=LSCT2[\"PhaseII\"],Type=\"T2 individuel Phase II\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cartes multivariées</span>"
    ]
  },
  {
    "objectID": "chapitre7.html#carte-sur-la-variance-généralisée",
    "href": "chapitre7.html#carte-sur-la-variance-généralisée",
    "title": "5  Cartes multivariées",
    "section": "5.7 Carte sur la variance généralisée",
    "text": "5.7 Carte sur la variance généralisée\n\nPour \\(X\\sim\\mathcal N_p(\\mu,\\Sigma)\\), la variance généralisée est définie comme le déterminant de la matrice de covariance \\(\\Sigma\\). Pour le prélèvement \\(t\\) on calcule \\[D_t=\\text{det}(\\Sigma_t).\\]\nComme précédemment la matrice \\(\\Sigma\\) est inconnue et donc elle est approximée à partir de \\(S\\).\n\n\nS=generalized_variance(carbon1)\nplot_chart(S$detSj,LIC=S$LIC,LSC=S$LSC,Type=\"Carte de la variance généralisée.\")"
  },
  {
    "objectID": "chapitre7.html#cartes-mewma",
    "href": "chapitre7.html#cartes-mewma",
    "title": "5  Cartes multivariées",
    "section": "5.8 Cartes MEWMA",
    "text": "5.8 Cartes MEWMA\n\nLes cartes \\(T^2\\) permettent comme les cartes de Shewart de détecter des fortes déviations mais ne permettent pas de détecter des faibles tendances à la hausse (ou bien à la baisse) de la moyenne du procédé.\nOn généralise les cartes EWMA à \\(p\\) variables. Etant données les \\(k\\) moyennes \\((\\bar X_1,..,\\bar X_k)\\) où \\(\\bar X_t\\in \\mathbb R^p\\), on calcule \\[Z_t=\\lambda \\bar X_t+(1-\\lambda)Z_{t-1},\\] pour \\(0&lt;\\lambda&lt;1.\\) En pratique on choisit souvent \\(\\lambda=0.1\\).\n\nCalcul de \\(T^2\\) :\n\nLa valeur de \\(T_t^2\\) est \\[T^2_t=(Z_t-\\bar Z)^T.\\Sigma_t .(Z_t-\\bar Z),\\] où \\(\\Sigma_t=\\dfrac{\\lambda[1-(1-\\lambda)^{2t}]}{2-\\lambda}\\Sigma.\\)\nComme précédemment on prend \\(\\hat \\Sigma \\simeq S\\).\nLe calcul de \\(LSC\\) est dans ce cas complexe\n\n\nlibrary(spc)\nLSC=mewma.crit(l=0.1, L0=200, p=3, hs=0, r=20)\n\nOn peut construire la carte MEWMA dans l’exemple sur le carbone :\n\ndata(\"carbon1\")\nT2=T2_MEWMA_kn(carbon1)\nplot_chart(T2,LSC=LSC,Type=\"Carte MEWMA\")\n\n\n\n\nOn peut aussi considérer des cartes MEWMA à données individuelles :\n\nT2=T2_MEWMA_k1(bimetal1)\nLSC=mewma.crit(l=0.1, L0=200, p=p, hs=0, r=20)\nplot_chart(T2,LSC=LSC,Type=\"Carte MEWMA\")"
  },
  {
    "objectID": "chapitre7.html#retour-sur-lexemple-carbon-1",
    "href": "chapitre7.html#retour-sur-lexemple-carbon-1",
    "title": "4  Cartes multivariées",
    "section": "5.7 Retour sur l’exemple carbon 1",
    "text": "5.7 Retour sur l’exemple carbon 1\n\ndata(\"carbon1\")\nresT2=T2_MEWMA_kn(carbon1)\nk=dim(carbon1)[1]\nggplot(data.frame(t=1:k,T2=resT2),aes(x=factor(t),y=T2))+\n  geom_point()+\n  geom_line(aes(x=t,y=T2))+\n  geom_hline(yintercept=LSC,linetype=\"dashed\",col=\"red\")+\n  geom_label(aes(x=t[k]-0.5,y=LSC,label=\"LSC\"),col=\"red\")+\n  labs(\n    x=\"prélèvement\",\n    y=\"Moyennes\",\n    title=\"Carte T^2 de Hotelling de la moyenne\"\n  )+\n  theme_minimal()\n\nWarning in geom_label(aes(x = t[k] - 0.5, y = LSC, label = \"LSC\"), col = \"red\"): All aesthetics have length 1, but the data has 30 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cartes multivariées</span>"
    ]
  },
  {
    "objectID": "chapitre7.html#t2-de-hotelling-pour-prélèvement-individuel",
    "href": "chapitre7.html#t2-de-hotelling-pour-prélèvement-individuel",
    "title": "5  Cartes multivariées",
    "section": "5.6 \\(T^2\\) de Hotelling pour prélèvement individuel",
    "text": "5.6 \\(T^2\\) de Hotelling pour prélèvement individuel\n\nDans de nombreuses applications on ne peut prélever qu’une seule observation (\\(n=1\\)) par prélèvement.\nCeci nécessite donc d’adapter la carte de Hotelling. Le problème étant l’approximation de la matrice de covariance \\(\\Sigma\\).\n\n\n\n\n\n\n\nEstimation de \\(\\Sigma\\)\n\n\n\n\nSullivan and Woodall (1996) ont proposé la matrice de covariance corrigée entre les \\(k\\) prélèvements \\(X_1,...,X_k\\in\\mathbb R^p\\) et leur moyenne empirique \\(\\overline{X}\\).\n\nDans R:\n\ncovariance_X(X)\n\n\nHolmes and Mergen (1993) ont proposé 1/2 fois la matrice de covariance corrigée entre les différences entre deux prélèvements consécutifs :\n\nDans R:\n\ncov(diff(X))/2\n\n\n\nCalcul du \\(T^2\\) et de LSC\nPour chaque prélèvement \\(t\\) on calcule \\[T^2_t=(X_t-\\bar X)^T.S^{-1}.(X_t-\\bar X).\\] Pour la phase I (mise en place de la carte) on utilise : \\[\nLSC=\\frac{(k-1)^2}{k}\\beta_{p/2,(m-p-1)/2}(\\alpha).\n\\] Pour la phase II on utilise (toujours avec le \\(k\\) de la phase I: \\[\nLSC=\\frac{p(k+1)(k-1)}{k^2-kp}F_{p,m-p}(\\alpha).\\]\nExemple: On considère des données contenant des mesures de la déviation, de la courbure, de la résistivité et de la dureté dans les côtés à faible et forte dilatation des thermostats bimétalliques en laiton et en acier.\n\ndata(\"bimetal1\")\nhead(bimetal1)\n\n     deflection curvature resistivity Hardness low side Hardness high side\n[1,]      20.84     39.84       14.98             21.88              25.87\n[2,]      20.89     39.94       14.91             22.03              25.97\n[3,]      21.13     40.12       15.58             22.13              26.11\n[4,]      20.42     39.78       14.73             21.46              25.74\n[5,]      21.29     40.31       15.56             22.65              26.22\n[6,]      21.08     39.98       15.19             22.22              25.91\n\n\nOn peut représenter les corrélations des caractéristiques :\n\nggpairs(bimetal1)\n\n\n\n\nCi dessous la carte de contrôle dans R pour la phase I :\n\nS=cov(diff(bimetal1))/2\nT2=T2_Hotelling_k1(bimetal1,S = S)\nLSCT2=LSC_T2_Hotelling_k1(bimetal1)\nplot_chart(T2,LSC=LSCT2[\"PhaseI\"],Type=\"T2 individuel Phase I\") \n\n\n\n\nLes prélèvements 16, 19 et 20 sont exclus du calcul de LSC (car HC) :\n\ndf=bimetal1[-c(16,19,20),]\nS=cov(diff(df))/2\nT2=T2_Hotelling_k1(df,S = S)\nLSCT2=LSC_T2_Hotelling_k1(df)\nplot_chart(T2,LSC=LSCT2[\"PhaseI\"],Type=\"T2 individuel Phase I\")\n\n\n\n\nOn utilise les données bimetal2 pour suivre la production :\n\ndata(\"bimetal2\")\n\nT2=T2_Hotelling_k1(bimetal2,\n                      MoyT = Moy_T(df),\n                      S=S)\nplot_chart(T2,LSC=LSCT2[\"PhaseII\"],Type=\"T2 individuel Phase II\") \n\n\n\n\nDeux prélèvements sont HC on va comme précédemment s’intéresser aux caractéristiques impliquant la présence de ces points HC. On peut pour ce faire regarder les cartes de contrôles univariées puis bivariée en ces points."
  },
  {
    "objectID": "chapitre7.html#cartes-sur-composantes-principales",
    "href": "chapitre7.html#cartes-sur-composantes-principales",
    "title": "5  Cartes multivariées",
    "section": "5.9 Cartes sur composantes principales",
    "text": "5.9 Cartes sur composantes principales\n\n5.9.1 Cartes individuelles :\nL’analyse en composante principale (ACP) est une méthode factorielle qui permet de réduire la dimension d’une matrice en résumant les caractéristiques à travers des combinaisons linéaires de celles-ci (appelées composantes principales). Elle est particulièrement indiquée lorsque la corrélation entre les caractéristiques est forte.\n\n\n\n\n\n\nACP\n\n\n\nEtant donnée une matrice \\(X\\) centrée sur les colonnes de dimension \\(k,p\\). On diagonalise la matrice de covariance \\(\\Sigma\\) de \\(X\\) ie on écrit \\[\\Sigma=U\\Lambda U^T,\\] où \\(\\Lambda\\) est diagonale telle que \\(\\lambda_1\\geq ... \\geq \\lambda_p\\), \\(U\\) est une matrice orthogonale.\n\nLes colonnes de \\(U\\) sont les scores factoriels des individus sur les composantes principales\nLes valeurs propres \\(\\lambda_1\\) sont les variances des composantes principales.\n\n\n\nOn peut utiliser la fonction PCA du package FactoMineR :\n\ndata(bimetal1)\nlibrary(FactoMineR)\nX=scale(bimetal1[-c(16,19,20),],center=TRUE,scale=FALSE)\npca=PCA(X,scale.unit=F,graph = F)\n\nLe choix du nombre de composantes se fait en étudiant l’éboulis des valeurs propres\n\nlibrary(factoextra)\n\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n\nfviz_eig(pca)\n\n\n\n\nOn choisit ici deux composantes.\nOn peut représenter les caractéristiques initiales sur le plan factoriel :\n\nfviz_pca_var(pca)\n\n\n\n\nLe calcul de \\(T^2\\) se fait à partir des scores factoriels :\n\\[\nT^2=\\sum_{j=1}^p \\frac{u_j^2}{\\lambda_j^2}\n\\]\n\nr &lt;- 3\nscores &lt;- pca$ind$coord[,1:r]\nS=cov(diff(scores))/2\nT2pca=T2_Hotelling_k1(scores,S=S)\nLSCpca=LSC_T2_Hotelling_k1(scores)\nplot_chart(T2pca,LSC=LSCpca[\"PhaseI\"],Type=\"T2 sur composantes principales\")\n\n\n\n\nce qui donne sur les nouveaux points :\n\nX2=scale(bimetal2,scale=F)\nscores2=predict.PCA(pca,newdata = X2)$coord[,1:r]\nT2pca=T2_Hotelling_k1(scores2,\n                      S = S)\nplot_chart(T2pca,LSC=LSCpca[\"PhaseII\"],Type=\"T2 sur composantes principales\")\n\n\n\n\n\n\n5.9.2 Cas multivarié\nRevenons sur l’ACP : on sélectionne \\(r\\) composantes principales (principe du coude par exemple) et soit \\(U_r\\) les \\(r\\) premières colonnes de la matrice des vecteurs propres de la matrice de covariance de \\(X\\).\nLes scores des individus sur les composantes principales sont donnés par \\(T=X.U,\\) donc si on pose \\(\\hat X=T.U_r^T\\) alors on a : \\[\nX=\\hat X+ E,\n\\] où \\(E\\) est la matrice des résidus.\nPour projeté un nouveau jeu de données \\(X_{new}\\) on commence par centré le jeu de données : \\[\nX^c_{new}=X_{new}-\\bar X,\n\\] où \\(\\bar X\\) est le vecteur des moyennes de la base de données initiales.\nOn calcule \\(T_{new}=X^c_{new}.U_r\\) et donc \\(\\hat X^c_{new}=T_{new}.U^T_r\\).\nOn va appliquer ce principe à la matrice \\((k,np)\\) correspondant aux données X qui seront empilées selon le troisème mode de \\(X\\)\n\nX1=carbon1\nn=dim(X1)[3]\nX=NULL\nfor(i in 1:n) X=cbind(X,X1[,,i])\ndim(X)\n\n[1] 30 24\n\nXc=scale(X,scale = F)\nM=apply(X,2,mean)\npca=PCA(Xc,scale.unit = F,graph=F,ncp = dim(Xc)[2])\nfviz_eig(pca)\n\n\n\nr=6\nscores=pca$ind$coord[,1:r]\nS=cov(scores)\nT2=T2_Hotelling_k1(scores,S = S)\nLSC=mean(T2)+3*sd(T2)\nplot_chart(T2,LSC=LSC,Type=\"T2 MPCA Phase I\")\n\n\n\nX2=carbon2\nX=NULL\nfor(i in 1:n) X=cbind(X,X2[,,i])\ndim(X)\n\n[1] 25 24\n\nXc=scale(X,center=M,scale = F)\n\nscores2=predict(pca,newdata=Xc)$coord[,1:r]\nT2=T2_Hotelling_k1(scores2,S = S)\nplot_chart(T2,LSC=LSC,Type=\"T2 MPCA Phase II\")"
  },
  {
    "objectID": "chapitre7.html#retour-sur-lexemple-bimetal1bimetal2",
    "href": "chapitre7.html#retour-sur-lexemple-bimetal1bimetal2",
    "title": "4  Cartes multivariées",
    "section": "6.2 Retour sur l’exemple bimetal1/bimetal2",
    "text": "6.2 Retour sur l’exemple bimetal1/bimetal2\n\nLa SVD dans R :\n\n\ndata(bimetal1)\nX=scale(bimetal1,center=TRUE,scale=FALSE)\nres=svd(X)\nU=res$u\nV=res$v\nLambda=res$d",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cartes multivariées</span>"
    ]
  },
  {
    "objectID": "chapitre7.html#choix-du-nombre-de-composantes",
    "href": "chapitre7.html#choix-du-nombre-de-composantes",
    "title": "4  Cartes multivariées",
    "section": "6.3 Choix du nombre de composantes",
    "text": "6.3 Choix du nombre de composantes\n\np=dim(X)[2]\nggplot(data.frame(PC=1:p,PourcentagePC=Lambda/sum(Lambda)),aes(x=PC,y=PourcentagePC))+\n  geom_col()+theme_minimal()\n\n\n\n\n\n\n\n\nOn choisit deux composantes.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cartes multivariées</span>"
    ]
  },
  {
    "objectID": "chapitre7.html#représentation-des-prélèvements-sur-les-deux-premières-composantes",
    "href": "chapitre7.html#représentation-des-prélèvements-sur-les-deux-premières-composantes",
    "title": "4  Cartes multivariées",
    "section": "6.4 Représentation des prélèvements sur les deux premières composantes :",
    "text": "6.4 Représentation des prélèvements sur les deux premières composantes :\nOn utilise :\n\nX_PC=U%*%diag(Lambda)\n\nce qui donne\n\nggplot(data.frame(PC1=X_PC[,1],PC2=X_PC[,2]),\n       aes(x=PC1,y=PC2))+\n  geom_point()+\n  geom_vline(xintercept = 0)+\n  geom_hline(yintercept = 0)+\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cartes multivariées</span>"
    ]
  },
  {
    "objectID": "chapitre7.html#cercle-des-corrélations",
    "href": "chapitre7.html#cercle-des-corrélations",
    "title": "4  Cartes multivariées",
    "section": "6.5 Cercle des corrélations",
    "text": "6.5 Cercle des corrélations\n\nXs=scale(bimetal1)\nn=nrow(Xs)\nres2=svd(Xs)\nR=as.data.frame(res2$v %*% diag(res2$d)/sqrt(n))\nrownames(R)=colnames(bimetal1)\ncolnames(R)=paste(\"PC\",1:dim(R),sep=\"\")\n\nWarning in 1:dim(R): numerical expression has 2 elements: only the first used\n\n\nce qui donne :\n\nlibrary(ggrepel)\nggplot(R, aes(x = PC1, y = PC2,label=rownames(R))) +\n  geom_segment(aes(xend = 0, yend = 0), color = \"grey\") +\n  #geom_point(color = \"blue\", size = 3) +\n  xlim(-1,1)+\n  ylim(-1,1)+\n  geom_label_repel(fill = \"white\", color = \"black\") +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  #coord_equal() +\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cartes multivariées</span>"
    ]
  },
  {
    "objectID": "chapitre7.html#section",
    "href": "chapitre7.html#section",
    "title": "4  Cartes multivariées",
    "section": "6.6 ",
    "text": "6.6 \nOn en déduit la carte du \\(T^2\\) en prenant les deux premières colonnes de \\(X'\\)\n\nXPC=X_PC[,1:2]\nres=T2_Hotelling_k1(XPC)\nLSC=LSC_T2_Hotelling_k1(XPC)\nk=dim(XPC)[1]\nggplot(data.frame(t=1:k,T2=res),aes(x=factor(t),y=T2))+\n  geom_point()+\n  geom_line(aes(x=t,y=T2))+\n  geom_hline(yintercept = LSC[1],linetype=\"dashed\",col=\"red\")+\n  geom_label(aes(x=t[1]+0.5,y=LSC[1],label=\"LSC\"),col=\"red\")+\n  labs(\n    x=\"prélèvement\",\n    y=\"Moyennes\",\n    title=\"Carte du T2 de Hotelling\"\n  )+\n  theme_minimal()\n\nWarning in geom_label(aes(x = t[1] + 0.5, y = LSC[1], label = \"LSC\"), col = \"red\"): All aesthetics have length 1, but the data has 28 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cartes multivariées</span>"
    ]
  },
  {
    "objectID": "chapitre7.html#nouveaux-points",
    "href": "chapitre7.html#nouveaux-points",
    "title": "4  Cartes multivariées",
    "section": "6.7 Nouveaux points",
    "text": "6.7 Nouveaux points\nOn note \\(X_{new}\\) la matrice centrée sur les colonnes de la nouvelle base de donnée. On calcule les coordonnées de \\(X_{new}\\) sur les composantes principales : \\[\nX'_{new}=X_{new}.V\n\\] On en déduit :\n\nX2=(scale(bimetal2,center=TRUE,scale=FALSE)%*%V)[,1:2]\nres=T2_Hotelling_k1(X2,MoyT = Moy_T(XPC),\n                    S=covariance_X(XPC))\nk=dim(X2)[1]\nggplot(data.frame(t=1:k,T2=res),aes(x=factor(t),y=T2))+\n  geom_point()+\n  geom_line(aes(x=t,y=T2))+\n  geom_hline(yintercept = LSC[2],linetype=\"dashed\",col=\"red\")+\n  geom_label(aes(x=t[1]+0.5,y=LSC[2],label=\"LSC\"),col=\"red\")+\n  labs(\n    x=\"prélèvement\",\n    y=\"Moyennes\",\n    title=\"Carte du T2 de Hotelling\"\n  )+\n  theme_minimal()\n\nWarning in geom_label(aes(x = t[1] + 0.5, y = LSC[2], label = \"LSC\"), col = \"red\"): All aesthetics have length 1, but the data has 28 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cartes multivariées</span>"
    ]
  },
  {
    "objectID": "chapitre4.html#cartes-de-shewart",
    "href": "chapitre4.html#cartes-de-shewart",
    "title": "4  Cartes univariées",
    "section": "4.1 Cartes de Shewart",
    "text": "4.1 Cartes de Shewart\nOn va construire deux graphiques : une carte dite de position et une carte de dispersion. Ces cartes sont appelées les cartes de Shewart.\nExemple\nSuivi de production journalière de steacks hachés surgelés durant 12h de production. Chaque heure on prélève 5 steaks et on les pèse.\nLes données sont disponibles ici\n\n\n\n\n\nX\nweight.1\nweight.2\nweight.3\nweight.4\nweight.5\n\n\n\n\n1\n98.6\n100.3\n100.9\n100.2\n99.6\n\n\n2\n100.3\n99.5\n98.9\n100.2\n100.6\n\n\n3\n99.2\n98.8\n101.5\n100.3\n101.0\n\n\n4\n101.1\n97.8\n98.9\n101.3\n101.7\n\n\n5\n101.0\n99.8\n97.3\n99.4\n100.8\n\n\n6\n101.1\n100.1\n99.0\n100.7\n99.9\n\n\n\n\n\nOn va construire les cartes de contrôle données ci-dessous\n\n\n\n\n\n\n\n\nPour chaque échantillon de 5 steacks on calcule la moyenne et l’écart type et on les reporte sur les cartes correspondantes.\n\n4.1.1 Distribution des paramètres\nOn suppose que tous les paramètres suivent une loi normale.\n\nLa moyenne d’un échantillon \\(\\bar Y \\sim \\mathcal N(\\mu,\\frac{\\sigma}{\\sqrt n}).\\)\nL’étendue d’un échantillon \\(R \\sim \\mathcal N(\\mu_R,\\sigma_R).\\)\nL’écart type d’un échantillon \\(S \\sim \\mathcal N(\\mu_S,\\sigma_S).\\)\n\nOn définit alors les limites de surveillance et de contrôle pour chaque carte. Pour la carte de la moyenne :\n On se fixe un risque \\(\\alpha\\) de stoper la production alors que celle-ci est sous contrôle (Fausses alertes). On cherche donc un intervalle de confiance \\(1-\\alpha\\) de \\(\\bar X\\) La distribution des moyennes étant normale on a\n\\[\n\\begin{cases}\nLI=\\mu-z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt n} \\\\\nLS=\\mu+z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt n} \\\\\n\\mathbb P(LI&lt;\\bar X&lt;LS)=1-\\alpha\n\\end{cases}\n\\]\nOn pourra en conclure que la moyenne \\(\\bar X\\) de l’échantillon considéré n’est pas significativement différente de la moyenne \\(\\mu\\) (c’est à dire que le procédé est sous contrôle) si \\(\\bar X \\in [LI,LS].\\)\nLes limites de surveillance sont définies de façon à déterminer, au risque de 4.5%, les moyennes significativement différentes de la moyenne globale :\n\nLimite inférieure de surveillance (LIS): \\(LIS=\\mu-2\\frac{\\sigma}{\\sqrt n}\\)\nLimite supérieure de surveillance (LSS): \\(LSS=\\mu+2\\frac{\\sigma}{\\sqrt n}\\)\n\nLes limites de contrôle sont définies de façon à déterminer, au risque de 0.3% de fausses alertes, les moyennes significativement différentes de la moyenne globale :\n\nLimite inférieure de contrôle (LIC): \\(LIC=\\mu-3\\frac{\\sigma}{\\sqrt n}\\)\nLimite supérieure de contrôle (LSC): \\(LSC=\\mu+3\\frac{\\sigma}{\\sqrt n}\\)\n\n\n\n\n\n\n\nLimites des cartes de contrôle\n\n\n\nOn a prélevé à intervalles réguliers \\(k\\) échantillons de \\(n\\) observations. On a calculé \\(\\bar y_j,R_j\\) la moyenne et l’étendue de chacun des \\(k\\) échantillons.\nPour construire :\n\nLa carte de la moyenne on utilise \\(\\hat \\mu_I=\\frac 1{k} \\displaystyle\\sum_{j=1}^k \\bar y_{j}\\) et \\(\\hat \\sigma_I = \\dfrac{\\bar R}{d_2}\\).\nLa carte de l’étendue on utilise \\(\\hat\\mu_R=\\bar R\\) et \\(\\hat \\sigma_R=\\frac{d_3}{d_2}\\bar R\\).\nLa carte de l’écart type on utilise \\(\\hat\\mu_S=\\bar S\\) et \\(\\hat \\sigma_S=\\frac{\\sqrt{1-c_4^2}}{c_4}\\bar S\\).\n\n\n\n\n\n4.1.2 Retour sur l’exemple :\n\nCalculer les limites de contrôles des cartes de la moyenne et de l’écart type.\nConstruire les cartes s’obtiennent en utilisant la fonction plot_chart() du package multiSPC.\n\n\n\nVoir la correction\ndf&lt;-data[,-1]\nn=ncol(df)\nM=apply(df,1,mean)\nS=apply(df,1,sd)\nmu=mean(M)\nsigI=mean(S)/c4(n)\nLICm=mu-3*sigI/sqrt(n)\nLSCm=mu+3*sigI/sqrt(n)\nLICs=mean(S)-3*mean(S)*sqrt(1-c4(n)^2)/c4(n)\nLSCs=mean(S)+3*mean(S)*sqrt(1-c4(n)^2)/c4(n)\nplot_chart(M,LIC=LICm,LSC=LSCm,Type = \"carte de la moyenne\")\nplot_chart(S,LIC=LICs,LSC=LSCs,Type = \"carte de l'écart type\")"
  },
  {
    "objectID": "chapitre4.html#carte-ewma",
    "href": "chapitre4.html#carte-ewma",
    "title": "4  Cartes univariées",
    "section": "4.2 Carte EWMA",
    "text": "4.2 Carte EWMA\n\n4.2.1 Introduction\nLa carte de Shewhart de la moyenne est très simple à mettre en oeuvre et à interpréter. Cependant elle n’a pas une très grande efficacité surtout :\n\nen cas de faibles et moyennes déviations\nen cas de structure d’autocorrélation, c’est à dire lorsque le passé a une influence, par exemple lorsqu’une tendance croissante apparaît.\n\nExemple :\nOn suit une production de caractéristique \\(\\mu=15\\) et \\(\\sigma=0.5\\). Pour ce faire 10 prélèvements de 4 unités de production ont été réalisés. On construit la carte de moyenne de Shewhart. A partir du 7ième prélèvement on constate une déviation de la moyenne et un décentrage supérieur. La carte de Shewhart ne détecte cette déviation que très tardivement (14ième prélèvement).\n\n\n\n\n\nUne des solutions est la carte EWMA\n\n\n4.2.2 Définition des cartes EWMA\nEWMA : Exponentially Weighted Moving Average\nOn définit la statistique \\(z_i\\) par une relation de récurrence pour tout \\(i=1,...,k\\)\n\\[\nz_i=\\lambda \\bar x_i +(1-\\lambda)z_{i-1},\n\\]\noù \\(\\bar x_i\\) est la moyenne des unités pour le prélèvement \\(i\\) et \\(0&lt;\\lambda\\leq 1\\) est un réel qui sera choisi en fonction du poids que l’on veut donner aux données précédentes. En effet, en général on choisit \\(z_0=\\mu\\) (moyenne du procédé de fabrication). On a \\[\n\\begin{cases}\nz_1=\\lambda \\bar x_1+(1-\\lambda)\\mu \\\\\nz_2=\\lambda \\bar x_2+(1-\\lambda)z_1= \\lambda \\bar x_2+\\lambda(1-\\lambda)\\bar x_1+(1-\\lambda)^2\\mu \\\\\nz_3=\\lambda \\bar x_3+\\lambda(1-\\lambda)\\bar x_2+\\lambda(1-\\lambda)^2\\bar x_1+\n(1-\\lambda)^3\\mu \\\\\n\\ldots\n\\end{cases}\n\\]\n\n\n\n\n\n\nLa cas \\(\\lambda=1\\) correspond à la carte de Shewhart sur la moyenne.\nOn constate que \\(\\bar x_i\\) a une importance d’autant plus importante dans \\(z_i\\) que \\(\\lambda\\) est grand.\nEn général on utilise \\(0.25&lt;\\lambda&lt;0.5\\).\n\n\n\n4.2.3 Limites de contrôle des cartes EWMA\nLes limites de ces cartes sont variables (en fonction de \\(i\\)) pour \\(X\\sim \\mathcal N(\\mu,\\sigma)\\) on a :\\[LC = \\mu  \\pm L\\frac{\\sigma}{\\sqrt{n}}\\times \\sqrt {\\frac{\\lambda}{2-\\lambda}[1-(1-\\lambda)^{2i}] },\\] en général avec \\(L=3\\).\nLorsque le nombre \\(i\\) de prélèvement est très grand alors \\(LC = \\mu \\pm L\\frac{\\sigma}{\\sqrt{n}}\\times \\sqrt {\\frac{\\lambda}{2-\\lambda}}\\). Dans ce cas on peut jouer sur ce paramètre \\(L\\) pour améliorer l’efficacité de la carte en fonction de \\(\\lambda\\).\n\n\n4.2.4 Retour à l’exemple :\nOn constate que contrairement à la carte de la moyenne la carte EWMA détecte le décentrage dès le 5ième prélèvement.\n\nlambda=0.25\nZ&lt;-ewma_cart1(data,n,mu=mu,sig=sig,lambda=lambda)\nplot_chart(Z$z,LIC=Z$LIC,LSC=Z$LSC,Type=\"Carte EWMA\")"
  },
  {
    "objectID": "chapitre2.html#capabilité-dun-procédé-de-fabrication",
    "href": "chapitre2.html#capabilité-dun-procédé-de-fabrication",
    "title": "2  Capabilité, Répétabilité, Reproductivité",
    "section": "2.1 Capabilité d’un procédé de fabrication :",
    "text": "2.1 Capabilité d’un procédé de fabrication :\nDans la suite \\(TS,TI\\) désigneront la tolérance supérieure et inférieure du procédé de fabrication.\nComme précédemment on distingue la variabilité globale du procédé et celle uniquement attribuable à la machine.\nOn définit deux types d’indices de capabilité :\n\n\n\n\n\n\nCapabilité\n\n\n\n\nLa capabilité globale du procédé de fabrication (appelée aussi coefficient d’aptitude du procédé) est \\[\nCap=\\frac{TS-TI}{D_G}.\n\\]\nLa capabilité machine (appelée aussi coefficient d’aptitude du moyen)\n\n\\[\nCam=\\frac{TS-TI}{D_I}.\n\\]\n\n\nIl est clair que lorsque \\(Cap&lt;1\\) le procédé n’est pas capable, il faut le revoir afin d’obtenir une production conforme aux tolérances. Par contre si \\(Cap&gt;2\\) on va considérer que le procédé est capable dans la mesure où la dispersion naturelle des observation est 2 fois moins importante que l’intervalle de tolérance.\nLes deux indicateurs précédents ont un gros inconvénient dans la mesure où ils ne permettent pas de juger du décentrage éventuel du procédé. Par exemple, dans le cas d’une loi normale, on peut avoir une situation comme celle ci-dessous :\n\nOn voit que le procédé est bien dans l’intervalle de tolérance avec une valeur \\(Cap&gt;2\\) mais qu’il est clairement décentré. Donc il faut définir de nouveaux indices de capabilité qui vont permettre de juger de la justesse du procédé !\n\n\n\n\n\n\nCapabilité (version 2)\n\n\n\nLe coefficient de performance du procédé est\n\\[\nCpk=\\frac{\\min\\left(\\mu-TI;TS-\\mu\\right)}{3\\sigma_{G}},\n\\] et celui la machine est \\[\nCmk=\\frac{\\min\\left(\\mu-TI;TS-\\mu\\right)}{3\\sigma_{I}}.\n\\]\n\n\nIl est clair que l’on a :\n\n\\(Cap&gt;Cpk,\\)\n\\(Cam&gt;Cmk.\\)\n\nOn utilisera la norme suivante :\nUn procédé (respectivement une machine) est capable si \\(Cpk&gt;1.33\\) (respectivement \\(Cmk&gt;1.33\\))\n\n2.1.1 Intervalles de confiance\nLes calculs de \\(Cap\\) et de \\(Cpk\\) sont basés sur des estimations de l’écart type \\(\\sigma_G\\). Dans le cas d’une loi normale on sait construire un intervalle de confiance de \\(\\sigma_G\\), on en déduit que\n\nL’intervalle \\(\\left[\\widehat C_{ap}\\sqrt{\\dfrac{\\chi^2_{n-1}(\\alpha/2)}{n-1}};\\widehat C_{ap}\\sqrt{\\dfrac{\\chi^2_{n-1}(1-\\alpha/2)}{n-1}}\\right]\\) est un intervalle de confiance de \\(Cap\\) au niveau de confiance \\(100(1-\\alpha)\\) %.\nL’intervalle \\(\\left[\\widehat C_{pk}\\left(1-z_{1-\\alpha/2}\\sqrt{\\dfrac{1}{9n\\widehat C_{pk}^2}+\\dfrac{1}{2(n-1)}}\\right);\\widehat C_{pk}\\left( 1+z_{1-\\alpha/2}\\sqrt{\\dfrac{1}{9n\\widehat C_{pk}^2}+\\dfrac{1}{2(n-1)}}\\right)\\right]\\) est un intervalle de confiance de \\(C_{pk}\\) au niveau de confiance \\(100(1-\\alpha)\\) %.\n\nDe même pour \\(C_{am},C_{mk}\\)\n\n\n2.1.2 Fin de l’exemple\nOn suppose que les tolérance sont \\(TI=0.9\\) et \\(TS=1.1\\). En utilisant la fonction capability du package multiSPC calculer les indices de capabilité associés à ce procédé de fabrication.\n\n\nVoir la correction\nlibrary(multiSPC)\ndf&lt;-read.csv(\"cap_data.csv\",sep=\",\")\nmu=mean(df$obs)\nsG=sd(df$obs)\nsI=df|&gt; group_by(sample) |&gt; summarise(S=sd(obs)) |&gt; select(S) |&gt;unlist() |&gt; mean()/c4(5)\ncapability(n=5,mu=mu,sI=sI,sG=sG,TI=0.9,TS=1.1)"
  },
  {
    "objectID": "chapitre2.html#analyse-de-la-qualité-dune-mesure",
    "href": "chapitre2.html#analyse-de-la-qualité-dune-mesure",
    "title": "2  Capabilité, Répétabilité, Reproductivité",
    "section": "2.2 Analyse de la qualité d’une mesure",
    "text": "2.2 Analyse de la qualité d’une mesure\nCette étape de vérification est indispensable dans tout système de contrôle de qualité.\nUne mesure doit être répétable et reproductible (R&R).\n\n2.2.1 R&R\n\n\n\n\n\n\nRépétabilité\n\n\n\nLa répétabilité désigne la capacité d’un processus, d’un instrument de mesure ou d’une expérience à produire des résultats identiques ou très proches lorsque les mêmes conditions (même opérateur, même équipement, …) sont appliquées plusieurs fois de suite sur une courte période.\n\n\nLa répétabilité est donc intrinsèquement liée à la qualité fournie par un instrument de mesure. On pourra vérifier que les spécifications de l’instrument sont bien conformes à des mesures effectuées in situ.\n\n\n\n\n\n\nReproductibilité\n\n\n\nLa reproductibilité désigne la capacité d’un processus, d’une expérience ou d’une mesure à produire des résultats similaires lorsqu’il est réalisé par des personnes différentes, dans des lieux différents, avec des équipements différents, ou à des moments différents.\n\n\nDans un système complet à l’erreur de la mesure proprement dite (R&R), s’ajoute la variabilité liée au produit :\n\\[\n\\sigma_{Total}^2=\\underbrace{\\sigma_{repetability}^2+\\sigma_{reproductivity}^2}_{\\sigma^2_{R\\& R}}+\\sigma_{product}^2.\n\\]\n\n\n\n\n\n\nRappel ANOVA\n\n\n\nOn considère \\(I\\) produits, \\(J\\) opérateurs et chaque mesure est repétée \\(K\\) fois Pour évaluer la répétabilité et la reproductibilité d’une mesure, on utilise un modèle d’ANOVA : Soit \\(Y_{ijk}\\) la mesure du produit \\(i\\) par l’opérateur \\(j\\) à la répétition \\(k\\).\nOn écrit \\[\nY_{ijk}=\\mu+\\alpha_i+\\beta_j+\\varepsilon_{ijk}\n\\] où on considère que \\(\\varepsilon_{ijk}\\sim \\mathcal N(0,\\sigma^2)\\).\nLes paramètres de ce modèle permettent d’évaluer l’ensemble des composantes de la variabilité totale de la mesure:\n\n\\((\\alpha_i)_i\\) pour la variabilité produit,\n\\((\\beta_j)_j\\) pour la reproductibilité,\n\\(\\sigma^2\\) pour la répétabilité\n\n\n\nExemple : On cherche à détecter les sources de variabilité d’une analyse par qPCR La réponse de la mesure dépend de la quantité d’ADN recherchée dans l’échantillon de départ.\n\n4 espèces différentes de mycoplasmes sont étudiées.\n2 opérateurs ont réalisé les mesures, sur 2 jours distincts, avec 4 répétitions à chaque fois. Les données sont disponibles ici.\n\n\n\n\n\n\n\n  \n    \n    \n      \n      souche\n      operateur\n      jour\n      repetition\n      reponse\n    \n  \n  \n    1\nS1\nO1\nJ1\nr1\n29.10\n    2\nS1\nO1\nJ1\nr2\n28.35\n    3\nS1\nO1\nJ1\nr3\n28.14\n    4\nS1\nO1\nJ1\nr4\n28.28\n    5\nS1\nO1\nJ2\nr1\n28.41\n    6..63\n\n\n\n\n\n    64\ns4\nO2\nJ2\nr4\n32.78\n  \n  \n  \n\n\n\n\nDans cet exemple on va pouvoir évaluer la variabilité due au produit, à l’opérateur, au jour grâce à une Anova :\n\noptions(contrasts=c(\"contr.sum\",\"contr.sum\"))\nmodel &lt;- lm(reponse ~ souche+operateur+jour, data = data)\nanova(model)\n\nAnalysis of Variance Table\n\nResponse: reponse\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nsouche     3 137.077  45.692 70.5476 &lt; 2.2e-16 ***\noperateur  1   5.499   5.499  8.4903  0.005064 ** \njour       1   0.011   0.011  0.0170  0.896647    \nResiduals 58  37.566   0.648                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nOn peut ainsi étudier :\n\nL’effet souche (\\(F(3,58)=70.5,p&lt;.001\\)) qui est significatif, l’effet opérateur (\\(F(1,58)=8.5,p=.005\\)) qui est également significatif et l’effet jour (\\(F(1,58)=0.02,p=.90\\)) qui ne l’est pas.\nLa variabilité associée au jour qui est une composante de la reproductibilité n’est pas considérée par la suite car très proche de 0.\nLe résidu correspond à la répétabilité de la mesure.\n\n\n\n\n\n\n\nRappel ANOVA à effets aléatoires\n\n\n\nPour évaluer la part de chaque composante de la variabilité on écrit \\[\nY_{ijk}=\\mu+\\alpha_i+\\beta_j+\\varepsilon_{ijk}\n\\]\noù on suppose que :\n\n\\(\\alpha_i\\sim \\mathcal N(0,\\sigma^2_\\alpha)\\) (\\(\\sigma^2_\\alpha\\) : variabilité produit),\n\\(\\beta_j\\sim \\mathcal N(0,\\sigma^2_\\beta)\\) (\\(\\sigma^2_\\beta\\) : reproductibilité),\n\\(\\varepsilon_{ijk}\\sim \\mathcal N(0,\\sigma^2)\\) (\\(\\sigma^2\\) : répétabilité).\n\n\n\nDans R, l’Anova à effets aléatoires :\n\nsuppressMessages(library(lmerTest))\n\nmodel &lt;- lmer(reponse ~ 1 + (1|souche) + (1|operateur) , data = data)\nvc &lt;- as.data.frame(VarCorr(model))$vcov\nnames(vc)=as.data.frame(VarCorr(model))$grp\ndf=data.frame(variance=c(vc,sum(vc)),\"per_var\"=c(vc/sum(vc)*100,100))\nrownames(df)=c(\"Part\",\"reproductibiliy\",\"repetebility\",\"Total\")\n\n\n\n\n\n\n\n  \n    \n    \n      \n      variance\n      per_var\n    \n  \n  \n    Part\n2.82\n78.12\n    reproductibiliy\n0.15\n4.21\n    repetebility\n0.64\n17.67\n    Total\n3.60\n100.00\n  \n  \n  \n\n\n\n\n[1] \"Estimation de RR :  21.88\"\n\n\n\n\n\n\n\n\nInterprétation %RR\n\n\n\nOn utilise les références suivantes :\n\nSi %RR &lt; 10%, alors la mesure est répétable et reproductible,\nSi %RR est compris entre 10% et 30% alors la mesure est acceptable,\nAu delà de 30% il faut revoir le processus.\n\n\n\nDonc ici la mesure est acceptable.\n\n\n2.2.2 Capabilité d’un instrument de mesure.\nIl est évalué comme précédemment en considérant les tolérances inférieures et supérieures imposées par le client :\n\n\n\n\n\n\nCapabilité instrument de mesure\n\n\n\n\nCoefficient de capabilité d’un moyen de contrôle : \\[\nCmc=\\frac{TS-TI}{6\\sigma_{R\\&R}},\n\\] on doit avoir \\(Cmc&gt;4\\)."
  },
  {
    "objectID": "projet.html",
    "href": "projet.html",
    "title": "7  Projet",
    "section": "",
    "text": "On considère les données ici qui correspondent à un suivi individuel de 7 niveaux d’impuretés dans une bio-production.\n\nOn se base uniquement sur les 30 premiers prélèvements pour construire les limites de contrôles de la carte du \\(T^2\\).\n\n\n\nAnalyser la corrélation entre les 7 caractéristiques. Une carte sur composante principale vous paraît-elle justifiée ?\nCalculer le \\(T^2\\), la limite de contrôle et construire la carte en retirant les éventuels points HC.\n\n\nAppliquer les limites de contrôle précédentes aux autres prélèvements de ce jeu de données. Une étude systématique des éventuels points hors contrôle sera réalisée."
  }
]