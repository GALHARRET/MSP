[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Maitrise statistique des procédés",
    "section": "",
    "text": "La Maitrise Statistique des Procédés (MSP) ou Statistical Process Control (SPC) est une branche des statistiques qui s’intéresse au suivi dans le temps d’un processus (par exemple un procédé de fabrication). Historiquement, les premières approches de la MSP ont été introduites par W. A. Shewhart dans les années 1920 alors qu’il travaillait dans les laboratoires BELL. Ensuite, William E. Deming, élève de Shewhart, a popularisé cette discipline au Japon après la seconde guerre mondiale.\n\n\n\n\nL’objectif est de pouvoir s’assurer que la production est stable avec un minimum de produits non conformes aux spécifications.\nLe contrôle doit être simple à mettre en oeuvre et aussi permettre un suivi au plus près pour pouvoir détecter le plus tôt possible les déviations de production."
  },
  {
    "objectID": "cartesCTRL.html",
    "href": "cartesCTRL.html",
    "title": "Cartes de contrôle",
    "section": "",
    "text": "Inventées par Walter A. Shewhart (années 1920)\nS’utilisent dans de très nombreux secteurs d’activité (industrie, transport, service, …)\nSuivi et/ou amélioration d’un système de production\n\nAvantages\n\nTrès faciles à mettre en oeuvre\nTrès faciles à interpréter (graphiques)\n\nInconvénients\n\nNe tient pas a priori compte des tolérances\nN’est pas toujours efficace (ex : si problème de déviation progressive)\n\n\n\n\nOn distingue plusieurs causes qui peuvent induire des variations dans un système de production :\n\ncauses aléatoires (communes) elles sont en grand nombre avec un effet individuel faible. On peut les modéliser par une variable aléatoire (en général gaussienne). Elles peuvent être corrigées par des actions sur le système global. Exemple : temps de trajet domicile-travail. Si il y a des feux rouges sur le trajet ceux-ci pourront être parfois verts ou rouges, il peut y avoir plus ou moins de circulation… Action globale : changer de route pour ne plus avoir de feux rouges !\ncauses assignables (spéciales) elles sont rares et ne peuvent pas être associées directement au procédé de fabrication (Deming 1986). Elles peuvent être corrigées par des actions locales. Exemple : un accident de la route se produit sur le trajet.\n\nUn processus est dit sous contrôle ou statistiquement stable lorsque les variations sont uniquement dûes à des causes aléatoires.\n\n\n\n\n\nOn va construire deux graphiques : une carte dite de position et une carte de dispersion.\nExemple\nSuivi de production journalière de steacks hachés surgelés durant 12h de production. Chaque heure on prélève 5 steaks et on les pèse.\n\ndata&lt;-read.csv(\"exemple_carte_Shewhart.csv\")\nkable(head(data))\n\n\n\n\nX\nweight.1\nweight.2\nweight.3\nweight.4\nweight.5\n\n\n\n\n1\n98.6\n100.3\n100.9\n100.2\n99.6\n\n\n2\n100.3\n99.5\n98.9\n100.2\n100.6\n\n\n3\n99.2\n98.8\n101.5\n100.3\n101.0\n\n\n4\n101.1\n97.8\n98.9\n101.3\n101.7\n\n\n5\n101.0\n99.8\n97.3\n99.4\n100.8\n\n\n6\n101.1\n100.1\n99.0\n100.7\n99.9\n\n\n\n\ndf&lt;-data[,-1]\n## Carte de la moyenne avec la librairie qcc dans R\nX&lt;-qcc(df,type=\"xbar\",title=\"Carte de la moyenne\")\n\n\n\n## Carte de l'étendue avec la librairie qcc dans R\nX&lt;-qcc(df,type=\"R\",title=\"Carte de l'étendue\")\n\n\n\n\nPour chaque échantillon de 5 steacks on calcule la moyenne et l’étendue et on les reporte sur les cartes correspondantes.\n\n\n\nOn suppose que tous les paramètres suivent une loi normale.\n\nLa moyenne d’un échantillon \\(\\bar X \\sim \\mathcal N(\\mu,\\frac{\\sigma}{\\sqrt n}).\\)\nL’étendue d’un échantillon \\(R \\sim \\mathcal N(\\mu_R,\\sigma_R).\\)\nL’écart type d’un échantillon \\(S \\sim \\mathcal N(\\mu_S,\\sigma_S).\\)\n\nOn définit alors les limites de surveillance et de contrôle pour chaque carte. Pour la carte de la moyenne :\n On se fixe un risque \\(\\alpha\\) de stoper la production alors que celle-ci est sous contrôle (Fausses alertes). On cherche donc un intervalle de confiance \\(1-\\alpha\\) de \\(\\bar X\\) La distribution des moyennes étant normale on a\n\\[\n\\begin{cases}\nLI=\\mu-z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt n} \\\\\nLS=\\mu+z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt n} \\\\\n\\mathbb P(LI&lt;\\bar X&lt;LS)=1-\\alpha\n\\end{cases}\n\\]\nOn pourra en conclure que la moyenne \\(\\bar X\\) de l’échantillon considéré n’est pas significativement différente de la moyenne \\(\\mu\\) (c’est à dire que le procédé est sous contrôle) si \\(\\bar X \\in [LI,LS].\\)\nLes limites de surveillance sont définies de façon à déterminer, au risque de 4.5%, les moyennes significativement différentes de la moyenne globale :\n\nLimite inférieure de surveillance : \\(LIS=\\mu-2\\frac{\\sigma}{\\sqrt n}\\)\nLimite supérieure de surveillance : \\(LSS=\\mu+2\\frac{\\sigma}{\\sqrt n}\\)\n\nLes limites de contrôle sont définies de façon à déterminer, au risque de 0.3% de fausses alertes, les moyennes significativement différentes de la moyenne globale :\n\nLimite inférieure de contrôle : \\(LIS=\\mu-3\\frac{\\sigma}{\\sqrt n}\\)\nLimite supérieure de contrôle : \\(LSS=\\mu+3\\frac{\\sigma}{\\sqrt n}\\)\n\n\n\n\nReprenons le cas précédent. Pour chaque échantillon on peut calculer \\(\\bar y_j,R_j\\) la moyenne et l’étendue.\nOn a vu dans le chapitre précédent que \\(\\hat\\mu=\\overline{\\overline{y}}=\\frac 1{k} \\displaystyle\\sum_{j=1}^k \\bar y_{j}\\) et que \\(\\hat \\sigma = \\dfrac{\\bar R}{d_2}\\). Donc on a : \\[\n\\begin{cases}\n\\widehat{LIC}= \\bar{\\bar{y}}-\\frac{3}{\\sqrt n} \\frac{\\overline R}{d_2} \\\\\n\\widehat{LSC}= \\bar{\\bar{y}}+\\frac{3}{\\sqrt n} \\frac{\\overline R}{d_2}\n\\end{cases}\n\\]\n\n\n\nPour l’estimation de \\(\\mu_R\\) on prend \\(\\hat\\mu_R=\\bar R\\), et pour l’estimation de \\(\\sigma_R\\) on prend \\(\\hat \\sigma_R=\\frac{d_3}{d_2}\\bar R\\) où \\(d_3\\) est l’écart type des étendues d’une loi normale centrée réduite. On a alors \\[\n\\begin{cases}\n\\widehat{LIC}= \\overline{R}-3\\frac{d_3}{d_2}\\overline R \\\\\n\\widehat{LSC}= \\overline{R}+3\\frac{d_3}{d_2}\\overline R\n\\end{cases}\n\\]\n\n\n\n\nLa notion d’efficacité d’une carte de contrôle est sa capacité à détecter un dérèglement alors que la production semble rester sous contrôle.\nLe dérèglement peut concerner un décentrage (dérèglement de la moyenne) ou bien une augmentation de la dispersion.\n\n\n Un décentrage de moyenne est exprimé en nombre d’écart type (unité standardisé) donc si \\(\\mu_1\\) est la moyenne décentrée, on lui associera le décentrage\n\\[\n\\rho=\\frac{|\\mu_1-\\mu|}{\\sigma}\n\\]\nLa probabilité \\(\\beta\\) de ne pas détecter le décentrage est alors\n\\[\n\\beta=\\mathbb P(LIC&lt;\\widetilde X &lt;LSC)\n\\]\noù \\(\\widetilde X \\sim \\mathcal N(\\mu+\\rho\\sigma,\\frac{\\sigma}{n}).\\) Un calcul simple permet d’obtenir\n\\[\n\\beta = F(3-\\rho\\sqrt n)-F(-3-\\rho\\sqrt n)\n\\]\noù \\(F(x)=\\mathbb P(X&lt;x)\\) est la fonction de répartition de la loi normale.\nL’efficacité de la carte est mesurée par \\(1-\\beta\\) (appelée puissance de la carte). \nOn obtient ainsi les courbes d’efficacité de la carte de la moyenne en fonction de la taille \\(n\\) des échantillons prélevés.\n\n\n\n\n\n\nOn constate (ce qui est logique) que la probabilité de ne pas détecter un déréglage donné diminue en fonction de la taille de l’échantillon.\nDétecter un déréglage \\(\\rho=0\\) correspond à une fausse alerte qui vaut pour la carte de la moyenne \\(\\alpha=0.3\\%\\).\n\n\n\n\nIci on considère des décentrages \\(\\rho&gt;1\\) (sinon il s’agit d’une amélioration de la dispersion).\nUn calcul similaire au précédent conduit à \\[\n\\beta=F(\\frac{3}{\\rho})-F(\\frac{-3}{\\rho})\n\\] Ici on constate que l’efficacité de la carte est indépendante de \\(n\\) et qu’elle est très mauvaise. Il faut une très grande valeur de \\(\\rho\\) pour avoir une petite valeur de \\(\\beta\\).\nPar exemple pour \\(\\rho=3\\) on a \\(\\beta=\\) 0.6826895 c’est à dire pour un écart type qui triplerait la probabilité ne peut pas détecter ce dérèglement est de 68.3%.\n\n\n\n\nLa Période Opérationnelle Moyenne correspond au nombre de prélèvements qu’il faut effectuer, en moyenne, pour sortir des limites de contrôle lorsque qu’un déréglage \\(\\rho\\) s’est produit.\nLe cas \\(\\rho=0\\) pour une carte de Shewhart avec des observations indépendantes correspond à une fausse alerte qui se produit dans \\(\\alpha=0.3\\%\\) et correspond à\n\\[\nARL_0=\\frac{1}{0.003}=333\n\\] donc il faut en moyenne 334 prélèvements avant de détecter une fausse alerte.\n\\(ARL\\) est définie par\n\\[\nARL_\\rho=\\frac 1{1-\\beta}\n\\]\nC’est donc l’inverse de la puissance (efficacité) de la carte, donc plus ce nombre sera petit plus la carte sera efficace.\nSi on reprend les courbes d’efficacité précédente on obtient :\n\n\n\n\n\n\n\nLa production initiale est \\(X\\sim \\mathcal N (\\mu,\\sigma)\\) et la production décentrée vaut \\(\\widetilde X \\sim \\mathcal N (\\mu+\\rho\\sigma,\\sigma)\\). On sait calculer la probabilité \\(1-\\beta\\) de détecter le décentrage en fonction de \\(\\rho\\) et on a donc\n\\[\nARL_\\rho=\\frac 1{1-\\beta}=\\frac 1{1-F(3-\\rho\\sqrt n)+F(-3-\\rho\\sqrt n)}\n\\]\nExemple :\nConsidérons le problème suivant : on a un décentrage de moyenne de 0.5 écart type. On voudrait le détecter en moyenne avant 50 prélèvements. Quelle taille d’échantillon doit-on considérer ?\n\nn&lt;-seq(2,20,by=1)\nrho&lt;-.5\nbeta=pnorm(3-rho*sqrt(n))-pnorm(-3-rho*sqrt(n))\nARL&lt;-1/(1-beta)\nJ&lt;-which.max(ARL&lt;50)\nn[J]\n\n[1] 4\n\n\n\n\n\nPour l’instant les cartes qui ont été proposées ne tiennent pas compte des tolérances imposées par le client. Elles reposent uniquement sur la distribution des observations et sur le % de fausses alertes que l’on souhaite observer (0.3% dans les cartes précédentes).\n\nOn suppose connaître les tolérances \\(TI,TS\\) autorisées par le client.\nOn suppose que la production suit une loi normale \\(\\mathcal N(\\mu,\\sigma).\\)\nOn définit les moyennes maximales refusables (inférieures et supérieures)\n\n\\[\n\\begin{cases}\n\\mu_I=TI+3\\sigma \\\\\n\\mu_S=TS-3\\sigma\n\\end{cases}\n\\]\nCe choix peut être relié au coefficient de performance défini dans le chapitre précédent \\(Cpk=\\frac{\\min\\left(\\mu-TI;TS-\\mu\\right)}{3\\sigma}\\). Si on remplace \\(\\mu\\) par \\(\\mu_I\\) on obtient\n\\(\\frac{\\min\\left(\\mu_I-TI;TS-\\mu_I\\right)}{3\\sigma}=\\min(1;\\frac{TS-TI-3\\sigma}{3\\sigma}).\\) On peut faire un calcul similaire avec \\(\\mu_S.\\)\n\nCe nombre vaut 1 si \\(\\frac{TS-TI-3\\sigma}{3\\sigma}&gt;1\\) ce qui revient à \\(Cap&gt;1.\\) C’est à dire que lorsque le procédé est sous contrôle on va autoriser une déviation de la moyenne.\nCe nombre vaut \\(\\frac{TS-TI-3\\sigma}{3\\sigma}\\) sinon et dans ce cas \\(Cap&lt;1,\\) le procédé ne répond pas aux spécifications imposées par le client. Il faut dans ce cas agir sur le procédé.\n\n\n\n\nPar exemple si on a une prodcution \\(X \\sim \\mathcal N(3,0.5)\\) avec des tolérances \\(TI=1\\) et \\(TS=5\\), on a \\(TS-TI &gt;&gt; 6\\sigma\\) donc on peut faire une carte de la moyenne aux limites modifiées les nouvelles limites \\(LIC^*,LSC^*\\) étant égales à \\(\\mu_I,\\mu_S.\\)\n\n\n\n\nOn peut également définir le déraglage maximal admissible \\(\\rho_{max}\\) par\n\\[\n\\rho_{max}=\\min\\left( \\frac{\\mu_S-\\mu}{\\sigma},\\frac{\\mu-\\mu_I}{\\sigma}\\right)\n\\]\nOn va alors calibrer la taille \\(n\\) des échantillons à prélever de façon à détecter le déréglage maximal admissible à un risque \\(\\beta\\) fixé de ne pas détecter ce déréglage maximal \\(\\rho_max\\). D’après ce qui précède \\(n\\) sera le plus petit entier tel que\n\\[\nn \\geq \\left( \\frac{3+z_{1-\\beta}}{\\rho_{max}} \\right)^2\n\\]\noù \\(z_{1-\\beta}\\) est le quantile d’ordre \\((1-\\beta)\\) de la loi normale.\n\n\nAvec les valeurs précédentes on a \\(\\rho_{max}=3.\\) Si on veut détecter ce déréglage dans 95% des cas alors on doit avoir \\(n \\geq 2.7\\)\nPrélever des échantillons de taille \\(n=3\\) suffit à détecter dans 95% des cas des décentrages d’au moins 3 écarts types.\n\n\n\n\nLa carte de Shewhart de la moyenne est très simple à mettre en oeuvre et à interpréter. Cependant elle n’a pas une très grande efficacité surtout :\n\nen cas de faibles et moyennes déviations\nen cas de structure d’autocorrélation, c’est à dire lorsque le passé a une influence, par exemple lorsqu’une tendance croissante apparaît.\n\nExemple d’application\nOn suit une production de caractéristique \\(\\mu=15\\) et \\(\\sigma=2\\). Pour ce faire 14 prélèvements de 4 unités de production ont été réalisés. On construit la carte de moyenne de Shewhart. A partir du 4ième prélèvement on constate une déviation de la moyenne et un décentrage supérieur. La carte de Shewhart ne détecte cette déviation que très tardivement (14ième prélèvement).\n\n\n\n\n\nUne des solutions est la carte EWMA\n\n\n\n\nEWMA : Exponentially Weighted Moving Average\nOn définit la statistique \\(z_i\\) par une relation de récurrence pour tout \\(i=1,...,k\\)\n\\[\nz_i=\\lambda \\bar x_i +(1-\\lambda)z_{i-1},\n\\]\noù \\(\\bar x_i\\) est la moyenne des unités pour le prélèvement \\(i\\) et \\(0&lt;\\lambda\\leq 1\\) est un réel qui sera choisi en fonction du poids que l’on veut donner aux données précédentes. En effet, en général on choisit \\(z_0=\\mu\\) (moyenne du procédé de fabrication). On a \\[\n\\begin{cases}\nz_1=\\lambda \\bar x_1+(1-\\lambda)\\mu \\\\\nz_2=\\lambda \\bar x_2+(1-\\lambda)z_1= \\lambda \\bar x_2+\\lambda(1-\\lambda)\\bar x_1+(1-\\lambda)^2\\mu \\\\\nz_3=\\lambda \\bar x_3+\\lambda(1-\\lambda)\\bar x_2+\\lambda(1-\\lambda)^2\\bar x_1+\n(1-\\lambda)^3\\mu \\\\\n\\ldots\n\\end{cases}\n\\]\n\n\n\n\n\n\nLa cas \\(\\lambda=1\\) correspond à la carte de Shewhart sur la moyenne.\nOn constate que \\(\\bar x_i\\) a une importance d’autant plus importante dans \\(z_i\\) que \\(\\lambda\\) est grand.\nEn général on utilise \\(0.25&lt;\\lambda&lt;0.5\\).\nLes limites de ces cartes sont variables (en fonction de \\(i\\)) et on a pour une production \\(X\\sim \\mathcal N(\\mu,\\sigma)\\)\n\n\\[\nLC = \\mu  \\pm L\\frac{\\sigma}{\\sqrt{n}}\\times \\sqrt {\\frac{\\lambda}{2-\\lambda}[1-(1-\\lambda)^{2i}] }\n\\]\n\nLorsque le nombre \\(i\\) de prélèvement est très grand alors \\(LC = \\mu \\pm L\\frac{\\sigma}{\\sqrt{n}}\\times \\sqrt {\\frac{\\lambda}{2-\\lambda}}\\). Dans ce cas on peut jouer sur ce paramètre \\(L\\) pour améliorer l’efficacité de la carte en fonction de \\(\\lambda\\).\nOn constate que sur les petites déviations de production l’efficacité des cartes EWMA est bien supérieure à celle de la carte de Shewhart.\n\n\n\n\n\n\nOn peut réaliser la carte sur R concernant l’exemple du chapitre précédent. On constate que contrairement à la carte de la moyenne la carte EWMA détecte le décentrage dès le 8ième prélèvement.\n\nY&lt;-ewma(data,center = 15,std.dev = 2,sizes = 4)"
  },
  {
    "objectID": "cartesCTRL.html#historique",
    "href": "cartesCTRL.html#historique",
    "title": "Cartes de contrôle",
    "section": "",
    "text": "Inventées par Walter A. Shewhart (années 1920)\nS’utilisent dans de très nombreux secteurs d’activité (industrie, transport, service, …)\nSuivi et/ou amélioration d’un système de production\n\nAvantages\n\nTrès faciles à mettre en oeuvre\nTrès faciles à interpréter (graphiques)\n\nInconvénients\n\nNe tient pas a priori compte des tolérances\nN’est pas toujours efficace (ex : si problème de déviation progressive)"
  },
  {
    "objectID": "cartesCTRL.html#comprendre-les-variations-des-procédés-de-fabrication",
    "href": "cartesCTRL.html#comprendre-les-variations-des-procédés-de-fabrication",
    "title": "Cartes de contrôle",
    "section": "",
    "text": "On distingue plusieurs causes qui peuvent induire des variations dans un système de production :\n\ncauses aléatoires (communes) elles sont en grand nombre avec un effet individuel faible. On peut les modéliser par une variable aléatoire (en général gaussienne). Elles peuvent être corrigées par des actions sur le système global. Exemple : temps de trajet domicile-travail. Si il y a des feux rouges sur le trajet ceux-ci pourront être parfois verts ou rouges, il peut y avoir plus ou moins de circulation… Action globale : changer de route pour ne plus avoir de feux rouges !\ncauses assignables (spéciales) elles sont rares et ne peuvent pas être associées directement au procédé de fabrication (Deming 1986). Elles peuvent être corrigées par des actions locales. Exemple : un accident de la route se produit sur le trajet.\n\nUn processus est dit sous contrôle ou statistiquement stable lorsque les variations sont uniquement dûes à des causes aléatoires."
  },
  {
    "objectID": "cartesCTRL.html#cartes-de-contrôles-de-shewhart",
    "href": "cartesCTRL.html#cartes-de-contrôles-de-shewhart",
    "title": "Cartes de contrôle",
    "section": "",
    "text": "On va construire deux graphiques : une carte dite de position et une carte de dispersion.\nExemple\nSuivi de production journalière de steacks hachés surgelés durant 12h de production. Chaque heure on prélève 5 steaks et on les pèse.\n\ndata&lt;-read.csv(\"exemple_carte_Shewhart.csv\")\nkable(head(data))\n\n\n\n\nX\nweight.1\nweight.2\nweight.3\nweight.4\nweight.5\n\n\n\n\n1\n98.6\n100.3\n100.9\n100.2\n99.6\n\n\n2\n100.3\n99.5\n98.9\n100.2\n100.6\n\n\n3\n99.2\n98.8\n101.5\n100.3\n101.0\n\n\n4\n101.1\n97.8\n98.9\n101.3\n101.7\n\n\n5\n101.0\n99.8\n97.3\n99.4\n100.8\n\n\n6\n101.1\n100.1\n99.0\n100.7\n99.9\n\n\n\n\ndf&lt;-data[,-1]\n## Carte de la moyenne avec la librairie qcc dans R\nX&lt;-qcc(df,type=\"xbar\",title=\"Carte de la moyenne\")\n\n\n\n## Carte de l'étendue avec la librairie qcc dans R\nX&lt;-qcc(df,type=\"R\",title=\"Carte de l'étendue\")\n\n\n\n\nPour chaque échantillon de 5 steacks on calcule la moyenne et l’étendue et on les reporte sur les cartes correspondantes.\n\n\n\nOn suppose que tous les paramètres suivent une loi normale.\n\nLa moyenne d’un échantillon \\(\\bar X \\sim \\mathcal N(\\mu,\\frac{\\sigma}{\\sqrt n}).\\)\nL’étendue d’un échantillon \\(R \\sim \\mathcal N(\\mu_R,\\sigma_R).\\)\nL’écart type d’un échantillon \\(S \\sim \\mathcal N(\\mu_S,\\sigma_S).\\)\n\nOn définit alors les limites de surveillance et de contrôle pour chaque carte. Pour la carte de la moyenne :\n On se fixe un risque \\(\\alpha\\) de stoper la production alors que celle-ci est sous contrôle (Fausses alertes). On cherche donc un intervalle de confiance \\(1-\\alpha\\) de \\(\\bar X\\) La distribution des moyennes étant normale on a\n\\[\n\\begin{cases}\nLI=\\mu-z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt n} \\\\\nLS=\\mu+z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt n} \\\\\n\\mathbb P(LI&lt;\\bar X&lt;LS)=1-\\alpha\n\\end{cases}\n\\]\nOn pourra en conclure que la moyenne \\(\\bar X\\) de l’échantillon considéré n’est pas significativement différente de la moyenne \\(\\mu\\) (c’est à dire que le procédé est sous contrôle) si \\(\\bar X \\in [LI,LS].\\)\nLes limites de surveillance sont définies de façon à déterminer, au risque de 4.5%, les moyennes significativement différentes de la moyenne globale :\n\nLimite inférieure de surveillance : \\(LIS=\\mu-2\\frac{\\sigma}{\\sqrt n}\\)\nLimite supérieure de surveillance : \\(LSS=\\mu+2\\frac{\\sigma}{\\sqrt n}\\)\n\nLes limites de contrôle sont définies de façon à déterminer, au risque de 0.3% de fausses alertes, les moyennes significativement différentes de la moyenne globale :\n\nLimite inférieure de contrôle : \\(LIS=\\mu-3\\frac{\\sigma}{\\sqrt n}\\)\nLimite supérieure de contrôle : \\(LSS=\\mu+3\\frac{\\sigma}{\\sqrt n}\\)\n\n\n\n\nReprenons le cas précédent. Pour chaque échantillon on peut calculer \\(\\bar y_j,R_j\\) la moyenne et l’étendue.\nOn a vu dans le chapitre précédent que \\(\\hat\\mu=\\overline{\\overline{y}}=\\frac 1{k} \\displaystyle\\sum_{j=1}^k \\bar y_{j}\\) et que \\(\\hat \\sigma = \\dfrac{\\bar R}{d_2}\\). Donc on a : \\[\n\\begin{cases}\n\\widehat{LIC}= \\bar{\\bar{y}}-\\frac{3}{\\sqrt n} \\frac{\\overline R}{d_2} \\\\\n\\widehat{LSC}= \\bar{\\bar{y}}+\\frac{3}{\\sqrt n} \\frac{\\overline R}{d_2}\n\\end{cases}\n\\]\n\n\n\nPour l’estimation de \\(\\mu_R\\) on prend \\(\\hat\\mu_R=\\bar R\\), et pour l’estimation de \\(\\sigma_R\\) on prend \\(\\hat \\sigma_R=\\frac{d_3}{d_2}\\bar R\\) où \\(d_3\\) est l’écart type des étendues d’une loi normale centrée réduite. On a alors \\[\n\\begin{cases}\n\\widehat{LIC}= \\overline{R}-3\\frac{d_3}{d_2}\\overline R \\\\\n\\widehat{LSC}= \\overline{R}+3\\frac{d_3}{d_2}\\overline R\n\\end{cases}\n\\]"
  },
  {
    "objectID": "cartesCTRL.html#efficacité-des-cartes-de-shewhart",
    "href": "cartesCTRL.html#efficacité-des-cartes-de-shewhart",
    "title": "Cartes de contrôle",
    "section": "",
    "text": "La notion d’efficacité d’une carte de contrôle est sa capacité à détecter un dérèglement alors que la production semble rester sous contrôle.\nLe dérèglement peut concerner un décentrage (dérèglement de la moyenne) ou bien une augmentation de la dispersion.\n\n\n Un décentrage de moyenne est exprimé en nombre d’écart type (unité standardisé) donc si \\(\\mu_1\\) est la moyenne décentrée, on lui associera le décentrage\n\\[\n\\rho=\\frac{|\\mu_1-\\mu|}{\\sigma}\n\\]\nLa probabilité \\(\\beta\\) de ne pas détecter le décentrage est alors\n\\[\n\\beta=\\mathbb P(LIC&lt;\\widetilde X &lt;LSC)\n\\]\noù \\(\\widetilde X \\sim \\mathcal N(\\mu+\\rho\\sigma,\\frac{\\sigma}{n}).\\) Un calcul simple permet d’obtenir\n\\[\n\\beta = F(3-\\rho\\sqrt n)-F(-3-\\rho\\sqrt n)\n\\]\noù \\(F(x)=\\mathbb P(X&lt;x)\\) est la fonction de répartition de la loi normale.\nL’efficacité de la carte est mesurée par \\(1-\\beta\\) (appelée puissance de la carte). \nOn obtient ainsi les courbes d’efficacité de la carte de la moyenne en fonction de la taille \\(n\\) des échantillons prélevés.\n\n\n\n\n\n\nOn constate (ce qui est logique) que la probabilité de ne pas détecter un déréglage donné diminue en fonction de la taille de l’échantillon.\nDétecter un déréglage \\(\\rho=0\\) correspond à une fausse alerte qui vaut pour la carte de la moyenne \\(\\alpha=0.3\\%\\).\n\n\n\n\nIci on considère des décentrages \\(\\rho&gt;1\\) (sinon il s’agit d’une amélioration de la dispersion).\nUn calcul similaire au précédent conduit à \\[\n\\beta=F(\\frac{3}{\\rho})-F(\\frac{-3}{\\rho})\n\\] Ici on constate que l’efficacité de la carte est indépendante de \\(n\\) et qu’elle est très mauvaise. Il faut une très grande valeur de \\(\\rho\\) pour avoir une petite valeur de \\(\\beta\\).\nPar exemple pour \\(\\rho=3\\) on a \\(\\beta=\\) 0.6826895 c’est à dire pour un écart type qui triplerait la probabilité ne peut pas détecter ce dérèglement est de 68.3%."
  },
  {
    "objectID": "cartesCTRL.html#période-opérationelle-moyenne-average-run-length",
    "href": "cartesCTRL.html#période-opérationelle-moyenne-average-run-length",
    "title": "Cartes de contrôle",
    "section": "",
    "text": "La Période Opérationnelle Moyenne correspond au nombre de prélèvements qu’il faut effectuer, en moyenne, pour sortir des limites de contrôle lorsque qu’un déréglage \\(\\rho\\) s’est produit.\nLe cas \\(\\rho=0\\) pour une carte de Shewhart avec des observations indépendantes correspond à une fausse alerte qui se produit dans \\(\\alpha=0.3\\%\\) et correspond à\n\\[\nARL_0=\\frac{1}{0.003}=333\n\\] donc il faut en moyenne 334 prélèvements avant de détecter une fausse alerte.\n\\(ARL\\) est définie par\n\\[\nARL_\\rho=\\frac 1{1-\\beta}\n\\]\nC’est donc l’inverse de la puissance (efficacité) de la carte, donc plus ce nombre sera petit plus la carte sera efficace.\nSi on reprend les courbes d’efficacité précédente on obtient :\n\n\n\n\n\n\n\nLa production initiale est \\(X\\sim \\mathcal N (\\mu,\\sigma)\\) et la production décentrée vaut \\(\\widetilde X \\sim \\mathcal N (\\mu+\\rho\\sigma,\\sigma)\\). On sait calculer la probabilité \\(1-\\beta\\) de détecter le décentrage en fonction de \\(\\rho\\) et on a donc\n\\[\nARL_\\rho=\\frac 1{1-\\beta}=\\frac 1{1-F(3-\\rho\\sqrt n)+F(-3-\\rho\\sqrt n)}\n\\]\nExemple :\nConsidérons le problème suivant : on a un décentrage de moyenne de 0.5 écart type. On voudrait le détecter en moyenne avant 50 prélèvements. Quelle taille d’échantillon doit-on considérer ?\n\nn&lt;-seq(2,20,by=1)\nrho&lt;-.5\nbeta=pnorm(3-rho*sqrt(n))-pnorm(-3-rho*sqrt(n))\nARL&lt;-1/(1-beta)\nJ&lt;-which.max(ARL&lt;50)\nn[J]\n\n[1] 4\n\n\n\n\n\nPour l’instant les cartes qui ont été proposées ne tiennent pas compte des tolérances imposées par le client. Elles reposent uniquement sur la distribution des observations et sur le % de fausses alertes que l’on souhaite observer (0.3% dans les cartes précédentes).\n\nOn suppose connaître les tolérances \\(TI,TS\\) autorisées par le client.\nOn suppose que la production suit une loi normale \\(\\mathcal N(\\mu,\\sigma).\\)\nOn définit les moyennes maximales refusables (inférieures et supérieures)\n\n\\[\n\\begin{cases}\n\\mu_I=TI+3\\sigma \\\\\n\\mu_S=TS-3\\sigma\n\\end{cases}\n\\]\nCe choix peut être relié au coefficient de performance défini dans le chapitre précédent \\(Cpk=\\frac{\\min\\left(\\mu-TI;TS-\\mu\\right)}{3\\sigma}\\). Si on remplace \\(\\mu\\) par \\(\\mu_I\\) on obtient\n\\(\\frac{\\min\\left(\\mu_I-TI;TS-\\mu_I\\right)}{3\\sigma}=\\min(1;\\frac{TS-TI-3\\sigma}{3\\sigma}).\\) On peut faire un calcul similaire avec \\(\\mu_S.\\)\n\nCe nombre vaut 1 si \\(\\frac{TS-TI-3\\sigma}{3\\sigma}&gt;1\\) ce qui revient à \\(Cap&gt;1.\\) C’est à dire que lorsque le procédé est sous contrôle on va autoriser une déviation de la moyenne.\nCe nombre vaut \\(\\frac{TS-TI-3\\sigma}{3\\sigma}\\) sinon et dans ce cas \\(Cap&lt;1,\\) le procédé ne répond pas aux spécifications imposées par le client. Il faut dans ce cas agir sur le procédé.\n\n\n\n\nPar exemple si on a une prodcution \\(X \\sim \\mathcal N(3,0.5)\\) avec des tolérances \\(TI=1\\) et \\(TS=5\\), on a \\(TS-TI &gt;&gt; 6\\sigma\\) donc on peut faire une carte de la moyenne aux limites modifiées les nouvelles limites \\(LIC^*,LSC^*\\) étant égales à \\(\\mu_I,\\mu_S.\\)\n\n\n\n\nOn peut également définir le déraglage maximal admissible \\(\\rho_{max}\\) par\n\\[\n\\rho_{max}=\\min\\left( \\frac{\\mu_S-\\mu}{\\sigma},\\frac{\\mu-\\mu_I}{\\sigma}\\right)\n\\]\nOn va alors calibrer la taille \\(n\\) des échantillons à prélever de façon à détecter le déréglage maximal admissible à un risque \\(\\beta\\) fixé de ne pas détecter ce déréglage maximal \\(\\rho_max\\). D’après ce qui précède \\(n\\) sera le plus petit entier tel que\n\\[\nn \\geq \\left( \\frac{3+z_{1-\\beta}}{\\rho_{max}} \\right)^2\n\\]\noù \\(z_{1-\\beta}\\) est le quantile d’ordre \\((1-\\beta)\\) de la loi normale.\n\n\nAvec les valeurs précédentes on a \\(\\rho_{max}=3.\\) Si on veut détecter ce déréglage dans 95% des cas alors on doit avoir \\(n \\geq 2.7\\)\nPrélever des échantillons de taille \\(n=3\\) suffit à détecter dans 95% des cas des décentrages d’au moins 3 écarts types.\n\n\n\n\nLa carte de Shewhart de la moyenne est très simple à mettre en oeuvre et à interpréter. Cependant elle n’a pas une très grande efficacité surtout :\n\nen cas de faibles et moyennes déviations\nen cas de structure d’autocorrélation, c’est à dire lorsque le passé a une influence, par exemple lorsqu’une tendance croissante apparaît.\n\nExemple d’application\nOn suit une production de caractéristique \\(\\mu=15\\) et \\(\\sigma=2\\). Pour ce faire 14 prélèvements de 4 unités de production ont été réalisés. On construit la carte de moyenne de Shewhart. A partir du 4ième prélèvement on constate une déviation de la moyenne et un décentrage supérieur. La carte de Shewhart ne détecte cette déviation que très tardivement (14ième prélèvement).\n\n\n\n\n\nUne des solutions est la carte EWMA"
  },
  {
    "objectID": "cartesCTRL.html#cartes-ewma",
    "href": "cartesCTRL.html#cartes-ewma",
    "title": "Cartes de contrôle",
    "section": "",
    "text": "EWMA : Exponentially Weighted Moving Average\nOn définit la statistique \\(z_i\\) par une relation de récurrence pour tout \\(i=1,...,k\\)\n\\[\nz_i=\\lambda \\bar x_i +(1-\\lambda)z_{i-1},\n\\]\noù \\(\\bar x_i\\) est la moyenne des unités pour le prélèvement \\(i\\) et \\(0&lt;\\lambda\\leq 1\\) est un réel qui sera choisi en fonction du poids que l’on veut donner aux données précédentes. En effet, en général on choisit \\(z_0=\\mu\\) (moyenne du procédé de fabrication). On a \\[\n\\begin{cases}\nz_1=\\lambda \\bar x_1+(1-\\lambda)\\mu \\\\\nz_2=\\lambda \\bar x_2+(1-\\lambda)z_1= \\lambda \\bar x_2+\\lambda(1-\\lambda)\\bar x_1+(1-\\lambda)^2\\mu \\\\\nz_3=\\lambda \\bar x_3+\\lambda(1-\\lambda)\\bar x_2+\\lambda(1-\\lambda)^2\\bar x_1+\n(1-\\lambda)^3\\mu \\\\\n\\ldots\n\\end{cases}\n\\]\n\n\n\n\n\n\nLa cas \\(\\lambda=1\\) correspond à la carte de Shewhart sur la moyenne.\nOn constate que \\(\\bar x_i\\) a une importance d’autant plus importante dans \\(z_i\\) que \\(\\lambda\\) est grand.\nEn général on utilise \\(0.25&lt;\\lambda&lt;0.5\\).\nLes limites de ces cartes sont variables (en fonction de \\(i\\)) et on a pour une production \\(X\\sim \\mathcal N(\\mu,\\sigma)\\)\n\n\\[\nLC = \\mu  \\pm L\\frac{\\sigma}{\\sqrt{n}}\\times \\sqrt {\\frac{\\lambda}{2-\\lambda}[1-(1-\\lambda)^{2i}] }\n\\]\n\nLorsque le nombre \\(i\\) de prélèvement est très grand alors \\(LC = \\mu \\pm L\\frac{\\sigma}{\\sqrt{n}}\\times \\sqrt {\\frac{\\lambda}{2-\\lambda}}\\). Dans ce cas on peut jouer sur ce paramètre \\(L\\) pour améliorer l’efficacité de la carte en fonction de \\(\\lambda\\).\nOn constate que sur les petites déviations de production l’efficacité des cartes EWMA est bien supérieure à celle de la carte de Shewhart.\n\n\n\n\n\n\nOn peut réaliser la carte sur R concernant l’exemple du chapitre précédent. On constate que contrairement à la carte de la moyenne la carte EWMA détecte le décentrage dès le 8ième prélèvement.\n\nY&lt;-ewma(data,center = 15,std.dev = 2,sizes = 4)"
  },
  {
    "objectID": "capabilite.knit.html",
    "href": "capabilite.knit.html",
    "title": "Capabilité",
    "section": "",
    "text": "Un procédé de fabrication même lorsqu’il est sous contrôle connait des variations aléatoires (peu importantes).\nCes variations sont assignables aux 5M (voir figure ). La dispersion globale du procédé de fabrication notée \\(D_G\\) rend compte de ces fluctuations.\n\n Lien vers le cours de Patrice Hardouin\n\nLes variations qui sont imputables aux machines sont particulièrement étudiées. On note \\(D_M\\) la dispersion due aux machines, on parle aussi de dispersion instantanée.\n\nIl est clair que \\(D_G \\geq D_M.\\)\n\n\n\nOn suppose que les observations suivent une loi normale de moyenne \\(\\mu\\) et d’écart type \\(\\sigma_G\\). Cela permet de dire que la proportion théorique de données dans\n\n\\([\\mu-\\sigma_G,\\mu+\\sigma_G]\\) est de 68.3 %,\n\\([\\mu-2\\sigma_G,\\mu+2\\sigma_G]\\) est de 95.4 %,\n\\([\\mu-3\\sigma_G,\\mu+3\\sigma_G]\\) est de 99.7 %.\n\nAinsi pour la dispersion globale on choisit \\[D_g=6\\sigma_G.\\]\nPour l’estimation de \\(D_M\\) on prélève un échantillon à un instant donné (ainsi les variations sont uniquement dues à la machine) et on suppose là-encore que les valeurs sont distribuées selon une loi normale de moyenne \\(\\mu\\) et d’écart type \\(\\sigma_M.\\) Naturellement, la dispersion instantanée sera définie par \\(D_M=6\\sigma_M.\\)\nLes deux écarts types \\(\\sigma_M,\\sigma_G\\) sont inconnus, en pratique, ils vont être estimés de la façon suivante :\nOn note \\(y_{ij}\\) la valeur \\(i=1,...,n\\) de l’échantillon \\(j=1,...,k.\\)\nExemple : on prélève 25 échantillons de 5 unités de production. Les observations fluctuent autour de \\(y=1\\). Ces fluctuations sont aléatoires et peu importantes (\\(\\pm\\) 5%).\n\n\n\n\n\nUne estimation de \\(\\mu\\) est \\[\\hat \\mu=\\overline{\\overline{y}}=\\frac 1{k} \\displaystyle\\sum_{j=1}^k \\bar y_{j},\\] et une estimation de \\(\\sigma_G\\) est \\[\\hat \\sigma_G= \\sqrt{\\frac{\\displaystyle\\sum_{j=1}^k\\sum_{i=1}^n(y_{ij}-\\hat \\mu)^2}{n\\times k-1}}.\\] Dans l’exemple on a \\(\\hat \\sigma_G=\\) 0.02206.\n\n\n\nIl existe plusieurs estimations possibles de \\(\\sigma_M\\) :\n\nla première est basée sur le calcul des écarts types des \\(k\\) échantillons prélevés.\nla deuxième est basée sur le calcul des étendues des \\(k\\) échantillons prélevés.\n\nPour ces calculs on appliquera des coefficients de correction qui sont donnés en fonction de \\(n\\) dans le tableau suivant. Le coefficient \\(d_2(n)\\) correspond à l’espérance de l’étendue d’une loi normale centrée réduite et \\(c_4(n)\\) à l’espérance de l’écart type d’une loi normale centrée réduite. Ces valeurs peuvent très facilement être obtenues par simulation par exemple pour \\(n=5\\) :\n\nn&lt;-5\nB&lt;-10^6\ns&lt;-rep(NA,B)\nR&lt;-rep(NA,B)\n  for(b in 1:B){\n    X&lt;-rnorm(n)\n    s[b]&lt;-sd(X)\n    R[b]&lt;-max(X)-min(X)\n  }\n  c4&lt;-mean(s)\n  d2&lt;-mean(R)\n  d3&lt;-sd(R)\n\n\n\n\ntable des coefficients c4, d2, d3\n\n\nn\nc4\nd2\nd3\n\n\n\n\n2\n0.7971\n1.1273\n0.8513\n\n\n3\n0.8862\n1.6924\n0.8897\n\n\n4\n0.9214\n2.0591\n0.8791\n\n\n5\n0.9400\n2.3262\n0.8645\n\n\n6\n0.9514\n2.5344\n0.8486\n\n\n7\n0.9593\n2.7046\n0.8340\n\n\n8\n0.9643\n2.8455\n0.8195\n\n\n9\n0.9695\n2.9704\n0.8076\n\n\n10\n0.9730\n3.0786\n0.7969\n\n\n\n\n\n\n\nOn sait pour chaque échantillon \\(j\\) de \\(n\\) valeurs calculer une estimation de l’écart type \\(\\sigma_j\\) en calculant \\[s_j= \\sqrt{\\frac{\\displaystyle\\sum_{i=1}^n(y_{ij}-\\bar y_j)^2}{n-1}},\\] où \\(\\bar y_j\\) est la moyenne de l’échantillon \\(j.\\)\nDans l’exemple les premiers écarts types valent\n\n\n\n\n\nsample\ns_j\n\n\n\n\n1\n0.01560\n\n\n2\n0.01229\n\n\n3\n0.02588\n\n\n4\n0.01433\n\n\n5\n0.02207\n\n\n6\n0.02400\n\n\n\n\n\nOn pose \\(\\bar S =\\frac{\\sum_{j=1}^k s_j}{k}\\) et alors une estimation de l’écart type instantané \\(\\sigma_M\\) est donné par\n\\[\n\\hat \\sigma_M=\\dfrac{\\bar S}{c_4}\n\\] où \\(c_4\\) est donné dans la table 1.\nOn obtient \\(\\hat \\sigma_M=\\) 0.0228258\n\n\n\nPour chaque échantillon \\(j\\) on calcule l’étendue\n\\[\nR_j=\\max(y_{ij})-\\min(y_{ij})\n\\]\nOn pose \\(\\bar R =\\frac{\\sum_{j=1}^k R_j}{k}\\) et alors une estimation de l’écart type instantané \\(\\sigma_M\\) est donné par\n\\[\n\\hat \\sigma_M=\\dfrac{\\bar R}{d_2}\n\\]\noù \\(d_2\\) est donné dans la table 1.\nRetour à l’exemple\n\n\n\n\n\nsample\nR_j\n\n\n\n\n1\n0.04128\n\n\n2\n0.02866\n\n\n3\n0.07048\n\n\n4\n0.03681\n\n\n5\n0.05540\n\n\n6\n0.06414\n\n\n\n\n\nOn obtient \\(\\hat \\sigma_M=\\) r\nOn constate que les estimations obtenues à partir de \\(\\bar R\\) ou de \\(\\bar S\\) sont proches.\n\n\n\n\n\n\nDans la suite \\(TS,TI\\) désigneront la tolérance supérieure et inférieure du procédé de fabrication.\nComme précédemment on distingue la variabilité globale du procédé et celle uniquement attribuable à la machine.\nOn définit deux types d’indices de capabilité :\n\nLa capabilité globale du procédé de fabrication (appelée aussi coefficient d’aptitude du procédé) \\[\nCap=\\frac{TS-TI}{D_G}\n\\]\nLa capabilité machine (appelée aussi coefficient d’aptitude du moyen)\n\n\\[\nCam=\\frac{TS-TI}{D_M}\n\\]\n\n\n\nIl est clair que lorsque \\(Cap&lt;1\\) le procédé n’est pas capable, il faut le revoir afin d’obtenir une production conforme aux tolérances. Par contre si \\(Cap&gt;2\\) on va considérer que le procédé est capable dans la mesure où la dispersion naturelle des observation est 2 fois moins importante que l’intervalle de tolérance.\nLes deux indicateurs précédents ont un gros inconvénient dans la mesure où ils ne permettent pas de juger du décentrage éventuel du procédé. Par exemple, dans le cas d’une loi normale, on peut avoir une situation comme celle ci-dessous :\n On voit que le procédé est bien dans l’intervalle de tolérance avec une valeur \\(Cap&gt;2\\) mais qu’il est clairement décentré. Donc il faut définir de nouveaux indices de capabilité qui vont permettre de juger de la justesse du procédé !\n\n\n\n\nLe coefficient de performance du procédé est\n\\[\nCpk=\\frac{\\min\\left(\\mu-TI;TS-\\mu\\right)}{3\\sigma_{g}},\n\\]\net celui la machine est\n\\[\nCmk=\\frac{\\min\\left(\\mu-TI;TS-\\mu\\right)}{3\\sigma_{i}}.\n\\]\nIl est clair que l’on a :\n\n\\(Cap&gt;Cpk,\\)\n\\(Cam&gt;Cmk.\\)\n\nOn utilisera la norme suivante :\nUn procédé (respectivement une machine) est capable si \\(Cpk&gt;1.33\\) (respectivement \\(Cmk&gt;1.33\\))\n\n\nLes calculs de \\(Cap\\) et de \\(Cpk\\) sont basés sur des estimations de l’écart type \\(\\sigma_G\\). Dans le cas d’une loi normale on sait construire un intervalle de confiance de \\(\\sigma_G\\), on en déduit que\n\nL’intervalle \\(\\left[\\widehat C_{ap}\\sqrt{\\dfrac{\\chi^2_{n-1}(\\alpha/2)}{n-1}};\\widehat C_{ap}\\sqrt{\\dfrac{\\chi^2_{n-1}(1-\\alpha/2)}{n-1}}\\right]\\) est un intervalle de confiance de \\(Cap\\) au niveau de confiance \\(100(1-\\alpha)\\) %.\nL’intervalle \\(\\left[\\widehat C_{pk}\\left(1-z_{1-\\alpha/2}\\sqrt{\\dfrac{1}{9n\\widehat C_{pk}^2}+\\dfrac{1}{2(n-1)}}\\right);\\widehat C_{pk}\\left( 1+z_{1-\\alpha/2}\\sqrt{\\dfrac{1}{9n\\widehat C_{pk}^2}+\\dfrac{1}{2(n-1)}}\\right)\\right]\\) est un intervalle de confiance de \\(C_{pk}\\) au niveau de confiance \\(100(1-\\alpha)\\) %.\n\n\n\n\nOn suppose que les tolérance sont \\(TI=0.9\\) et \\(TS=1.1\\).\nOn a \\(\\hat Cap=\\) 1.51 et \\(\\hat Cam=\\) 1.43.\nLa moyenne du procédé est estimé par \\(\\hat \\mu=\\overline{\\overline X}=\\) 0.999. Donc on a \\(\\hat Cpk=\\) 1.5 et \\(\\hat Cmk=\\) 1.41.\nL’intervalle de confiance de \\(Cap\\) est 1.32, 1.7 et celui de \\(Cpk\\) est 1.3, 1.69."
  },
  {
    "objectID": "capabilite.knit.html#introduction",
    "href": "capabilite.knit.html#introduction",
    "title": "Capabilité",
    "section": "",
    "text": "Un procédé de fabrication même lorsqu’il est sous contrôle connait des variations aléatoires (peu importantes).\nCes variations sont assignables aux 5M (voir figure ). La dispersion globale du procédé de fabrication notée \\(D_G\\) rend compte de ces fluctuations.\n\n Lien vers le cours de Patrice Hardouin\n\nLes variations qui sont imputables aux machines sont particulièrement étudiées. On note \\(D_M\\) la dispersion due aux machines, on parle aussi de dispersion instantanée.\n\nIl est clair que \\(D_G \\geq D_M.\\)"
  },
  {
    "objectID": "capabilite.knit.html#estimation-de-la-dispersion-globale",
    "href": "capabilite.knit.html#estimation-de-la-dispersion-globale",
    "title": "Capabilité",
    "section": "",
    "text": "On suppose que les observations suivent une loi normale de moyenne \\(\\mu\\) et d’écart type \\(\\sigma_G\\). Cela permet de dire que la proportion théorique de données dans\n\n\\([\\mu-\\sigma_G,\\mu+\\sigma_G]\\) est de 68.3 %,\n\\([\\mu-2\\sigma_G,\\mu+2\\sigma_G]\\) est de 95.4 %,\n\\([\\mu-3\\sigma_G,\\mu+3\\sigma_G]\\) est de 99.7 %.\n\nAinsi pour la dispersion globale on choisit \\[D_g=6\\sigma_G.\\]\nPour l’estimation de \\(D_M\\) on prélève un échantillon à un instant donné (ainsi les variations sont uniquement dues à la machine) et on suppose là-encore que les valeurs sont distribuées selon une loi normale de moyenne \\(\\mu\\) et d’écart type \\(\\sigma_M.\\) Naturellement, la dispersion instantanée sera définie par \\(D_M=6\\sigma_M.\\)\nLes deux écarts types \\(\\sigma_M,\\sigma_G\\) sont inconnus, en pratique, ils vont être estimés de la façon suivante :\nOn note \\(y_{ij}\\) la valeur \\(i=1,...,n\\) de l’échantillon \\(j=1,...,k.\\)\nExemple : on prélève 25 échantillons de 5 unités de production. Les observations fluctuent autour de \\(y=1\\). Ces fluctuations sont aléatoires et peu importantes (\\(\\pm\\) 5%).\n\n\n\n\n\nUne estimation de \\(\\mu\\) est \\[\\hat \\mu=\\overline{\\overline{y}}=\\frac 1{k} \\displaystyle\\sum_{j=1}^k \\bar y_{j},\\] et une estimation de \\(\\sigma_G\\) est \\[\\hat \\sigma_G= \\sqrt{\\frac{\\displaystyle\\sum_{j=1}^k\\sum_{i=1}^n(y_{ij}-\\hat \\mu)^2}{n\\times k-1}}.\\] Dans l’exemple on a \\(\\hat \\sigma_G=\\) 0.02206."
  },
  {
    "objectID": "capabilite.knit.html#estimation-de-la-dispersion-instantanée",
    "href": "capabilite.knit.html#estimation-de-la-dispersion-instantanée",
    "title": "Capabilité",
    "section": "",
    "text": "Il existe plusieurs estimations possibles de \\(\\sigma_M\\) :\n\nla première est basée sur le calcul des écarts types des \\(k\\) échantillons prélevés.\nla deuxième est basée sur le calcul des étendues des \\(k\\) échantillons prélevés.\n\nPour ces calculs on appliquera des coefficients de correction qui sont donnés en fonction de \\(n\\) dans le tableau suivant. Le coefficient \\(d_2(n)\\) correspond à l’espérance de l’étendue d’une loi normale centrée réduite et \\(c_4(n)\\) à l’espérance de l’écart type d’une loi normale centrée réduite. Ces valeurs peuvent très facilement être obtenues par simulation par exemple pour \\(n=5\\) :\n\nn&lt;-5\nB&lt;-10^6\ns&lt;-rep(NA,B)\nR&lt;-rep(NA,B)\n  for(b in 1:B){\n    X&lt;-rnorm(n)\n    s[b]&lt;-sd(X)\n    R[b]&lt;-max(X)-min(X)\n  }\n  c4&lt;-mean(s)\n  d2&lt;-mean(R)\n  d3&lt;-sd(R)\n\n\n\n\ntable des coefficients c4, d2, d3\n\n\nn\nc4\nd2\nd3\n\n\n\n\n2\n0.7971\n1.1273\n0.8513\n\n\n3\n0.8862\n1.6924\n0.8897\n\n\n4\n0.9214\n2.0591\n0.8791\n\n\n5\n0.9400\n2.3262\n0.8645\n\n\n6\n0.9514\n2.5344\n0.8486\n\n\n7\n0.9593\n2.7046\n0.8340\n\n\n8\n0.9643\n2.8455\n0.8195\n\n\n9\n0.9695\n2.9704\n0.8076\n\n\n10\n0.9730\n3.0786\n0.7969\n\n\n\n\n\n\n\nOn sait pour chaque échantillon \\(j\\) de \\(n\\) valeurs calculer une estimation de l’écart type \\(\\sigma_j\\) en calculant \\[s_j= \\sqrt{\\frac{\\displaystyle\\sum_{i=1}^n(y_{ij}-\\bar y_j)^2}{n-1}},\\] où \\(\\bar y_j\\) est la moyenne de l’échantillon \\(j.\\)\nDans l’exemple les premiers écarts types valent\n\n\n\n\n\nsample\ns_j\n\n\n\n\n1\n0.01560\n\n\n2\n0.01229\n\n\n3\n0.02588\n\n\n4\n0.01433\n\n\n5\n0.02207\n\n\n6\n0.02400\n\n\n\n\n\nOn pose \\(\\bar S =\\frac{\\sum_{j=1}^k s_j}{k}\\) et alors une estimation de l’écart type instantané \\(\\sigma_M\\) est donné par\n\\[\n\\hat \\sigma_M=\\dfrac{\\bar S}{c_4}\n\\] où \\(c_4\\) est donné dans la table 1.\nOn obtient \\(\\hat \\sigma_M=\\) 0.0228258\n\n\n\nPour chaque échantillon \\(j\\) on calcule l’étendue\n\\[\nR_j=\\max(y_{ij})-\\min(y_{ij})\n\\]\nOn pose \\(\\bar R =\\frac{\\sum_{j=1}^k R_j}{k}\\) et alors une estimation de l’écart type instantané \\(\\sigma_M\\) est donné par\n\\[\n\\hat \\sigma_M=\\dfrac{\\bar R}{d_2}\n\\]\noù \\(d_2\\) est donné dans la table 1.\nRetour à l’exemple\n\n\n\n\n\nsample\nR_j\n\n\n\n\n1\n0.04128\n\n\n2\n0.02866\n\n\n3\n0.07048\n\n\n4\n0.03681\n\n\n5\n0.05540\n\n\n6\n0.06414\n\n\n\n\n\nOn obtient \\(\\hat \\sigma_M=\\) r\nOn constate que les estimations obtenues à partir de \\(\\bar R\\) ou de \\(\\bar S\\) sont proches."
  },
  {
    "objectID": "capabilite.knit.html#indices-de-capabilité-globale",
    "href": "capabilite.knit.html#indices-de-capabilité-globale",
    "title": "Capabilité",
    "section": "",
    "text": "Dans la suite \\(TS,TI\\) désigneront la tolérance supérieure et inférieure du procédé de fabrication.\nComme précédemment on distingue la variabilité globale du procédé et celle uniquement attribuable à la machine.\nOn définit deux types d’indices de capabilité :\n\nLa capabilité globale du procédé de fabrication (appelée aussi coefficient d’aptitude du procédé) \\[\nCap=\\frac{TS-TI}{D_G}\n\\]\nLa capabilité machine (appelée aussi coefficient d’aptitude du moyen)\n\n\\[\nCam=\\frac{TS-TI}{D_M}\n\\]\n\n\n\nIl est clair que lorsque \\(Cap&lt;1\\) le procédé n’est pas capable, il faut le revoir afin d’obtenir une production conforme aux tolérances. Par contre si \\(Cap&gt;2\\) on va considérer que le procédé est capable dans la mesure où la dispersion naturelle des observation est 2 fois moins importante que l’intervalle de tolérance.\nLes deux indicateurs précédents ont un gros inconvénient dans la mesure où ils ne permettent pas de juger du décentrage éventuel du procédé. Par exemple, dans le cas d’une loi normale, on peut avoir une situation comme celle ci-dessous :\n On voit que le procédé est bien dans l’intervalle de tolérance avec une valeur \\(Cap&gt;2\\) mais qu’il est clairement décentré. Donc il faut définir de nouveaux indices de capabilité qui vont permettre de juger de la justesse du procédé !"
  },
  {
    "objectID": "capabilite.knit.html#indices-de-capabilité-de-centrage",
    "href": "capabilite.knit.html#indices-de-capabilité-de-centrage",
    "title": "Capabilité",
    "section": "",
    "text": "Le coefficient de performance du procédé est\n\\[\nCpk=\\frac{\\min\\left(\\mu-TI;TS-\\mu\\right)}{3\\sigma_{g}},\n\\]\net celui la machine est\n\\[\nCmk=\\frac{\\min\\left(\\mu-TI;TS-\\mu\\right)}{3\\sigma_{i}}.\n\\]\nIl est clair que l’on a :\n\n\\(Cap&gt;Cpk,\\)\n\\(Cam&gt;Cmk.\\)\n\nOn utilisera la norme suivante :\nUn procédé (respectivement une machine) est capable si \\(Cpk&gt;1.33\\) (respectivement \\(Cmk&gt;1.33\\))\n\n\nLes calculs de \\(Cap\\) et de \\(Cpk\\) sont basés sur des estimations de l’écart type \\(\\sigma_G\\). Dans le cas d’une loi normale on sait construire un intervalle de confiance de \\(\\sigma_G\\), on en déduit que\n\nL’intervalle \\(\\left[\\widehat C_{ap}\\sqrt{\\dfrac{\\chi^2_{n-1}(\\alpha/2)}{n-1}};\\widehat C_{ap}\\sqrt{\\dfrac{\\chi^2_{n-1}(1-\\alpha/2)}{n-1}}\\right]\\) est un intervalle de confiance de \\(Cap\\) au niveau de confiance \\(100(1-\\alpha)\\) %.\nL’intervalle \\(\\left[\\widehat C_{pk}\\left(1-z_{1-\\alpha/2}\\sqrt{\\dfrac{1}{9n\\widehat C_{pk}^2}+\\dfrac{1}{2(n-1)}}\\right);\\widehat C_{pk}\\left( 1+z_{1-\\alpha/2}\\sqrt{\\dfrac{1}{9n\\widehat C_{pk}^2}+\\dfrac{1}{2(n-1)}}\\right)\\right]\\) est un intervalle de confiance de \\(C_{pk}\\) au niveau de confiance \\(100(1-\\alpha)\\) %.\n\n\n\n\nOn suppose que les tolérance sont \\(TI=0.9\\) et \\(TS=1.1\\).\nOn a \\(\\hat Cap=\\) 1.51 et \\(\\hat Cam=\\) 1.43.\nLa moyenne du procédé est estimé par \\(\\hat \\mu=\\overline{\\overline X}=\\) 0.999. Donc on a \\(\\hat Cpk=\\) 1.5 et \\(\\hat Cmk=\\) 1.41.\nL’intervalle de confiance de \\(Cap\\) est 1.32, 1.7 et celui de \\(Cpk\\) est 1.3, 1.69."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "capabilite.html",
    "href": "capabilite.html",
    "title": "Capabilité",
    "section": "",
    "text": "Un procédé de fabrication même lorsqu’il est sous contrôle connait des variations aléatoires (peu importantes).\nCes variations sont assignables aux 5M (voir figure ). La dispersion globale du procédé de fabrication notée \\(D_G\\) rend compte de ces fluctuations.\n\n Lien vers le cours de Patrice Hardouin\n\nLes variations qui sont imputables aux machines sont particulièrement étudiées. On note \\(D_M\\) la dispersion due aux machines, on parle aussi de dispersion instantanée.\n\nIl est clair que \\(D_G \\geq D_M.\\)\n\n\n\nOn suppose que les observations suivent une loi normale de moyenne \\(\\mu\\) et d’écart type \\(\\sigma_G\\). Cela permet de dire que la proportion théorique de données dans\n\n\\([\\mu-\\sigma_G,\\mu+\\sigma_G]\\) est de 68.3 %,\n\\([\\mu-2\\sigma_G,\\mu+2\\sigma_G]\\) est de 95.4 %,\n\\([\\mu-3\\sigma_G,\\mu+3\\sigma_G]\\) est de 99.7 %.\n\nAinsi pour la dispersion globale on choisit \\[D_g=6\\sigma_G.\\]\nPour l’estimation de \\(D_M\\) on prélève un échantillon à un instant donné (ainsi les variations sont uniquement dues à la machine) et on suppose là-encore que les valeurs sont distribuées selon une loi normale de moyenne \\(\\mu\\) et d’écart type \\(\\sigma_M.\\) Naturellement, la dispersion instantanée sera définie par \\(D_M=6\\sigma_M.\\)\nLes deux écarts types \\(\\sigma_M,\\sigma_G\\) sont inconnus, en pratique, ils vont être estimés de la façon suivante :\nOn note \\(y_{ij}\\) la valeur \\(i=1,...,n\\) de l’échantillon \\(j=1,...,k.\\)\nExemple : on prélève 25 échantillons de 5 unités de production. Les observations fluctuent autour de \\(y=1\\). Ces fluctuations sont aléatoires et peu importantes (\\(\\pm\\) 5%).\n\n\n\n\n\nUne estimation de \\(\\mu\\) est \\[\\hat \\mu=\\overline{\\overline{y}}=\\frac 1{k} \\displaystyle\\sum_{j=1}^k \\bar y_{j},\\] et une estimation de \\(\\sigma_G\\) est \\[\\hat \\sigma_G= \\sqrt{\\frac{\\displaystyle\\sum_{j=1}^k\\sum_{i=1}^n(y_{ij}-\\hat \\mu)^2}{n\\times k-1}}.\\] Dans l’exemple on a \\(\\hat \\sigma_G=\\) 0.02206.\n\n\n\nIl existe plusieurs estimations possibles de \\(\\sigma_M\\) :\n\nla première est basée sur le calcul des écarts types des \\(k\\) échantillons prélevés.\nla deuxième est basée sur le calcul des étendues des \\(k\\) échantillons prélevés.\n\nPour ces calculs on appliquera des coefficients de correction qui sont donnés en fonction de \\(n\\) dans le tableau suivant. Le coefficient \\(d_2(n)\\) correspond à l’espérance de l’étendue d’une loi normale centrée réduite et \\(c_4(n)\\) à l’espérance de l’écart type d’une loi normale centrée réduite. Ces valeurs peuvent très facilement être obtenues par simulation par exemple pour \\(n=5\\) :\n\nn&lt;-5\nB&lt;-10^6\ns&lt;-rep(NA,B)\nR&lt;-rep(NA,B)\n  for(b in 1:B){\n    X&lt;-rnorm(n)\n    s[b]&lt;-sd(X)\n    R[b]&lt;-max(X)-min(X)\n  }\n  c4&lt;-mean(s)\n  d2&lt;-mean(R)\n  d3&lt;-sd(R)\n\n\n\n\ntable des coefficients c4, d2, d3\n\n\nn\nc4\nd2\nd3\n\n\n\n\n2\n0.7971\n1.1273\n0.8513\n\n\n3\n0.8862\n1.6924\n0.8897\n\n\n4\n0.9214\n2.0591\n0.8791\n\n\n5\n0.9400\n2.3262\n0.8645\n\n\n6\n0.9514\n2.5344\n0.8486\n\n\n7\n0.9593\n2.7046\n0.8340\n\n\n8\n0.9643\n2.8455\n0.8195\n\n\n9\n0.9695\n2.9704\n0.8076\n\n\n10\n0.9730\n3.0786\n0.7969\n\n\n\n\n\n\n\nOn sait pour chaque échantillon \\(j\\) de \\(n\\) valeurs calculer une estimation de l’écart type \\(\\sigma_j\\) en calculant \\[s_j= \\sqrt{\\frac{\\displaystyle\\sum_{i=1}^n(y_{ij}-\\bar y_j)^2}{n-1}},\\] où \\(\\bar y_j\\) est la moyenne de l’échantillon \\(j.\\)\nDans l’exemple les premiers écarts types valent\n\n\n\n\n\nsample\ns_j\n\n\n\n\n1\n0.01560\n\n\n2\n0.01229\n\n\n3\n0.02588\n\n\n4\n0.01433\n\n\n5\n0.02207\n\n\n6\n0.02400\n\n\n\n\n\nOn pose \\(\\bar S =\\frac{\\sum_{j=1}^k s_j}{k}\\) et alors une estimation de l’écart type instantané \\(\\sigma_M\\) est donné par\n\\[\n\\hat \\sigma_M=\\dfrac{\\bar S}{c_4}\n\\] où \\(c_4\\) est donné dans la table 1.\nOn obtient \\(\\hat \\sigma_M=\\) 0.0228258\n\n\n\nPour chaque échantillon \\(j\\) on calcule l’étendue\n\\[\nR_j=\\max(y_{ij})-\\min(y_{ij})\n\\]\nOn pose \\(\\bar R =\\frac{\\sum_{j=1}^k R_j}{k}\\) et alors une estimation de l’écart type instantané \\(\\sigma_M\\) est donné par\n\\[\n\\hat \\sigma_M=\\dfrac{\\bar R}{d_2}\n\\]\noù \\(d_2\\) est donné dans la table 1.\nRetour à l’exemple\n\n\n\n\n\nsample\nR_j\n\n\n\n\n1\n0.04128\n\n\n2\n0.02866\n\n\n3\n0.07048\n\n\n4\n0.03681\n\n\n5\n0.05540\n\n\n6\n0.06414\n\n\n\n\n\nOn obtient \\(\\hat \\sigma_M=\\) r\nOn constate que les estimations obtenues à partir de \\(\\bar R\\) ou de \\(\\bar S\\) sont proches.\n\n\n\n\n\n\nDans la suite \\(TS,TI\\) désigneront la tolérance supérieure et inférieure du procédé de fabrication.\nComme précédemment on distingue la variabilité globale du procédé et celle uniquement attribuable à la machine.\nOn définit deux types d’indices de capabilité :\n\nLa capabilité globale du procédé de fabrication (appelée aussi coefficient d’aptitude du procédé) \\[\nCap=\\frac{TS-TI}{D_G}\n\\]\nLa capabilité machine (appelée aussi coefficient d’aptitude du moyen)\n\n\\[\nCam=\\frac{TS-TI}{D_M}\n\\]\n\n\n\nIl est clair que lorsque \\(Cap&lt;1\\) le procédé n’est pas capable, il faut le revoir afin d’obtenir une production conforme aux tolérances. Par contre si \\(Cap&gt;2\\) on va considérer que le procédé est capable dans la mesure où la dispersion naturelle des observation est 2 fois moins importante que l’intervalle de tolérance.\nLes deux indicateurs précédents ont un gros inconvénient dans la mesure où ils ne permettent pas de juger du décentrage éventuel du procédé. Par exemple, dans le cas d’une loi normale, on peut avoir une situation comme celle ci-dessous :\n On voit que le procédé est bien dans l’intervalle de tolérance avec une valeur \\(Cap&gt;2\\) mais qu’il est clairement décentré. Donc il faut définir de nouveaux indices de capabilité qui vont permettre de juger de la justesse du procédé !\n\n\n\n\nLe coefficient de performance du procédé est\n\\[\nCpk=\\frac{\\min\\left(\\mu-TI;TS-\\mu\\right)}{3\\sigma_{g}},\n\\]\net celui la machine est\n\\[\nCmk=\\frac{\\min\\left(\\mu-TI;TS-\\mu\\right)}{3\\sigma_{i}}.\n\\]\nIl est clair que l’on a :\n\n\\(Cap&gt;Cpk,\\)\n\\(Cam&gt;Cmk.\\)\n\nOn utilisera la norme suivante :\nUn procédé (respectivement une machine) est capable si \\(Cpk&gt;1.33\\) (respectivement \\(Cmk&gt;1.33\\))\n\n\nLes calculs de \\(Cap\\) et de \\(Cpk\\) sont basés sur des estimations de l’écart type \\(\\sigma_G\\). Dans le cas d’une loi normale on sait construire un intervalle de confiance de \\(\\sigma_G\\), on en déduit que\n\nL’intervalle \\(\\left[\\widehat C_{ap}\\sqrt{\\dfrac{\\chi^2_{n-1}(\\alpha/2)}{n-1}};\\widehat C_{ap}\\sqrt{\\dfrac{\\chi^2_{n-1}(1-\\alpha/2)}{n-1}}\\right]\\) est un intervalle de confiance de \\(Cap\\) au niveau de confiance \\(100(1-\\alpha)\\) %.\nL’intervalle \\(\\left[\\widehat C_{pk}\\left(1-z_{1-\\alpha/2}\\sqrt{\\dfrac{1}{9n\\widehat C_{pk}^2}+\\dfrac{1}{2(n-1)}}\\right);\\widehat C_{pk}\\left( 1+z_{1-\\alpha/2}\\sqrt{\\dfrac{1}{9n\\widehat C_{pk}^2}+\\dfrac{1}{2(n-1)}}\\right)\\right]\\) est un intervalle de confiance de \\(C_{pk}\\) au niveau de confiance \\(100(1-\\alpha)\\) %.\n\n\n\n\nOn suppose que les tolérance sont \\(TI=0.9\\) et \\(TS=1.1\\).\nOn a \\(\\hat Cap=\\) 1.51 et \\(\\hat Cam=\\) 1.43.\nLa moyenne du procédé est estimé par \\(\\hat \\mu=\\overline{\\overline X}=\\) 0.999. Donc on a \\(\\hat Cpk=\\) 1.5 et \\(\\hat Cmk=\\) 1.41.\nL’intervalle de confiance de \\(Cap\\) est 1.32, 1.7 et celui de \\(Cpk\\) est 1.3, 1.69."
  },
  {
    "objectID": "capabilite.html#introduction",
    "href": "capabilite.html#introduction",
    "title": "Capabilité",
    "section": "",
    "text": "Un procédé de fabrication même lorsqu’il est sous contrôle connait des variations aléatoires (peu importantes).\nCes variations sont assignables aux 5M (voir figure ). La dispersion globale du procédé de fabrication notée \\(D_G\\) rend compte de ces fluctuations.\n\n Lien vers le cours de Patrice Hardouin\n\nLes variations qui sont imputables aux machines sont particulièrement étudiées. On note \\(D_M\\) la dispersion due aux machines, on parle aussi de dispersion instantanée.\n\nIl est clair que \\(D_G \\geq D_M.\\)"
  },
  {
    "objectID": "capabilite.html#estimation-de-la-dispersion-globale",
    "href": "capabilite.html#estimation-de-la-dispersion-globale",
    "title": "Capabilité",
    "section": "",
    "text": "On suppose que les observations suivent une loi normale de moyenne \\(\\mu\\) et d’écart type \\(\\sigma_G\\). Cela permet de dire que la proportion théorique de données dans\n\n\\([\\mu-\\sigma_G,\\mu+\\sigma_G]\\) est de 68.3 %,\n\\([\\mu-2\\sigma_G,\\mu+2\\sigma_G]\\) est de 95.4 %,\n\\([\\mu-3\\sigma_G,\\mu+3\\sigma_G]\\) est de 99.7 %.\n\nAinsi pour la dispersion globale on choisit \\[D_g=6\\sigma_G.\\]\nPour l’estimation de \\(D_M\\) on prélève un échantillon à un instant donné (ainsi les variations sont uniquement dues à la machine) et on suppose là-encore que les valeurs sont distribuées selon une loi normale de moyenne \\(\\mu\\) et d’écart type \\(\\sigma_M.\\) Naturellement, la dispersion instantanée sera définie par \\(D_M=6\\sigma_M.\\)\nLes deux écarts types \\(\\sigma_M,\\sigma_G\\) sont inconnus, en pratique, ils vont être estimés de la façon suivante :\nOn note \\(y_{ij}\\) la valeur \\(i=1,...,n\\) de l’échantillon \\(j=1,...,k.\\)\nExemple : on prélève 25 échantillons de 5 unités de production. Les observations fluctuent autour de \\(y=1\\). Ces fluctuations sont aléatoires et peu importantes (\\(\\pm\\) 5%).\n\n\n\n\n\nUne estimation de \\(\\mu\\) est \\[\\hat \\mu=\\overline{\\overline{y}}=\\frac 1{k} \\displaystyle\\sum_{j=1}^k \\bar y_{j},\\] et une estimation de \\(\\sigma_G\\) est \\[\\hat \\sigma_G= \\sqrt{\\frac{\\displaystyle\\sum_{j=1}^k\\sum_{i=1}^n(y_{ij}-\\hat \\mu)^2}{n\\times k-1}}.\\] Dans l’exemple on a \\(\\hat \\sigma_G=\\) 0.02206."
  },
  {
    "objectID": "capabilite.html#estimation-de-la-dispersion-instantanée",
    "href": "capabilite.html#estimation-de-la-dispersion-instantanée",
    "title": "Capabilité",
    "section": "",
    "text": "Il existe plusieurs estimations possibles de \\(\\sigma_M\\) :\n\nla première est basée sur le calcul des écarts types des \\(k\\) échantillons prélevés.\nla deuxième est basée sur le calcul des étendues des \\(k\\) échantillons prélevés.\n\nPour ces calculs on appliquera des coefficients de correction qui sont donnés en fonction de \\(n\\) dans le tableau suivant. Le coefficient \\(d_2(n)\\) correspond à l’espérance de l’étendue d’une loi normale centrée réduite et \\(c_4(n)\\) à l’espérance de l’écart type d’une loi normale centrée réduite. Ces valeurs peuvent très facilement être obtenues par simulation par exemple pour \\(n=5\\) :\n\nn&lt;-5\nB&lt;-10^6\ns&lt;-rep(NA,B)\nR&lt;-rep(NA,B)\n  for(b in 1:B){\n    X&lt;-rnorm(n)\n    s[b]&lt;-sd(X)\n    R[b]&lt;-max(X)-min(X)\n  }\n  c4&lt;-mean(s)\n  d2&lt;-mean(R)\n  d3&lt;-sd(R)\n\n\n\n\ntable des coefficients c4, d2, d3\n\n\nn\nc4\nd2\nd3\n\n\n\n\n2\n0.7971\n1.1273\n0.8513\n\n\n3\n0.8862\n1.6924\n0.8897\n\n\n4\n0.9214\n2.0591\n0.8791\n\n\n5\n0.9400\n2.3262\n0.8645\n\n\n6\n0.9514\n2.5344\n0.8486\n\n\n7\n0.9593\n2.7046\n0.8340\n\n\n8\n0.9643\n2.8455\n0.8195\n\n\n9\n0.9695\n2.9704\n0.8076\n\n\n10\n0.9730\n3.0786\n0.7969\n\n\n\n\n\n\n\nOn sait pour chaque échantillon \\(j\\) de \\(n\\) valeurs calculer une estimation de l’écart type \\(\\sigma_j\\) en calculant \\[s_j= \\sqrt{\\frac{\\displaystyle\\sum_{i=1}^n(y_{ij}-\\bar y_j)^2}{n-1}},\\] où \\(\\bar y_j\\) est la moyenne de l’échantillon \\(j.\\)\nDans l’exemple les premiers écarts types valent\n\n\n\n\n\nsample\ns_j\n\n\n\n\n1\n0.01560\n\n\n2\n0.01229\n\n\n3\n0.02588\n\n\n4\n0.01433\n\n\n5\n0.02207\n\n\n6\n0.02400\n\n\n\n\n\nOn pose \\(\\bar S =\\frac{\\sum_{j=1}^k s_j}{k}\\) et alors une estimation de l’écart type instantané \\(\\sigma_M\\) est donné par\n\\[\n\\hat \\sigma_M=\\dfrac{\\bar S}{c_4}\n\\] où \\(c_4\\) est donné dans la table 1.\nOn obtient \\(\\hat \\sigma_M=\\) 0.0228258\n\n\n\nPour chaque échantillon \\(j\\) on calcule l’étendue\n\\[\nR_j=\\max(y_{ij})-\\min(y_{ij})\n\\]\nOn pose \\(\\bar R =\\frac{\\sum_{j=1}^k R_j}{k}\\) et alors une estimation de l’écart type instantané \\(\\sigma_M\\) est donné par\n\\[\n\\hat \\sigma_M=\\dfrac{\\bar R}{d_2}\n\\]\noù \\(d_2\\) est donné dans la table 1.\nRetour à l’exemple\n\n\n\n\n\nsample\nR_j\n\n\n\n\n1\n0.04128\n\n\n2\n0.02866\n\n\n3\n0.07048\n\n\n4\n0.03681\n\n\n5\n0.05540\n\n\n6\n0.06414\n\n\n\n\n\nOn obtient \\(\\hat \\sigma_M=\\) r\nOn constate que les estimations obtenues à partir de \\(\\bar R\\) ou de \\(\\bar S\\) sont proches."
  },
  {
    "objectID": "capabilite.html#indices-de-capabilité-globale",
    "href": "capabilite.html#indices-de-capabilité-globale",
    "title": "Capabilité",
    "section": "",
    "text": "Dans la suite \\(TS,TI\\) désigneront la tolérance supérieure et inférieure du procédé de fabrication.\nComme précédemment on distingue la variabilité globale du procédé et celle uniquement attribuable à la machine.\nOn définit deux types d’indices de capabilité :\n\nLa capabilité globale du procédé de fabrication (appelée aussi coefficient d’aptitude du procédé) \\[\nCap=\\frac{TS-TI}{D_G}\n\\]\nLa capabilité machine (appelée aussi coefficient d’aptitude du moyen)\n\n\\[\nCam=\\frac{TS-TI}{D_M}\n\\]\n\n\n\nIl est clair que lorsque \\(Cap&lt;1\\) le procédé n’est pas capable, il faut le revoir afin d’obtenir une production conforme aux tolérances. Par contre si \\(Cap&gt;2\\) on va considérer que le procédé est capable dans la mesure où la dispersion naturelle des observation est 2 fois moins importante que l’intervalle de tolérance.\nLes deux indicateurs précédents ont un gros inconvénient dans la mesure où ils ne permettent pas de juger du décentrage éventuel du procédé. Par exemple, dans le cas d’une loi normale, on peut avoir une situation comme celle ci-dessous :\n On voit que le procédé est bien dans l’intervalle de tolérance avec une valeur \\(Cap&gt;2\\) mais qu’il est clairement décentré. Donc il faut définir de nouveaux indices de capabilité qui vont permettre de juger de la justesse du procédé !"
  },
  {
    "objectID": "capabilite.html#indices-de-capabilité-de-centrage",
    "href": "capabilite.html#indices-de-capabilité-de-centrage",
    "title": "Capabilité",
    "section": "",
    "text": "Le coefficient de performance du procédé est\n\\[\nCpk=\\frac{\\min\\left(\\mu-TI;TS-\\mu\\right)}{3\\sigma_{g}},\n\\]\net celui la machine est\n\\[\nCmk=\\frac{\\min\\left(\\mu-TI;TS-\\mu\\right)}{3\\sigma_{i}}.\n\\]\nIl est clair que l’on a :\n\n\\(Cap&gt;Cpk,\\)\n\\(Cam&gt;Cmk.\\)\n\nOn utilisera la norme suivante :\nUn procédé (respectivement une machine) est capable si \\(Cpk&gt;1.33\\) (respectivement \\(Cmk&gt;1.33\\))\n\n\nLes calculs de \\(Cap\\) et de \\(Cpk\\) sont basés sur des estimations de l’écart type \\(\\sigma_G\\). Dans le cas d’une loi normale on sait construire un intervalle de confiance de \\(\\sigma_G\\), on en déduit que\n\nL’intervalle \\(\\left[\\widehat C_{ap}\\sqrt{\\dfrac{\\chi^2_{n-1}(\\alpha/2)}{n-1}};\\widehat C_{ap}\\sqrt{\\dfrac{\\chi^2_{n-1}(1-\\alpha/2)}{n-1}}\\right]\\) est un intervalle de confiance de \\(Cap\\) au niveau de confiance \\(100(1-\\alpha)\\) %.\nL’intervalle \\(\\left[\\widehat C_{pk}\\left(1-z_{1-\\alpha/2}\\sqrt{\\dfrac{1}{9n\\widehat C_{pk}^2}+\\dfrac{1}{2(n-1)}}\\right);\\widehat C_{pk}\\left( 1+z_{1-\\alpha/2}\\sqrt{\\dfrac{1}{9n\\widehat C_{pk}^2}+\\dfrac{1}{2(n-1)}}\\right)\\right]\\) est un intervalle de confiance de \\(C_{pk}\\) au niveau de confiance \\(100(1-\\alpha)\\) %.\n\n\n\n\nOn suppose que les tolérance sont \\(TI=0.9\\) et \\(TS=1.1\\).\nOn a \\(\\hat Cap=\\) 1.51 et \\(\\hat Cam=\\) 1.43.\nLa moyenne du procédé est estimé par \\(\\hat \\mu=\\overline{\\overline X}=\\) 0.999. Donc on a \\(\\hat Cpk=\\) 1.5 et \\(\\hat Cmk=\\) 1.41.\nL’intervalle de confiance de \\(Cap\\) est 1.32, 1.7 et celui de \\(Cpk\\) est 1.3, 1.69."
  },
  {
    "objectID": "bibliographie.html",
    "href": "bibliographie.html",
    "title": "Bibliographie",
    "section": "",
    "text": "Bibliographie\nLe cours est principalement basé sur :\n\nGupta (2021) Statistical Quality Control Using Minitab, R, JMP, and Python, Wiley.\n\nIci le site web et des compléments pour ce livre.\nEnsuite :\nPour les normes (France)\n\nAFNOR. Méthodes statistiques, tome 4. Maîtrise statistique des processus, 7ième édition. AFNOR, Paris, 1996.\n\nEt d’autres références :\n\nMontgomery Douglas C. (2019) Introduction to Statistical Quality Control, 8th Edition, Wiley\nDuclos E. (2008) La Maîtrise Statistique des Procédés E. Duclos Conseil."
  }
]